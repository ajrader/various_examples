{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts on Random Forests as Graphs\n",
    "### August 31, 2015\n",
    "\n",
    "### Classification\n",
    "Consider a single decision tree, $T$. When a test vector, $\\vec{x}$ is applied to $T$ a prediction for that observation, $\\hat{y}$ is produced.\n",
    "\n",
    "So if a test matrix ${\\bf X}$ containing $m$ observations is applied to $T$ a prediction vector $\\vec{\\hat{y}}$ is produced.\n",
    "\n",
    "A forest of decision trees is just an ensemble of them. Denote this by ${\\cal T}$ where $\\forall T_k \\in {\\cal T}$, ${\\bf X} T_k = \\vec{\\hat {y_k}}$ and thus the ensemble prediction $\\vec{\\hat{\\gamma}}$ is the average (possibly weighted) of these ensemble of trees.\n",
    "\n",
    "### Question: Is there a mapping between an ensemble of decision trees and random graphs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say everything is boolean so an example test vector is $\\vec{x} = (1,0,1,1)$ then the splits are all able to be written as $x_i <0.5 \\forall i$. \n",
    "\n",
    "#### Work through an example with 2 features\n",
    "In the case of $\\eta =2$ features there are only 4 possible options: $\\vec{x} = (0,0) \\textrm{ or } (0,1)  \\textrm{ or } (1,0)  \\textrm{ or } (1,1)$. This means there are $N = 2^\\eta = 4$ possible states. With this the max number of splits required in the tree is $s=N-1 = 3$. Likewise for $\\eta = 3$ features, there are $N=8$ cases and $s = 2^\\eta -1 = 7$ splits.\n",
    "\n",
    "#### Now as a graph\n",
    "The graph of Random Forests can be thought of as a complete graph of size $s$ where the edges are the weights between splits,  i.e. how frequently they are linked and how meaningful (for classification) these splits are.\n",
    "\n",
    "Define the weight fo a split by gini? or frequency? or weighted frequency?\n",
    "\n",
    "Again for boolean vectors, the set of nodes are defined to have dimension $s$. \n",
    "\n",
    "Try to assign the edge weight to the frequency. \n",
    "\n",
    "* first option: $e(j,k) = f(j,k)$ where $f(j,k) = $ (number of treese where split $j$ and split $k$ are adjacent) divided by number of trees generated.\n",
    "\n",
    "* 2nd option: $e(j,k) = \\zeta_{j,k}$ where $\\zeta_{j,k} = \\frac{1}{n_{trees}}\\sum_{trees} \\chi_{0,\\alpha} \\dot \\Theta(T_\\alpha - I_{j,k})$ where $\\Theta(T_\\alpha - I_{j,k}) = 1 \\textrm{ if } j,k \\textrm{ are adjacent in } T_\\alpha \\textrm{ and } 0 \\textrm{ else}$.\n",
    "\n",
    "This gives you an $s \\times s$ matrix, ${\\bf \\cal{S}}$ with zeros on the diagonals. Would ${\\bf X}{\\bf \\cal{S}} = \\vec{\\hat{\\gamma}}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
