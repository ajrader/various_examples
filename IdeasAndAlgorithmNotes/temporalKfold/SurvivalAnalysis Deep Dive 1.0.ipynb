{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning for HR Separations\n",
    "## Deep dive into Survival analysis\n",
    "## December 17, 2015\n",
    "<hr>\n",
    "\n",
    "\n",
    "\n",
    "### 1. Start with the partially processed data\n",
    "* filename = 'after2001_v3.csv'\n",
    "* historical columns removed\n",
    "* RATE column removed\n",
    "* Dates converted to timestamps\n",
    "* calculated the age/tenure and hire_age\n",
    "* converted indicator variables to 1/0\n",
    "* converted BOX1 to {0,1,2,3} \n",
    "* \n",
    "#### define the source repo\n",
    "* '/home/kesj/lib/repo/'\n",
    "\n",
    "### 2. Define the correct working directories\n",
    "* '/data/discovery/hrsepara/core/' for HDFS\n",
    "* '/data/discovery/hrsepara/staging/eda' and '/home/kesj/working/hrsepara/eda/' for HDFS and LFS on phd\n",
    "* ' /home/hrsepara/work/data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coredir = '/data/discovery/hrsepara/core/'\n",
    "stgdir1 = '/data/discovery/hrsepara/staging/eda'\n",
    "#stgdir1local = '/home/kesj/work/hrsepara/eda'\n",
    "#stgdir2local = '/home/kesj/work/hrsepara/proc'\n",
    "repodir = '/home/kesj/lib/repo/'\n",
    "datadirlocal = '/home/hrsepara/work/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### load the basic files\n",
    "import os,subprocess,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "import random\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "plt.style.use('ggplot')\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(repodir)\n",
    "import bear.bear as br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## save this dataframe\n",
    "os.chdir(datadirlocal)\n",
    "#em2002.to_csv('after2001_keyed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## strings\n",
    "em2002.fillna({'ACTRES1':'UNKNOWN','LOC_STATE':'XX','STATE':'XX','LOC_CITY':'UNKNOWN','SKEY':'UNKNOWN',\n",
    "               'GRADE':'XX','JOB_FAMILY':'XX','POSTAL_SFI':'XXX','ADDRESS1':'UNKNOWN','VOLINVOL':'N/A',\n",
    "              'JOB_FUNCTION':'XX'},inplace=True)\n",
    "em2002.fillna({'BOX1':0,'HAVE_INS':'N','HAVE_DEP':'N'},inplace=True)\n",
    "## floats\n",
    "em2002.fillna({'DEPENDENT_CNT':0,'TOTAL_RPT_CNT':0,'EXTFUNC_CNT':0.0,'MERIT1':0.0,'PERF1':0.0,'SAL1':0.0,\n",
    "              'FUNC_CNT':0.0,'DIRECT_RPT_CNT':0.0,'ADDRCNT1':0.0},inplace=True)\n",
    "\n",
    "br.get_columns_with_nulls(em2002[all_cols3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START LOADING HERE 12.09.2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002 = pd.read_csv('after2001_v3.csv',dtype={'EEO1CODE':np.str,'EMPL_CLASS':np.str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col3_categorical = br.get_categorical(em2002)\n",
    "col3_numeric = br.get_numeric(em2002)\n",
    "print len(col3_numeric), len(col3_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#indicator_cols = []\n",
    "#cat_cols2 = []\n",
    "for c in col3_categorical: #cat_cols:\n",
    "    nobs = len(em2002[c].unique())\n",
    "    #if nobs == 2:\n",
    "        #indicator_cols.append(c)\n",
    "    #else:\n",
    "    print c, nobs\n",
    "    #    cat_cols2.append(c)\n",
    "print \"============\"\n",
    "numeric_to_categorical = ['COMPANY','DIVISION_CODE_SFI','ETHNIC_GROUP']\n",
    "for c in numeric_to_categorical:\n",
    "    print c, len(em2002[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(em2002['FUNC_ID_SFI'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cat_cols_to_dummy_encode = ['EMPL_TYPE','EMPL_CLASS','EEO1CODE','FULL_PART_TIME','FLSA_STATUS','LOC_TYPE_DESCR_SFI',\n",
    "                           'COMPANY','DIVISION_CODE_SFI','ETHNIC_GROUP','JOB_FUNCTION']\n",
    "my_label_encode_cols = ['JOB_FAMILY', 'GRADE', 'FLOR_SFI', 'FUNC_ID_SFI', 'EXT_FUNC_ID_SFI',\n",
    "                        'JOBCODE', 'LOC_STATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(col,em2002[col].dtype) for col in cat_cols_to_dummy_encode]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## identify meaningless columns for modeling\n",
    "* potential responses: retired, status\n",
    "* timestamps (3)\n",
    "* KEY, SKEY, ACTRES1, MAR_STA_SNAME_SFI, LOC_TYPE_DESCR_SFI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_numeric = list(set(col3_numeric)-set(numeric_to_categorical)-set(my_label_encode_cols))\n",
    "true_numeric.sort()\n",
    "len(true_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(col,em2002[col].nunique(), em2002[col].max()) for col in true_numeric]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare Age, tenure and hire age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002[['Age_years','Tenure_years','hire_age']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='Age_years',y='hire_age',data=em2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='Tenure_years',y='hire_age',data=em2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iterative_modeling_cols = [col for col in true_numeric]\n",
    "iterative_modeling_cols.remove('status')\n",
    "iterative_modeling_cols.remove('retired')\n",
    "iterative_modeling_cols.remove('KEY')\n",
    "iterative_modeling_cols.remove('former')\n",
    "iterative_modeling_cols.remove('Tenure_years')\n",
    "iterative_modeling_cols.remove('ANNUAL_RT')\n",
    "iterative_modeling_cols.remove('Age_years')\n",
    "iterative_modeling_cols.remove('hire_age')\n",
    "len(iterative_modeling_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "br.perfect_collinearity_test(em2002[iterative_modeling_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Oct. 23, 2015\n",
    "## Looking at doing survival analysis for Retirement\n",
    "plan of attack\n",
    "\n",
    "1. id the minimum age of retirement, $A_R$, in our dataset and adjust it by $y_H$, the maximum horizon age..\n",
    "2. use the train-test-split from above (build & evaluation sets)\n",
    "3. pull out subsets from each where the following conditions are met:\n",
    "    a. retired == 1  OR\n",
    "    b. Age $\\ge A_R - y_H$\n",
    "4. calculate retire age\n",
    "    * I might have to calculate this in relative terms\n",
    "5. take subset of columns (minimal_cols_to_keep)\n",
    "6. apply coxph to get prob of retire and weights of factors/features.\n",
    "7. also try other models like Aaalen and Nelson\n",
    "7. test on evaluation set for ability to predict \n",
    "    * ...\n",
    "9. check for retirement rates in each of the coming years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for retirement split based on age (50 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "over50 = em2002[em2002.Age_years >= 50.0].copy()\n",
    "print len(over50)\n",
    "#over50.to_csv('over50.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# repeat the split\n",
    "\n",
    "# break into evaluation and build sets\n",
    "print \"Starting with subset of {0} employees.\".format(len(over50))\n",
    "eval_fraction = 0.20\n",
    "o50build, o50eval = cross_validation.train_test_split(over50,test_size=eval_fraction,random_state = 88843)\n",
    "print \"Evaluation set has {0} employees; training set has {1} employees.\".format(len(o50eval),len(o50build))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50build.retired.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval.retired.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "cf = CoxPHFitter()\n",
    "#from lifelines import AalenAdditiveFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function to fit and score a model with variables\n",
    "def optimize_model(df,column_list,tgt_col = 'Age_years',ind_col='retired'):\n",
    "    concordvals =[]\n",
    "    my_col = [tgt_col,ind_col]\n",
    "    for idx,col in enumerate(column_list):\n",
    "        cf = CoxPHFitter()\n",
    "        my_col.append(col)\n",
    "        cf.fit(df[my_col],tgt_col,event_col=ind_col)\n",
    "       \n",
    "        try: \n",
    "            cf.print_summary()\n",
    "        except AttributeError:\n",
    "            print cf.summary()\n",
    "        \n",
    "        concord = concordance_index(df[tgt_col],-cf.predict_partial_hazard(df[my_col[2:]].values),df[ind_col])\n",
    "        print col, idx, concord\n",
    "        concordvals.append(concord)\n",
    "    return concordvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50build.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_col = ['SEX','hire_age','SAL1','MERIT1','HAVE_INS','HAVE_DEP','PERF1','BOX1','Age_years','retired']\n",
    "cf.fit(em2002[tmp_col],'Age_years','retired')\n",
    "cv = cf.print_summary()\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_col2 = tmp_col\n",
    "tmp_col2.remove('Age_years')\n",
    "tmp_col2.remove('retired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lifelines.utils import concordance_index\n",
    "concordance_index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(em2002[tmp_col2].values.ravel())#.Age_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concordance_index(em2002.Age_years,-cf.predict_partial_hazard(em2002[tmp_col2].values),em2002['retired'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cf.predict_partial_hazard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time\n",
    "tmp_col = ['SEX','hire_age','SAL1','MERIT1','HAVE_INS','HAVE_DEP','PERF1','BOX1']\n",
    "optimize_model(o50build,tmp_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.predict_expectation(o50eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval[o50eval.retired==1].Age_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_cat1 = CoxPHFitter()\n",
    "cf_cat1.fit(o50build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002[['status','retired','former']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50build[['retired','Age_years','SEX','hire_age']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### build a coxproporitional hazard model based upon:\n",
    "* Sex, hire_age, SAL1, MERIT1, HAVE_INS, & HAVE_DEP (model_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_modA = CoxPHFitter()\n",
    "cf_modA.fit(o50build[['retired','Age_years','SEX','hire_age','SAL1','MERIT1','HAVE_INS','HAVE_DEP']],'Age_years',event_col='retired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cf_modA.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_modA.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_modA.predict_expectation(o50build[['retired','Age_years','SEX','hire_age','SAL1','MERIT1','HAVE_INS','HAVE_DEP']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_modA2 = CoxPHFitter()\n",
    "cf_modA2.fit(o50build[['retired','Age_years','SEX','Tenure_years','SAL1','MERIT1','HAVE_INS','HAVE_DEP','BOX1','PERF1']],'Age_years',event_col='retired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_modA2.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.hazards_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concordance_index(self.durations,\n",
    "                                        -self.predict_partial_hazard(self.data).values.ravel(),\n",
    "                                        self.event_observed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.predict_partial_hazard(o50build).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lifelines.utils import concordance_index \n",
    "concordance_index(cf.durations.values,cf.predict_expectation(o50build[['retired','Age_years','SEX','HAVE_INS','hire_age']]).values.ravel(),cf.event_observed.astype(int).values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.event_observed.astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expectations = cf.predict_expectation(o50build[['retired','Age_years','SEX','HAVE_INS','hire_age']])\n",
    "expectations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.durations[cf.event_observed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#surv_minimal_cols_to_keep = ['Age_years','Tenure_years','SAL1','MERIT1','PERF1','BOX1','SEX','HAVE_INS','HAVE_DEP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retire_surv_cols1 = ['retired','Age_years','hire_age','SAL1','MERIT1','PERF1','BOX1','SEX','HAVE_INS','HAVE_DEP']\n",
    "cf2 = CoxPHFitter()\n",
    "cf2.fit(o50build[retire_surv_cols1], 'Age_years', event_col='retired')\n",
    "\n",
    "cf2.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.hazards_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf2.hazards_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle my result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( cf_modA, open( \"retirement_sfA.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## now load it\n",
    "ret_model = pickle.load(open('retirement_sfA.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ret_model.hazards_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict results for o50eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval[['Age_years','retired']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_modA.predict_survival_function(o50eval.head()).ix[58.07:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf2_pred = cf2.predict_survival_function(o50eval[retire_surv_cols1[2:]].values)\n",
    "cf2_pred.index.name='years'\n",
    "cf2_pred.reset_index(inplace=True)\n",
    "cf2_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dec 17, 2015\n",
    "replace hire_age with Tenure_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retire_surv_cols1 = ['retired','Age_years','Tenure_years','SAL1','MERIT1','PERF1','BOX1','SEX','HAVE_INS','HAVE_DEP']\n",
    "cf3 = CoxPHFitter()\n",
    "cf3.fit(o50build[retire_surv_cols1], 'Age_years', event_col='retired')\n",
    "\n",
    "cf3.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf2.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.interpolate\n",
    "def survival_predictions(edf,psf = cf_pred):\n",
    "    for employee_id,age in enumerate(ages):\n",
    "        prior_idx = np.where(psf.years<age+1.0)\n",
    "        posterior_idx = np.where(psf.years>age+1.0)\n",
    "        x= [psf.ix[prior_idx]['years'], psf.ix[posterior_idx]['years']]\n",
    "        y= [psf.ix[prior_idx][employee_id],psf.ix[posterior_idx][employee_id]]\n",
    "        print x,y, employee_id, age\n",
    "    ## now interpolate these\n",
    "        y_interp = scipy.interpolateinterp1d(x,y)\n",
    "        print y_interp\n",
    "    return y_interp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_survival_prediction(edf,psf=cf_pred, age_col='Age_years',yr_vals=[1,2,3,4,5]):\n",
    "    \n",
    "    pred_col_names = ['proba_'+str(y) for y in yr_vals]\n",
    "    df = pd.DataFrame(index=edf.index,columns=pred_col_names,dtype=float)\n",
    "    print pred_col_names\n",
    "    for employee_id,age in enumerate(edf['Age_years']):\n",
    "        if employee_id % 1000 ==0 :\n",
    "            print employee_id, age\n",
    "            \n",
    "        prob_vals =np.ones((len(yr_vals),))\n",
    "        #print prob_vals,\"\\n\"\n",
    "        \n",
    "        for idx,year in enumerate(yr_vals):\n",
    "            ck_yr = age+year\n",
    "            #if ck_yr in psf.years:\n",
    "            #    proba = psf[psf.years==ck_yr][employee_id]\n",
    "            #else:\n",
    "            #proba=np.nan\n",
    "            \n",
    "            try:\n",
    "                prior_idx = np.where(psf.years < ck_yr)[0][-1]\n",
    "                posterior_idx = np.where(psf.years > ck_yr)[0][0]\n",
    "                x= [psf.ix[prior_idx]['years'], psf.ix[posterior_idx]['years']]\n",
    "                y= [psf.ix[prior_idx][employee_id],psf.ix[posterior_idx][employee_id]]\n",
    "                #print x,y, year\n",
    "                ## now interpolate these\n",
    "                y_interp = scipy.interpolate.interp1d(x,y)\n",
    "                proba = y_interp(ck_yr)\n",
    "            except IndexError:\n",
    "                proba = psf.ix[np.where(psf.years == ck_yr)[0]][employee_id]\n",
    "            #print proba\n",
    "            \n",
    "            try:\n",
    "                prob_vals[idx] = proba\n",
    "                #print employee_id,age,ck_yr,proba, prob_vals[idx]\n",
    "            except ValueError: # case when age not found because too young\n",
    "                #lse:\n",
    "                pass #print idx, prob_vals[idx]\n",
    "                # just leave it as the default value of 1\n",
    "                    \n",
    "            #prob_vals[id]=1-proba    \n",
    "            #if len(yr_vals)>1:\n",
    "            #    empl_list.append(1-proba)# get prob of retirement\n",
    "            #else:\n",
    "            #    empl_list = 1-proba\n",
    "        #try:\n",
    "        df.loc[edf.index[employee_id]]=prob_vals\n",
    "        #except ValueError: # case when not found (because too young)\n",
    "        #    df.loc[edf.index[employee_id]]=0.0 # zero probability\n",
    "            #print employee_id, edf.index[employee_id]\n",
    "    df.fillna(0.0,inplace=True) # fillin missing values with zero\n",
    "    df[df<0] = 0.0 #replace negative probabilities with zero\n",
    "    #df.replace()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfRetProb = get_survival_prediction(o50eval,psf=cf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pred_o50eval=pd.concat([o50eval[retire_surv_cols1[:2]],retireProb_df],axis=1)\n",
    "pred_o50eval_cf = pd.concat([o50eval[retire_surv_cols1[:2]],cfRetProb],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_o50eval_cf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess the prob_retired at current age for eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_retire_age = get_survival_prediction(o50eval,yr_vals=[0])\n",
    "o50eval_curr = pd.concat([o50eval[retire_surv_cols1[:2]],curr_retire_age],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval_curr.head() #proba is the probability of 'survival' so I want 1-proba for probability to retire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(df,true_col = 'retired', p_col = 'proba_0',thresh=0.5,verbose=False):\n",
    "    ckdf = (df[p_col]<=thresh).astype('int')\n",
    "    true_pos = df[ckdf==1][true_col].sum()\n",
    "    false_pos= len(df[ckdf==1])-true_pos\n",
    "    \n",
    "    false_neg=df[ckdf==0][true_col].sum()\n",
    "    true_neg =len(df[ckdf==0]) - false_neg\n",
    "    if verbose:\n",
    "        print \"threshold = {0}\".format(thresh)\n",
    "        print \"TP\\t FP\\t FN\\t TN\"\n",
    "        print true_pos, '\\t',false_pos,'\\t' ,false_neg,'\\t', true_neg\n",
    "    \n",
    "    acc = (true_pos + true_neg)/float(len(df))\n",
    "    \n",
    "    mcc = (true_pos*true_neg - false_pos*false_neg)/np.sqrt((true_pos+false_pos)*(true_pos+false_neg)*(true_neg+false_pos)*(true_neg+false_neg))\n",
    "    if verbose:\n",
    "        print \"Accuracy is {0:.3f}\".format(acc)\n",
    "        print \"Matthews correlation coefficient is {0:.3f}\".format(mcc)\n",
    "    tpr = true_pos/float(true_pos+false_neg)\n",
    "    fpr = false_pos/float(false_pos + true_neg)\n",
    "    return tpr,fpr,acc,mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.roc_auc_score(o50eval_curr.retired.values,1-o50eval_curr.proba_0.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_vals = []\n",
    "tvals = np.linspace(0,1,21)#,0.05)#:#xrange(0,1,0.05):\n",
    "for t in tvals:\n",
    "    roc_vals.append(get_accuracy(o50eval_curr,thresh=t))\n",
    "\n",
    "    \n",
    "roc_vals = np.array(roc_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_vals = np.array(roc_vals)\n",
    "plt.plot(roc_vals[:,1],roc_vals[:,0])\n",
    "plt.plot(tvals,tvals,color='k',ls='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for Separation\n",
    "* use all employees -- split into test & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# repeat the split\n",
    "\n",
    "# break into evaluation and build sets\n",
    "print \"Starting with subset of {0} employees.\".format(len(em2002))\n",
    "eval_fraction = 0.20\n",
    "e2build, e2eval = cross_validation.train_test_split(em2002,test_size=eval_fraction,random_state = 8223)\n",
    "print \"Evaluation set has {0} employees; training set has {1} employees.\".format(len(e2eval),len(e2build))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_surv_cols1=['former','Tenure_years','Age_years','SAL1','MERIT1','PERF1','BOX1','SEX','HAVE_INS','HAVE_DEP']\n",
    "#'SEX','FTE','HAVE_INS','HAVE_DEP','SAL1']\n",
    "reduced_cols = ['SAL1','HAVE_INS','MERIT1','PERF1','MIN_RT_ANNUAL','INTERN','BOX1','HAVE_DEP','Age_years','DEPENDENT_CNT','DIRECT_RPT_CNT','SEX','Tenure_years','former']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sepCF = CoxPHFitter()\n",
    "sepCF.fit(e2build[sep_surv_cols1], 'Tenure_years', event_col='former')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sepCF.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time\n",
    "tmp_col = reduced_cols[:-2]\n",
    "optimize_model(e2build,tmp_col,tgt_col='Tenure_years',ind_col='former')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sepcf_pred = sepCF.predict_survival_function(e2eval[sep_surv_cols1[2:]].values)\n",
    "sepcf_pred.index.name='years'\n",
    "sepcf_pred.reset_index(inplace=True)\n",
    "sepcf_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(sepcf_pred.years, sepcf_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfSepProb = get_survival_prediction(e2eval,psf=sepcf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfSepProb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assess the current Sep probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curryear_sep_pred = get_survival_prediction(e2eval,yr_vals=[0],psf=sepcf_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e2eval_sepNow = pd.concat([e2eval[sep_surv_cols1[:2]],curryear_sep_pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e2eval_sepNow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(e2eval_sepNow.former.values,1-e2eval_sepNow.proba_0.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_roc_vals = []\n",
    "tvals = np.linspace(0,1,41)#,0.05)#:#xrange(0,1,0.05):\n",
    "for t in tvals:\n",
    "    sep_roc_vals.append(get_accuracy(e2eval_sepNow,thresh=t,true_col='former'))\n",
    "\n",
    "    \n",
    "sep_roc_vals = np.array(sep_roc_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(sep_roc_vals[:,1],sep_roc_vals[:,0])\n",
    "plt.plot(tvals,tvals,color='k',ls='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('Separation ROC curve; current values e2eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the retirement Rates for current employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current = em2002[em2002.status==0].copy() \n",
    "np.shape(current)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply retirement and separation for next 5 years to this set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_retcf_pred = cf.predict_survival_function(current[retire_surv_cols1[2:]].values)\n",
    "current_retcf_pred.index.name='years'\n",
    "current_retcf_pred.reset_index(inplace=True)\n",
    "current_retcf_pred.head()\n",
    "currentcfRetProb = get_survival_prediction(current,psf=current_retcf_pred)\n",
    "#current_sepcf_pred = sepCF.predict_survival_function(current[sep_surv_cols1[2:]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret_fiveyrDF = pd.concat([current[retire_surv_cols1[:3]],currentcfRetProb],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ret_fiveyrDF[['yr1','yr2','yr3','yr4','yr5']]=1-ret_fiveyrDF[['proba_1','proba_2','proba_3','proba_4','proba_5']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_rates = pd.DataFrame(ret_fiveyrDF[['yr1','yr2','yr3','yr4','yr5']].sum()/float(len(ret_fiveyrDF)))\n",
    "tmp_rates.index = ['yr1','yr2','yr3','yr4','yr5']\n",
    "tmp_rates.columns = ['Retirement']\n",
    "tmp_rates['Annual Retirement'] = tmp_rates.diff()\n",
    "tmp_rates.loc['yr1','Annual Retirement']= tmp_rates.loc['yr1','Retirement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_sepcf_pred = sepCF.predict_survival_function(current[sep_surv_cols1[2:]].values)\n",
    "current_sepcf_pred.index.name='years'\n",
    "current_sepcf_pred.reset_index(inplace=True)\n",
    "current_sepcf_pred.head()\n",
    "currentcfSepProb = get_survival_prediction(current,psf=current_sepcf_pred)\n",
    "#current_sepcf_pred = sepCF.predict_survival_function(current[sep_surv_cols1[2:]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_fiveyrDF = pd.concat([current[sep_surv_cols1[:3]],currentcfSepProb],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_fiveyrDF[['Sep_1','Sep_2','Sep_3','Sep_4','Sep_5']]=1-sep_fiveyrDF[['proba_1','proba_2','proba_3','proba_4','proba_5']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_fiveyrDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_rates = pd.DataFrame(sep_fiveyrDF[['Sep_1','Sep_2','Sep_3','Sep_4','Sep_5']].sum()/float(len(sep_fiveyrDF)))\n",
    "simple_rates.index = ['yr1','yr2','yr3','yr4','yr5']\n",
    "simple_rates.columns = ['Separation']\n",
    "simple_rates['Annual Separation'] = simple_rates.diff()\n",
    "simple_rates.loc['yr1','Annual Separation']= simple_rates.loc['yr1','Separation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_rates = pd.concat([simple_rates,tmp_rates],axis=1)\n",
    "simple_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up missing & dummy encode/etc the categorical --> use a pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_columns = br.get_columns_with_nulls(em2[all_cols3])\n",
    "print len(missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_cat_cols = br.get_columns_with_nulls(em2[cat_cols2])\n",
    "missing_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mthl_tenure_range = np.linspace(0,65,781)\n",
    "def calculate_survival_functions_b(df,y, time_col, col_name,num_cutoff = 40,timerange =mthl_tenure_range):\n",
    "    \n",
    "    \"\"\" Function to generically return a dataframe of survival function, grouped by some categorical column\n",
    "    inputs:\n",
    "        df --> database to derive survival functions from\n",
    "        time_col --> the temporal column to use for SF modeling (Kaplan Meier fitter applied)\n",
    "        event_col --> the truncated column to use for SF modeling\n",
    "        col_name --> the column to group up and determine KMF sf for\n",
    "        num_cutoff --> number of groups to consider\n",
    "        timerange --> min and max range\n",
    "    outputs:\n",
    "        survivalfunc_df --> a data frame that contains survival function.\n",
    "\n",
    "    other options:\n",
    "        *frac_cutoff --> the fraction of unique elements that will be kept as separate groups\n",
    "        *min_size_cutoff --> min size to use for the cutoff.\n",
    "        * these last two are not implemented\n",
    "    \"\"\"\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    kmf=KaplanMeierFitter()\n",
    "    # create example for all cases -- serves as background\n",
    "    # create a time range\n",
    "    \n",
    "    kmf.fit(df[time_col],timeline=timerange,event_observed=y,label='all')\n",
    "    survivalfunc_df = pd.DataFrame(kmf.survival_function_)\n",
    "    # groupify the dataframe\n",
    "    grp_value_counts = df[col_name].value_counts()\n",
    "    #if frac_cutoff == None:\n",
    "    #    #by default take 15 %\n",
    "    #    frac_cutoff = .15 \n",
    "    #top_n_groups = int(frac_cutoff *len(grp_value_counts))\n",
    "    #if min_size_cutoff == None:\n",
    "        # by default \n",
    "    # Take the top num_cutoff groups\n",
    "    #my_grps = grp_value_counts.ix[:num_cutoff].index.tolist() \n",
    "    my_grps = grp_value_counts.iloc[:num_cutoff].index.tolist() \n",
    "    \n",
    "    # make a list of elements in each of these groups\n",
    "    grp_dict = {}\n",
    "    for grp in my_grps: \n",
    "        grp_dict[grp] = df[df[col_name] == grp].index.tolist()\n",
    "    # loop through grps and create kmf survival function\n",
    "    for i,jgrp in enumerate(my_grps):\n",
    "        j_idx = grp_dict[jgrp]\n",
    "        #print i, jgrp, len(j_idx)\n",
    "        kmf.fit(df[time_col].ix[j_idx],timeline=mthl_tenure_range,event_observed=y.ix[j_idx],label=str(jgrp))\n",
    "        survivalfunc_df = pd.concat([survivalfunc_df,kmf.survival_function_],axis=1)\n",
    "    \n",
    "    \n",
    "    return survivalfunc_df\n",
    "\n",
    "def return_first_time_survival(sfdf,thresh=0.5):\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # assign all value to the default\n",
    "    default_value = sfdf[sfdf['all']<=thresh].index[0]\n",
    "    median_survival_dict = defaultdict(lambda: default_value)\n",
    "    for c in sfdf.columns[1:]:\n",
    "        #print c\n",
    "        try:\n",
    "            my_sf_date = sfdf[sfdf[c]<=thresh].index[0]\n",
    "        except IndexError: # because never reached that threshold value\n",
    "            my_sf_date = sfdf.index[-1]\n",
    "        except KeyError: # because of type of the key\n",
    "            my_sf_date = sfdf[sfdf[int(c)]<=thresh].index[0]\n",
    "\n",
    "        median_survival_dict[c]=my_sf_date\n",
    "        \n",
    "    return median_survival_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SurvivalEncodeColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_fix=[],rows_to_scan='all',method='median',max_number_groups=40, my_thresh=0.5):\n",
    "        self.method = method\n",
    "        self.columns_to_fix = columns_to_fix\n",
    "        self.rows_to_scan = rows_to_scan\n",
    "        self.max_num_groups = max_number_groups\n",
    "        self.thresh = my_thresh\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.survive_columns = {} # dictionary to map old columns to new\n",
    "        self.survive_values = {}\n",
    "        self.column_cutoff = {}\n",
    "        \n",
    "        \n",
    "        for col in self.columns_to_fix:\n",
    "            #(assumes these have previously been label encoded so the values should be ints)\"\n",
    "            ncol=str(col)+\"_le\"\n",
    "            num_cutoff = self.max_num_groups\n",
    "            survive_col = 'surv_'+ncol.lower()\n",
    "            nuniq = len(X[ncol].unique())\n",
    "            if nuniq < num_cutoff:\n",
    "                num_cutoff = nuniq\n",
    "                \n",
    "            self.column_cutoff[col]=num_cutoff\n",
    "            \n",
    "            #frac_accounted_for = X[col].value_counts().iloc[:num_cutoff].sum()/float(len(X))\n",
    "            #print i,col,newcol, nuniq, num_cutoff,num_cutoff/float(nuniq),frac_accounted_for\n",
    "            # I want to make this fraction close to 80%?\n",
    "            sf_df = calculate_survival_functions_b(X,y,'Tenure_years', ncol,num_cutoff)\n",
    "            self.survive_columns[col]=survive_col\n",
    "            ## create the dictionary\n",
    "            self.survive_values[col]=return_first_time_survival(sf_df,thresh=self.thresh)\n",
    "    \n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        X_temp = X.copy()\n",
    "        original_cols = list(X_temp.columns)\n",
    "        for col in self.columns_to_fix:\n",
    "            ncol=str(col)+\"_le\" # assumes labelencoded\n",
    "            new_col = self.survive_columns[col]\n",
    "            col_dict = self.survive_values[col]\n",
    "            X_temp[new_col] = X_temp[ncol].apply(lambda x: col_dict[str(x)])\n",
    "            original_cols.remove(ncol)\n",
    "            original_cols.append(new_col)\n",
    "        \n",
    "        X_temp = X_temp[original_cols]\n",
    "        return X_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#my_cols_to_omit =list(set(all_cols)-set(all_cols3))\n",
    "#len(my_cols_to_omit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[a for a in all_cols4 if a.endswith('SFI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_cols2 = list(set(all_cols3).intersection(set(cat_cols2)))\n",
    "[(c,len(em2[c].unique())) for c in cat_cols2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_label_encode_cols = ['JOB_FAMILY', 'GRADE', 'JOB_FUNCTION',\n",
    " 'FLOR_SFI', 'FUNC_ID_SFI', 'EXT_FUNC_ID_SFI',\n",
    " 'JOBCODE', 'LOC_TYPE_DESCR_SFI',\n",
    " 'LOC_STATE']\n",
    "cat_cols_to_dummy_encode = ['EMPL_CLASS','EEO1CODE','EMPL_TYPE','FULL_PART_TIME','ETHNIC_GROUP','DIVISION_CODE_SFI','COMPANY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allcols = em2.columns.tolist()\n",
    "my_cols_to_omit = ['TOT_MO_SERVICE_SFI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_minfix_cols = ['SAL1','MIN_RT_ANNUAL','MERIT1','PERF1']\n",
    "my_maxfix_cols = ['MAX_RT_ANNUAL']\n",
    "missing_zero_cols = ['BOX1','FUNC_CNT','EXTFUNC_CNT','TOTAL_RPT_CNT','DIRECT_RPT_CNT']\n",
    "mode_impute_cols = ['MERIT1','PERF1','ADDRCNT1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([(\"null\",br.RemoveAllNull()),\n",
    "                 (\"drop\",br.DropColumns(columns_to_drop =my_cols_to_omit)),\n",
    "                 (\"label_encode\",br.LabelEncodeColumn(my_label_encode_cols)),\n",
    "                 \n",
    "                 #(\"dummy_encode\", br.DummyEncodeColumn(cat_cols_to_dummy_encode)),\n",
    "                 (\"survival_encode\",SurvivalEncodeColumn(my_label_encode_cols[:5],method='median')),\n",
    "                 (\"dummy_encode\",br.ConvertCategorical(categorical_columns=cat_cols_to_dummy_encode,method='dummy')),\n",
    "                 (\"fixout_min\",br.FixNumericOutlier(columns_to_fix=my_minfix_cols,criteria_coef=('percentile',2),\n",
    "                                                   method='lower',fill_with='nearest_value')),\n",
    "                 (\"fixout_max\",br.FixNumericOutlier(columns_to_fix=['MAX_ANNUAL_RT'],criteria_coef=('percentile',2),\n",
    "                                                   method='both',fill_with='nearest_value')),\n",
    "                 (\"fill_missingzero\",br.FillMissingValue(columns_to_fix=missing_zero_cols,fill_value=0)),\n",
    "                 (\"imp_mode\",br.ImputeData(columns_to_impute=mode_impute_cols,rows_to_scan=0.8))\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pull out a build set to make the pipeline from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Starting with subest of {0} employees.\".format(len(em2))\n",
    "eval_fraction = 0.20\n",
    "em2build, em2eval = train_test_split(em2,test_size=eval_fraction,random_state=83221)\n",
    "print \"Evaluation set has {0} employees; training set has {1} employees.\".format(len(em2eval),len(em2build))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = em2build['former']\n",
    "build = pipe2.fit_transform(em2build,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation = pipe2.fit(em2build,y).transform(em2eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_columns = build.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[a for a in list_of_columns if a.endswith('SFI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build.to_csv('trans_train.csv',index=False)\n",
    "evaluation.to_csv('trans_eval.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(list_of_columns)\n",
    "[a for a in list_of_columns if a in ['former','status','retired']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_for_modeling = [a for a in list_of_columns if a not in ['former','status','retired']]\n",
    "len(columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "br.perfect_collinearity_test(build[columns_for_modeling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tstmp_cols = [a for a in em2.columns if a.endswith('tstmp')]\n",
    "tstmp_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redundant_cols = ['hire_age','FULLPART1','COMPANY','ETHNIC_GROUP',\n",
    "                  'EMPL_TYPE','DIVISION_CODE_SFI','ADDRCNT1_d','PERF1_d','MERIT_d',\n",
    "                  'EMPL_TYPE_E','FULL_PART_TIME_X','COMPANY_1','ETHNIC_GROUP_1.0','DIVISION_CODE_SFI_4',\n",
    "                 'EMPL_CLASS_1','EEO1CODE_6']\n",
    "columns_for_modeling2 = list(set(columns_for_modeling)-set(redundant_cols)-set(tstmp_cols))\n",
    "br.perfect_collinearity_test(build[columns_for_modeling2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(columns_for_modeling2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now build the time-kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the date range\n",
    "full_date_range = [str(a)+'-01-01' for a in np.arange(2002,2016)]\n",
    "print len(full_date_range)\n",
    "#full_date_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize temporal kfolds:\n",
    "1. split the training dataset into windows corresponding to the difference in time\n",
    "2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def create_temporal_kfolds(dates_df,date_range,time_delta):\n",
    "    \"\"\"\n",
    "    inputs: date_range\n",
    "            time_delta (in years)\n",
    "            dataframe_dates --> assumes 'hire_tstmp' and 'term_tstmp'\n",
    "    outputs:\n",
    "            kf is a list of list of list: \n",
    "            [indices from original df that are 'in' a fold, indices from original df that are 'out' of a fold]\n",
    "            each row in this corresponds to the temporal-kfold\n",
    "            filtered_pairs is a list of start and end times\n",
    "    \"\"\"\n",
    "    min_date = pd.to_datetime(date_range[0])\n",
    "    max_date = pd.to_datetime(date_range[-1])\n",
    "    my_index = dates_df[(dates_df.term_tstmp>=min_date)].index\n",
    "    # calculate number of kfolds\n",
    "    date_span_years = np.int(np.round((max_date-min_date).days/365.24,0))\n",
    "    nfolds = date_span_years - time_delta\n",
    "    print date_span_years, time_delta, nfolds, len(my_index)\n",
    "    all_pairs = list(itertools.combinations(date_range,2))\n",
    "    # now filter if difference in time  == time_delta\n",
    "    filtered_pairs = []\n",
    "    for i0,i1 in all_pairs:\n",
    "        if int(i1[:4])-int(i0[:4]) == time_delta:\n",
    "            filtered_pairs.append([i0,i1])\n",
    "            #print i0,i1\n",
    "    print len(filtered_pairs)\n",
    "    # now process each of these filtered pairs\n",
    "    kf = []\n",
    "    for j0,j1 in filtered_pairs: # omit the last one because it has no corresponding partner/endtime\n",
    "        start_date = pd.to_datetime(j0)\n",
    "        end_date = pd.to_datetime(j1)\n",
    "        #print j0,j1#,len(k)\n",
    "        \n",
    "        \n",
    "        kfold_idx = dates_df[(dates_df.term_tstmp >= start_date) & (dates_df.hire_tstmp<start_date)].index.tolist()\n",
    "        after_idx = dates_df[(dates_df.hire_tstmp>=end_date)].index.tolist()\n",
    "        before_idx = list(set(my_index)-set(kfold_idx)-set(after_idx))\n",
    "        #temporal_kfold(dates_df[dates_df.term_tstmp>=min_date],start_date,end_date)\n",
    "        #print \"\\t\",len(kfold_idx), len(after_idx),len(before_idx)\n",
    "        \n",
    "        # combined out of fold\n",
    "        not_kfold_idx = list(set(after_idx).union(set(before_idx)))\n",
    "        \n",
    "        print j0,j1,len(kfold_idx),len(not_kfold_idx)\n",
    "        kf.append([kfold_idx,not_kfold_idx])\n",
    "    \n",
    "    return kf,filtered_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_years2(paired_times,indices,dates_df,cols_to_alter = ['Age_years','Tenure_years']):\n",
    "    # calc the Age at beginnning of time period\n",
    "    ## now calculate age at hire\n",
    "    reset_age_tdelta = pd.to_datetime(paired_times[0])-dates_df['birth_tstmp']#)/np.timedelta64(1,'D')\n",
    "    reset_tenure_tdelta = pd.to_datetime(paired_times[0])-dates_df['hire_tstmp']#)/np.timedelta64(1,'D')\n",
    "    # convert to days, months or years\n",
    "    reset_age = reset_age_tdelta/np.timedelta64(1,'Y')\n",
    "    reset_tenure = reset_tenure_tdelta/np.timedelta64(1,'Y')\n",
    "    # look at terminated or not\n",
    "    #empl_df['terminated']= 0\n",
    "    # push these as a data frame so I can merge\n",
    "    adj_times = pd.DataFrame()\n",
    "    adj_times['adj_age']=reset_age\n",
    "    adj_times['adj_tenure']=reset_tenure      \n",
    "    return adj_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_target_within_x_years(df,paired_dates,tfold,n_years,target_col):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        df -- data frame\n",
    "        paired_dates (2nd output from create_temporal_kfolds)\n",
    "        tfold (1st output from create_temporal_kfolds)\n",
    "        targe_col --> desired target\n",
    "        \n",
    "    plan is to adjust the target, Age and tenure to match time frame of temporal kfold\n",
    "    outputs:\n",
    "    \"\"\"\n",
    "    print len(tfold)#, paired_dates\n",
    "\n",
    "    df_dict = {}\n",
    "    for i,tf in enumerate(tfold):\n",
    "        start_date = paired_dates[i][0]\n",
    "        end_date = paired_dates[i][1]\n",
    "        #print start_date,end_date,n_years\n",
    "        #altered_fold_df = pd.DataFrame(columns=['fold_mbr','adj_age','adj_tenure','adj_term'])\n",
    "        # if in the fold reset the age to start of fold; define new window of termination\n",
    "        in_fold_idx = tfold[i][0] # the index of the in_fold_observations \n",
    "        # note that \"sex\" is just used to create a value that then gets dummied out\n",
    "        cols_to_copy = ['SEX','Age_years','Tenure_years']\n",
    "        cols_to_copy.append(target_col)\n",
    "        \n",
    "        altered_fold_df = df[cols_to_copy].copy()\n",
    "        # adjust these\n",
    "        altered_fold_df.columns=['fold_mbr','adj_age','adj_tenure','adj_tgt']\n",
    "        altered_fold_df.fold_mbr = 0\n",
    "        \n",
    "        #ra,rt = reset_years(paired_dates[i],in_fold_idx,dates_df)\n",
    "        adj_df =reset_years2(paired_dates[i],in_fold_idx,df)\n",
    "        #altered_fold_df.ix[in_fold_idx]['adj_age']=ra\n",
    "        #altered_fold_df.ix[in_fold_idx]['adj_tenure']=rt\n",
    "        altered_fold_df.loc[in_fold_idx,['adj_age','adj_tenure']]=adj_df.ix[in_fold_idx] # assign to the altered values\n",
    "        new_tgt = (df.ix[in_fold_idx]['term_tstmp']<= end_date).as_matrix().astype(np.int)\n",
    "        #(em2mod.ix[kf[0][0]]['term_tstmp']<= fp[0][1]).as_matrix().astype(np.int)\n",
    "        # deal with last time-fold specially\n",
    "        if i == len(tfold)-1:\n",
    "            new_tgt = (df.ix[in_fold_idx]['term_tstmp']< end_date).as_matrix().astype(np.int)\n",
    "        #print \"\\t\", len(new_term),sum(new_term)\n",
    "        altered_fold_df.loc[in_fold_idx,'adj_tgt']=new_tgt\n",
    "        altered_fold_df.loc[in_fold_idx,'fold_mbr']=1\n",
    "        df_dict[i]=altered_fold_df\n",
    "    # now append this to a larger panel\n",
    "    tfold_panel = pd.Panel.from_dict(data =df_dict)\n",
    "    return tfold_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_tfolds(df, n_years, cols_to_model, tgt_value='former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = tstmp_cols, date_range=full_date_range):\n",
    "    \"\"\" Function to create the temporal kfolds\n",
    "    parameters:\n",
    "        df       - a pandas data frame (that has been preprocessed)\n",
    "        n_years  - size of the temporal window (in years)\n",
    "        cols_to_model - list of columns to use in the modeling procedure \n",
    "        tgt_value  - column name to use as the target variable\n",
    "        time_cols  - list of columns that are time senitive and must be adjusted\n",
    "        tstmp_cols - list of columns that contain timestamps for things like hiring, termination and birth\n",
    "        date_range - list comprising the inclusive annual starting dates from beginning to end of range.\n",
    "    output:\n",
    "        tfolds  - a list containing the indices of in and out of fold members for each of the tfolds created\n",
    "        tfold_panel - a pandas Panel (3D data frame) containing the membership in different folds, the adjusted targets,\n",
    "            the adjusted timesenitive data, and the columns to use for modeling.\n",
    "    \"\"\"    \n",
    "    # step 1 create the temporal_folds\n",
    "    if not [a for a in tstmp_cols if a in df.columns] == tstmp_cols:\n",
    "        print \"The list of required timestamp columns do not exist in the input dataframe.\"\n",
    "        print tstmp_cols\n",
    "        exit\n",
    "    tfolds, paired_dates = create_temporal_kfolds(df[tstmp_cols],date_range, n_years) \n",
    "    #defines the time-windows and assigns observations to folds\n",
    "    \n",
    "    # create the time-shifted tfolds and push into a pandas Panel (3D data frame)\n",
    "    tfold_panel=transform_df_to_tfold(df,tfolds,paired_dates,n_years,cols_to_model, tgt_value,tstmp_cols,time_cols)\n",
    "    return tfold_panel, tfolds\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_df_to_tfold(df,tfold,paired_dates,n_years,cols_to_keep,target_col,tstmp_cols,time_cols):\n",
    "    \"\"\"\n",
    "    Function to adjust the input data frame so that time_sensitive columns and target column\n",
    "    conform to the bounds of that temporal kfold (tfold). Specifically adjust the target, Age and tenure \n",
    "    to match time frame of temporal kfold\n",
    "    \n",
    "    Parameters:\n",
    "        df -- a pandas data frame\n",
    "        paired_dates (2nd output from create_temporal_kfolds)\n",
    "        tfolds (1st output from create_temporal_kfolds)\n",
    "        target_col --> desired target\n",
    "        cols_to_keep --> the list of columns within df that get expressed in df.\n",
    "        time_cols\n",
    "        \n",
    "    plan is to \n",
    "    outputs:\n",
    "        tfold_panel\n",
    "    \"\"\"\n",
    "    #print len(tfold)#, paired_dates\n",
    "    #print df.columns ,len(df.columns), len(cols_to_keep)\n",
    "    #return\n",
    "    # do some sanity checks\n",
    "    # 1. make sure cols_to_keep, target and tstmp_cols columns are in df.columns\n",
    "    input_column_list = df.columns.tolist()\n",
    "    n_total_columns = len(input_column_list)\n",
    "    #if (n_total_columns != len(cols_to_keep)+len(target_col)+len(tstmp_cols)):\n",
    "        # now look at each piece\n",
    "    targetlist = []\n",
    "    targetlist.append(target_col)\n",
    "    if not check_if_subset(targetlist,input_column_list):\n",
    "            #target_col in df.columns:\n",
    "            #print \"{0} target column not present in input set\".format(target_col)\n",
    "        return\n",
    "    if not check_if_subset(tstmp_cols,input_column_list):\n",
    "        return\n",
    "            #[a for a in tstmp_cols if a in input_column_list] == tstmp_cols: # requires\n",
    "            #print \"There are missing timestamp columns. Recheck the list {0}\".format(tstmp_cols)\n",
    "    #        return\n",
    "    if not check_if_subset(time_cols,input_column_list):\n",
    "            #[a for a in time_cols if a in input_column_list] == time_cols: # requires\n",
    "            #print \"There are missing timestamp columns. Recheck the list {0}\".format(tstmp_cols)\n",
    "        return    \n",
    "    if not check_if_subset(cols_to_keep,input_column_list):\n",
    "        return\n",
    "    \n",
    "    ## now set up the columns for manipulation\n",
    "    cols_to_copy = cols_to_keep\n",
    "    if not check_if_subset(time_cols,cols_to_keep):\n",
    "        cols_to_copy+=time_cols\n",
    "        print len(cols_to_copy)\n",
    "    \n",
    "    \n",
    "    df_dict = {}\n",
    "    \n",
    "    # identify which element of tstmp_cols corresponds to term_tstmp\n",
    "    term_id = tstmp_cols.index('term_tstmp')\n",
    "    birth_id = tstmp_cols.index('birth_tstmp')\n",
    "    hire_id = tstmp_cols.index('hire_tstmp')\n",
    "    #print term_id, tstmp_cols[term_id]\n",
    "    \n",
    "    for i,tf in enumerate(tfold):\n",
    "        start_date = paired_dates[i][0]\n",
    "        end_date = paired_dates[i][1]\n",
    "        \n",
    "        in_fold_idx = tfold[i][0] # the index of the in_fold_observations \n",
    "       \n",
    "        altered_fold_df = df[cols_to_copy].copy()\n",
    "        altered_fold_df['fold_mbr']=0 # create a new column to identify membership in that fold.\n",
    "        altered_fold_df.loc[in_fold_idx,'fold_mbr']=1 # assign the in_fold_indices to that fold membership\n",
    "        ####\n",
    "        # adjust the age and tenure for those in the fold\n",
    "        reset_age_tdelta = pd.to_datetime(start_date)-df.ix[in_fold_idx][tstmp_cols[birth_id]]\n",
    "        reset_age = reset_age_tdelta/np.timedelta64(1,'Y')\n",
    "        reset_tenure_tdelta = pd.to_datetime(start_date)-df.ix[in_fold_idx][tstmp_cols[hire_id]]\n",
    "        reset_tenure = reset_tenure_tdelta/np.timedelta64(1,'Y')\n",
    "        altered_fold_df.loc[in_fold_idx,'Age_years']=reset_age\n",
    "        altered_fold_df.loc[in_fold_idx,'Tenure_years']=reset_tenure\n",
    "        old_tgt = df.ix[tfold[i][1]][target_col]\n",
    "        new_tgt = (df.ix[in_fold_idx][tstmp_cols[term_id]]<= end_date).as_matrix().astype(np.int)\n",
    "        # deal with last time-fold specially\n",
    "        if i == len(tfold)-1:\n",
    "            new_tgt = (df.ix[in_fold_idx][tstmp_cols[term_id]]< end_date).as_matrix().astype(np.int)\n",
    "            \n",
    "        altered_fold_df.loc[in_fold_idx,target_col]=new_tgt\n",
    "        old_tgt = df.ix[tfold[i][1]][target_col]\n",
    "        altered_fold_df.loc[tfold[i][1],target_col] = old_tgt\n",
    "        #ra,rt = reset_years(paired_dates[i],in_fold_idx,dates_df)\n",
    "        \"\"\"adj_df =reset_years2(paired_dates[i],in_fold_idx,df)\n",
    "        #altered_fold_df.ix[in_fold_idx]['adj_age']=ra\n",
    "        #altered_fold_df.ix[in_fold_idx]['adj_tenure']=rt\n",
    "        altered_fold_df.loc[in_fold_idx,time_cols]=adj_df.ix[in_fold_idx] # assign to the altered values\n",
    "        \n",
    "        #(em2mod.ix[kf[0][0]]['term_tstmp']<= fp[0][1]).as_matrix().astype(np.int)\n",
    "        \n",
    "        #print \"\\t\", len(new_term),sum(new_term)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        df_dict[i]=altered_fold_df\n",
    "    # now append this to a larger panel\n",
    "    tfold_panel = pd.Panel.from_dict(data =df_dict)\n",
    "    return tfold_panel\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_tKfold_CV2(modeltype, in_panel, tkfolds, cols_to_use, tgt_column = 'former', ntrees=100):\n",
    "    \"\"\" Calculate the rmse for each cross-validated temporalFold\n",
    "    \n",
    "    Parameters:\n",
    "        model - a scikit learn model name\n",
    "        in_panel  - a pandas Panel with the observed input data adjusted \n",
    "        tgt_column -- the target variable\n",
    "        cols_to_use -- the input variables to be used in modeling\n",
    "        tkfolds -- teh temporal timefolds (list of dimension 2)\n",
    "    outputs:\n",
    "        models --> the list of fit models\n",
    "        RMSE --> the rmse error\n",
    "        \n",
    "    \"\"\"\n",
    "    RMSE = []\n",
    "    roc_auc = []\n",
    "    models = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for fold_id, indices in enumerate(tkfolds):\n",
    "        training = indices[0]\n",
    "        testing = indices[1]\n",
    "        #print fold_id, len(training),len(testing)\n",
    "        X_train, X_test = in_panel[fold_id][cols_to_use].ix[training].as_matrix(), in_panel[fold_id][cols_to_use].ix[testing].as_matrix()\n",
    "        y_train, y_test = in_panel[fold_id][tgt_column].ix[training].as_matrix(), in_panel[fold_id][tgt_column].ix[testing].as_matrix()\n",
    "        if modeltype == 'rfc':\n",
    "            model = ensemble.RandomForestClassifier(n_estimators=ntrees, max_features='auto', oob_score=True)\n",
    "        elif modeltype=='bgc':\n",
    "            model=ensemble.GradientBoostingClassifier(n_estimators=ntrees,max_features='auto')\n",
    "        else:\n",
    "            model=tree.DecisionTreeClassifier()\n",
    "            \n",
    "        # Train the model\n",
    "        model.fit(X_train,y_train)\n",
    "        # use the model to predict output\n",
    "        y_fitted = model.predict(X_test)\n",
    "        RMSE.append(np.sqrt(metrics.mean_squared_error(y_test,y_fitted)))\n",
    "        roc_auc.append(metrics.roc_auc_score(y_test,y_fitted))\n",
    "        models.append(model)\n",
    "    # leave the model fit to the entire dataset\n",
    "    #model.fit(in_x,in_y)\n",
    "    \n",
    "    return RMSE,roc_auc,models\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_if_subset(list1,list2): #compare_column_lists(list1,list2):\n",
    "    if set(list1).issubset(set(list2)):\n",
    "        return 1\n",
    "    else:\n",
    "        print \"{0} is not contained in {1}. Recheck your lists.\".format(list1,list2)\n",
    "        return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reintroduce the tstmp columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build[tstmp_cols]=em2build[tstmp_cols].apply(lambda x:  pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel4, tfold4 = setup_tfolds(build, 4, columns_for_modeling2, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols=tstmp_cols, date_range=full_date_range)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now  apply gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble, tree, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse4,roc_auc4,gbmdl4 = apply_tKfold_CV2('gbc',panel4, tfold4,  cols_to_use = columns_for_modeling2, tgt_column='former',ntrees=500)#['columns_for_modeling'],em2mod['former'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbc_eval_pred4class, gbc_eval_pred4proba = evaluate_models(gbmdl4,X4eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y4eval,gbc_eval_pred4proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y4eval,map(np.int,gbc_eval_pred4class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build rf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse4rf,roc_auc4rf,rfmdl4 = apply_tKfold_CV2('rfc',panel4, tfold4,  cols_to_use = columns_for_modeling2, tgt_column='former',ntrees=100)#['columns_for_modeling'],em2mod['former'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_eval_pred4class, rfc_eval_pred4proba = evaluate_models(rfmdl4,X4eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluation[tstmp_cols]=em2eval[tstmp_cols].apply(lambda x: pd.to_datetime(x)) # append the tstmp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4eval, y4eval =adjust_eval_by_x_years(evaluation,4,columns_for_modeling2)#,tstmp_cols=default_tstmps,target_col='former')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse4, rmse4rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc4, roc_auc4rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y4eval,np.vstack([gbc_eval_pred4class.mean(axis=1), gbc_eval_pred4class.mean(axis=1)]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y4eval,rfc_eval_pred4proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#REPEAT for retirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel4, Rtfold4 = setup_tfolds(evaluation,4, columns_for_modeling2, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "Rrmse4,Rroc_auc4,Rrfmdl4 = apply_tKfold_CV2('rfc',Rpanel4, Rtfold4, cols_to_use = columns_for_modeling2, tgt_column='retired')#['columns_for_modeling'],em2mod['former'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#float(\n",
    "((today - evaluation[default_tstmps[2]].iloc[0]).days)/365.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RX4eval, Ry4eval = adjust_eval_by_x_yearsR(evaluation,4,columns_for_modeling2, today,target_col = 'retired')\n",
    "Reval_pred4class,Reval_pred4proba = evaluate_models(Rrfmdl4,RX4eval)\n",
    "plot_roc_curve(Ry4eval,Reval_pred4proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retry retirements using undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from unbalanced_dataset import UnderSampler, NearMiss, CondensedNearestNeighbour, OneSidedSelection,\\\n",
    "NeighbourhoodCleaningRule, TomekLinks, ClusterCentroids\n",
    "#OverSampler, SMOTE,\\\n",
    "#SMOTETomek, SMOTEENN, EasyEnsemble, BalanceCascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count the initial classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Random under-sampling'\n",
    "US = UnderSampler(ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rpanel4, Rtfold4 = setup_tfolds(evaluation,4, columns_for_modeling2, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(Rpanel4)\n",
    "len(Rpanel4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel4[0].retired.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel_cols = Rpanel4[0].columns.tolist()\n",
    "Rpanel_cols.remove('retired')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usx,usy = US.fit_transform(Rpanel4[0][Rpanel_cols].values, Rpanel4[0]['retired'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usRpanel4[0] = pd.DataFrame(data=usx,columns=Rpanel_cols)\n",
    "usRpanel4[0]['retired']= usy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(0,len(Rtfold4)):\n",
    "    print i, len(Rtfold4[i][0]), len(Rtfold4[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel4[0].ix[Rtfold4[0][1]].retired.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_tKfold_CV2_unBalanced(modeltype, in_panel, tkfolds, cols_to_use, unbalance_mtd='random', tgt_column = 'former', ntrees=100):\n",
    "    \"\"\" Calculate the rmse for each cross-validated temporalFold\n",
    "    \n",
    "    Parameters:\n",
    "        model - a scikit learn model name\n",
    "        in_panel  - a pandas Panel with the observed input data adjusted \n",
    "        tgt_column -- the target variable\n",
    "        cols_to_use -- the input variables to be used in modeling\n",
    "        tkfolds -- the temporal timefolds (list of dimension 2)\n",
    "        unbalance_mtd -- a method of how to deal with imbalanced classes\n",
    "    outputs:\n",
    "        models --> the list of fit models\n",
    "        RMSE --> the rmse error\n",
    "        \n",
    "    \"\"\"\n",
    "    RMSE = []\n",
    "    roc_auc = []\n",
    "    models = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for fold_id, indices in enumerate(tkfolds):\n",
    "        training = indices[0]\n",
    "        testing = indices[1]\n",
    "        \n",
    "        # 'Random under-sampling'\n",
    "        if unbalance_mtd == 'random':\n",
    "            sampler = UnderSampler(ratio=2)\n",
    "        else:\n",
    "            sampler = NearMiss(version=3)\n",
    "\n",
    "        \n",
    "        #print fold_id, len(training),len(testing)\n",
    "        X_train, X_test = in_panel[fold_id][cols_to_use].ix[training].as_matrix(), in_panel[fold_id][cols_to_use].ix[testing].as_matrix()\n",
    "        y_train, y_test = in_panel[fold_id][tgt_column].ix[training].as_matrix(), in_panel[fold_id][tgt_column].ix[testing].as_matrix()\n",
    "        usXtrain, usytrain = sampler.fit_transform(X_train,y_train)\n",
    "        \n",
    "        if modeltype == 'rfc':\n",
    "            model = ensemble.RandomForestClassifier(n_estimators=ntrees, max_features='auto', oob_score=True)\n",
    "        elif modeltype=='bgc':\n",
    "            model=ensemble.GradientBoostingClassifier(n_estimators=ntrees,max_features='auto')\n",
    "        else:\n",
    "            model=tree.DecisionTreeClassifier()\n",
    "            \n",
    "        # Train the model\n",
    "        print len(usXtrain)\n",
    "        model.fit(usXtrain,usytrain)\n",
    "        \n",
    "        # use the model to predict output\n",
    "        y_fitted = model.predict(X_test)\n",
    "        RMSE.append(np.sqrt(metrics.mean_squared_error(y_test,y_fitted)))\n",
    "        roc_auc.append(metrics.roc_auc_score(y_test,y_fitted))\n",
    "        models.append(model)\n",
    "    # leave the model fit to the entire dataset\n",
    "    #model.fit(in_x,in_y)\n",
    "    \n",
    "    return RMSE,roc_auc,models\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uRrmse4,uRroc_auc4,uRrfmdl4 = apply_tKfold_CV2_unBalanced('rfc',Rpanel4, Rtfold4, cols_to_use = columns_for_modeling2, tgt_column='retired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.scatter(uRroc_auc4, Rroc_auc4)\n",
    "plt.plot(uRroc_auc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_models(model_list,Xeval):\n",
    "    eval_pred_class = np.zeros((len(Xeval),len(model_list)))\n",
    "    eval_pred_proba = np.zeros((len(Xeval),2,len(model_list)))\n",
    "\n",
    "    for i,mdl in enumerate(model_list):\n",
    "        eval_proba = mdl.predict_proba(Xeval)\n",
    "        eval_pred_class[:,i]=mdl.predict(Xeval)\n",
    "        eval_pred_proba[:,:,i]=eval_proba\n",
    "    #print np.shape(eval_prediction_proba3)\n",
    "    return eval_pred_class, eval_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in xrange(0,len(uRrfmdl4)):\n",
    "    plot_roc_curve(Ry4eval,uReval_pred4proba[:,:,a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(Ry4eval,uReval_pred4proba[:,:,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uReval_pred4class,uReval_pred4proba = evaluate_models(uRrfmdl4,RX4eval)\n",
    "plot_roc_curve(Ry4eval,uReval_pred4proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(uReval_pred4proba[:,0,9])\n",
    "#len(uReval_pred4class)\n",
    "uReval_pred4class[:,8].sum(), Ry4eval.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uReval_pred4proba[:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(Ry4eval,uReval_pred4class[:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(Ry4eval,'o')\n",
    "#plt.plot(uReval_pred4class[:,2],'d')\n",
    "#plt.scatter(Ry4eval,Ry4eval-uReval_pred4class[:,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#zip(columns_for_modeling2, gbmdl4[0].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[columns_for_modeling2[a] for a in list(np.where(gbmdl4[1].feature_importances_ > 0.1)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(0,len(gbmdl4)):\n",
    "    plt.plot(gbmdl4[i].feature_importances_)\n",
    "    \n",
    "#plt.plot(gbmdl4[1].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X5eval, y5eval = adjust_eval_by_x_years(evaluate,5,columns_for_modeling2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2[em2.retired==1].Age_years.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2[em2.retired==1].Age_years.hist(bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(em2[(em2.retired == 1) & (em2.Age_years < 55)]), len(em2[em2.retired == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2[(em2.retired == 1) & (em2.Age_years < 55)].Age_years.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the over50 set\n",
    "over50.to_csv('over50.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "over50.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# repeat the split\n",
    "\n",
    "# break into evaluation and build sets\n",
    "print \"Starting with subset of {0} employees.\".format(len(over50))\n",
    "eval_fraction = 0.20\n",
    "o50build, o50eval = cross_validation.train_test_split(over50,test_size=eval_fraction,random_state = 84)\n",
    "print \"Evaluation set has {0} employees; training set has {1} employees.\".format(len(o50eval),len(o50build))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print over50.retired.value_counts()\n",
    "print \"----\"\n",
    "print o50eval.retired.value_counts()\n",
    "print \"----\"\n",
    "print o50build.retired.value_counts()\n",
    "print \"----\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50build['JOBCODE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50build.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retire_surv_cols1 = ['retired','Age_years','hire_age','SEX','FTE','HAVE_INS','HAVE_DEP']\n",
    "cf.fit(o50build[retire_surv_cols1], 'Age_years', event_col='retired')\n",
    "\n",
    "cf.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.hazards_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.baseline_cumulative_hazard_.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first10pred = cf.predict_survival_function(o50eval[retire_surv_cols1[2:]].iloc[:10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_pred = cf.predict_survival_function(o50eval[retire_surv_cols1[2:]].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first10pred[1].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval[retire_surv_cols1[:2]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[first10pred[first10pred[a]<0.5].index[0] for a in xrange(0,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lifelines import AalenAdditiveFitter\n",
    "aaf = AalenAdditiveFitter(coef_penalizer=1.0, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.fit(o50build[retire_surv_cols1], 'Age_years', event_col='retired')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.plot( columns=[ 'hire_age', 'baseline', 'SEX','FTE' ],ix=slice(53,70)) # cumulative hazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.cumulative_hazards_.ix[:70].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.predict_survival_function(o50eval[retire_surv_cols1[2:]].iloc[:3].values).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.predict_survival_function(o50eval[retire_surv_cols1[2:]].iloc[:10].values).ix[:70].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to apply this\n",
    "1. take current age, add 1 yr, 2, yr, 3, yr, ,4yr, 5yr and report prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval[retire_surv_cols1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ages_to_check = o50eval['Age_years'].apply(lambda x: x+[1.0,2.0,3.0,4.0,5.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sf1 = aaf.predict_survival_function(o50eval[retire_surv_cols1[2:]].values)\n",
    "# columns are the indiviuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sf1.index.name='years'\n",
    "pred_sf1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_pred = cf.predict_survival_function(o50eval[retire_surv_cols1[2:]].values)\n",
    "cf_pred.index.name='years'\n",
    "cf_pred.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pred_sf1.T), len(o50eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cfRetProb.head(), retireProb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retireProb_df = get_survival_prediction(o50eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_o50eval=pd.concat([o50eval[retire_surv_cols1],retireProb_df],axis=1)\n",
    "pred_o50eval_cf = pd.concat([o50eval[retire_surv_cols1],cfRetProb],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_o50eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try to assess current age for retired or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval_curr.Age_years.hist()#tail()#proba_0.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval_curr[o50eval_curr.retired==1].proba_0.hist(bins=30,label='retired',normed=True,alpha=0.8)\n",
    "print sum(o50eval_curr.retired==1), sum(o50eval_curr.retired==0)\n",
    "o50eval_curr[o50eval_curr.retired==0].proba_0.hist(bins=30,label='active',normed=True,alpha=0.3)\n",
    "plt.legend()\n",
    "plt.xlabel('Retirement Probability')\n",
    "plt.ylabel('Normed Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CFcurr_retire_age = get_survival_prediction(o50eval,psf=cf_pred,yr_vals=[0])\n",
    "o50eval_curr_cf = pd.concat([o50eval[retire_surv_cols1],CFcurr_retire_age],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## assess the model\n",
    "* define a cutoff in probability and do a count/assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(df,true_col = 'retired', p_col = 'proba_0',thresh=0.5):\n",
    "    ckdf = (df[p_col]>thresh).astype('int')\n",
    "    true_pos = df[ckdf==1][true_col].sum()\n",
    "    false_pos= len(df[ckdf==1])-true_pos\n",
    "    \n",
    "    false_neg=df[ckdf==0][true_col].sum()\n",
    "    true_neg =len(df[ckdf==0]) - false_neg\n",
    "    print \"threshold = {0}\".format(thresh)\n",
    "    print \"TP\\t FP\\t FN\\t TN\"\n",
    "    print true_pos, '\\t',false_pos,'\\t' ,false_neg,'\\t', true_neg\n",
    "    acc = (true_pos + true_neg)/float(len(df))\n",
    "    print \"Accuracy is {0:.3f}\".format(acc)\n",
    "    mcc = (true_pos*true_neg - false_pos*false_neg)/np.sqrt((true_pos+false_pos)*(true_pos+false_neg)*(true_neg+false_pos)*(true_neg+false_neg))\n",
    "    print \"Matthews correlation coefficient is {0:.3f}\".format(mcc)\n",
    "    tpr = true_pos/float(true_pos+false_neg)\n",
    "    fpr = false_pos/float(false_pos + true_neg)\n",
    "    return tpr,fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_accuracy(o50eval_curr,thresh=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_vals = []\n",
    "tvals = np.linspace(0,1,21)#,0.05)#:#xrange(0,1,0.05):\n",
    "for t in tvals:\n",
    "    roc_vals.append(get_accuracy(o50eval_curr,thresh=t))\n",
    "\n",
    "    \n",
    "roc_vals = np.array(roc_vals)\n",
    "#    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_vals = np.array(roc_vals)\n",
    "plt.plot(roc_vals[:,0],roc_vals[:,1])\n",
    "plt.plot(tvals,tvals,color='k',ls='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.auc(roc_vals[:,0],roc_vals[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_vals_cf = []\n",
    "tvals = np.linspace(0,1,21)#,0.05)#:#xrange(0,1,0.05):\n",
    "for t in tvals:\n",
    "    roc_vals_cf.append(get_accuracy(o50eval_curr_cf,thresh=t))\n",
    "\n",
    "    \n",
    "roc_vals_cf = np.array(roc_vals_cf)\n",
    "\n",
    "plt.plot(roc_vals_cf[:,1],roc_vals_cf[:,0])\n",
    "plt.plot(tvals,tvals,color='k',ls='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('CoxPH Fitter of eval set')\n",
    "print metrics.auc(roc_vals_cf[:,0],roc_vals_cf[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(roc_vals_cf[:,0],roc_vals_cf[:,1])\n",
    "plt.plot(roc_vals[:,1],roc_vals[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c02 = (o50eval_curr.proba_0 > 0.2).astype('int')\n",
    "sum(c02 == o50eval_curr.retired), len(o50eval_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval_curr[c02==1].retired.sum(), len(o50eval_curr[c02==1]), o50eval_cur[c02==0].retired.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval[retire_surv_cols1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_med_survAge = cf.predict(o50eval[retire_surv_cols1[2:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_med_survAge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.predict_expectation(o50eval[retire_surv_cols1[2:]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply this model to all current to get workforce retirement predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_current = aaf.predict_survival_function(all_current[retire_surv_cols1[2:]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_current.head()\n",
    "pred_current.index.name='years'\n",
    "pred_current.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_current[['years',0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_current[retire_surv_cols1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_current[retire_surv_cols1].ix[65080:65093]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "current_retireProb_df = get_survival_prediction(all_current[retire_surv_cols1],psf=pred_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_retireProb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create a set that is under 50 for separation modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "under50 = em2[em2.Age_years <= 50].copy()\n",
    "print len(under50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "under50.HAVE_DEP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_surv_cols1=['former','Tenure_years','hire_age','SEX','FTE','HAVE_INS','HAVE_DEP','SAL1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# break into evaluation and build sets\n",
    "print \"Starting with subset of {0} employees.\".format(len(under50))\n",
    "eval_fraction = 0.20\n",
    "u50build, u50eval = cross_validation.train_test_split(under50,test_size=eval_fraction,random_state = 84554)\n",
    "print \"Evaluation set has {0} employees; training set has {1} employees.\".format(len(u50eval),len(u50build))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "br.perfect_collinearity_test(u50build[sep_surv_cols1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.fit(u50build[sep_surv_cols1], 'Tenure_years', event_col='former')\n",
    "\n",
    "cf.print_summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.hazards_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep_cf_pred = cf.predict_survival_function(u50eval[sep_surv_cols1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Now transform this panel into an h2o Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(panel4), len(tfold4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one off \n",
    "* for each mdl in len(panel4):\n",
    "    * train = panel4[mdl].ix[tfold4[mdl][0]]\n",
    "    * test = panel4[mdl].ix[tfold4[mdl][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_train_df = panel4[0].ix[tfold4[0][0]]\n",
    "my_test_df =  panel4[0].ix[tfold4[0][1]]\n",
    "#train4_0 = h2o.H2OFrame(panel4[0][columns_for_modeling2].ix[tfold4[0][0]])\n",
    "#y4_0 = h2o.H2OFrame(python_obj=panel4[0]['former'].ix[tfold4[0][0]])\n",
    "my_train_df.shape, my_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_train_df[].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o_cols = my_train_df.columns.tolist()\n",
    "h2o_cols.remove('fold_mbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir tmp\n",
    "os.chdir('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_train_df[h2o_cols].to_csv('my_train.csv',index=False)\n",
    "my_test_df[h2o_cols].to_csv('my_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dictionary does not preserve the colum order/data\n",
    "#train4_0 = h2o.H2OFrame(python_obj = my_train_df[h2o_cols].to_dict())\n",
    "#test4_0 = h2o.H2OFrame(python_obj = my_test_df[h2o_cols].to_dict())\n",
    "train4_0 = h2o.H2OFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -put *.csv /user/kesj/ajH2O_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train4_0 = h2o.import_file(path = 'hdfs://nameservice1/user/kesj/ajH2O_3/my_train.csv')\n",
    "test4_0 = h2o.import_file(path = 'hdfs://nameservice1/user/kesj/ajH2O_3/my_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o_gbm_mdl_0 = h2o.gbm(y = \"former\", x = columns_for_modeling2, training_frame = train4_0, validation_frame = test4_0, ntrees = 500 , max_depth = 4, learn_rate=0.1,distribution=\"AUTO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o_gbm_mdl_0.deepfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_0_vi = pd.DataFrame(data =h2o_gbm_mdl_0.varimp(return_list=True),columns=['variable','relative_importance','scaled_importance','percentage'])\n",
    "gbm_0_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_0_vi.percentage.cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict on the hold out set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_tstmps = ['birth_tstmp','hire_tstmp','term_tstmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adjust_eval_by_x_years(df,year_val,modeling_columns,tstmp_cols=default_tstmps,target_col='former'):\n",
    "    # construct\n",
    "  \n",
    "    ## set up method to assess the eval set\n",
    "    print \"There are {0} elements in the evaluation set\".format(len(df))\n",
    "   \n",
    "    print \"original target variable value counts:\", df[target_col].value_counts()\n",
    "    # restructure to deal with time_frame retirement (target variable)\n",
    "    yr_cut_val = year_val+0.5\n",
    "    # index of those that actually accomplish target within timeframe (allow 0.5 additional years)\n",
    "    eval_within_time_target_index = df[(df[target_col]==1) & (df.Tenure_years <= yr_cut_val)].index\n",
    "    # exclude indices that are active and have tenure less than this time\n",
    "    eval_excluded_index = df[(df[target_col]==0) & (df.Tenure_years  <= yr_cut_val)].index\n",
    "    \n",
    "    # the rest become my not-terminated set\n",
    "    eval_active_index = set(df.index) - set(eval_within_time_target_index) - set(eval_excluded_index)\n",
    "    print len(eval_excluded_index),len(eval_within_time_target_index), len(eval_active_index)\n",
    "    eval_idx_to_use =df.ix[set(df.index)-set(eval_excluded_index)].index\n",
    "    #len(eval_idx_to_use)\n",
    "    # reset the target to 0 for active\n",
    "    eval_new_target = df[target_col].copy()\n",
    "    eval_new_target.ix[eval_active_index] = 0\n",
    "    print \"new target variable value counts: \"\n",
    "    print eval_new_target.ix[eval_idx_to_use].value_counts()\n",
    "    print \"_____\"\n",
    "    y_eval = eval_new_target.ix[eval_idx_to_use].as_matrix().astype(np.int) # true values\n",
    "    eval_adj_tenure = df.ix[eval_idx_to_use].Tenure_years.apply(lambda x: x-year_val if (x>float(year_val)) else 0).values\n",
    "    print len(eval_adj_tenure), len(y_eval)\n",
    "    # now adjust age by length of time; use hire_age if not in set to use.\n",
    "    eval_adj_age = df.ix[eval_idx_to_use].Age_years.apply(lambda x: x-year_val)\n",
    "    hire_age = (df.ix[eval_within_time_target_index]['birth_tstmp']-df.ix[eval_within_time_target_index]['hire_tstmp'])/np.timedelta64(1,'Y')#.days/days_in_year\n",
    "    eval_adj_age.ix[eval_within_time_target_index] = hire_age #df.ix[eval_within_time_target_index]['birth_tstmp'#df_dates['hire_age']\n",
    "    \n",
    "    # construct the evaluation X matrix\n",
    "    print \"input matrix has {0} features\".format(len(modeling_columns))\n",
    "    Xeval = np.zeros((len(eval_idx_to_use),len(modeling_columns)))\n",
    "    # drop 'Age_years' and Tenure_years from the list\n",
    "    cols_to_use = []\n",
    "    cols_to_use+=modeling_columns\n",
    "    cols_to_use.remove('Age_years')\n",
    "    cols_to_use.remove('Tenure_years')#.copy()\n",
    "    \"\"\"\n",
    "    Xeval[:,:-2] = df.ix[eval_idx_to_use][cols_to_use].as_matrix().astype(np.float)\n",
    "    # now put the adjusted tenure and ages into this matrix\n",
    "    Xeval[:,-2] = eval_adj_age.values\n",
    "    Xeval[:,-1]=eval_adj_tenure\n",
    "    #print len(modeling_columns),np.shape(Xeval)\n",
    "    \"\"\"\n",
    "    # this version matches the changed ording of columns\n",
    "    Xeval[:,0]=eval_adj_age.values\n",
    "    Xeval[:,1]=eval_adj_tenure\n",
    "    Xeval[:,2:] = df.ix[eval_idx_to_use][cols_to_use].as_matrix().astype(np.float)\n",
    "    return Xeval, y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_dict = {}\n",
    "for idx,feature in enumerate(columns_for_modeling2):\n",
    "    print idx, feature\n",
    "    eval_dict[feature]=list(X4eval[:,idx])\n",
    "    \n",
    "eval_dict['former']=list(y4eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval4_frame = h2o.H2OFrame(python_obj=eval_dict)\n",
    "\n",
    "#h2o_gbm_mdl_0.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval4_frame.as_data_frame().to_csv('eval_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "['former' in eval4_frame.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred4_0 = h2o_gbm_mdl_0.predict(eval4_frame).as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred4_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(pred4_0.predict.values,y4eval,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred4_0.predict.apply(lambda x: np.int(x+0.6)).sum(), sum(y4eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.vstack([pred4_0.predict.values, pred4_0.predict.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y4eval,np.vstack([pred4_0.predict.values, pred4_0.predict.values]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o.save_model(h2o_gbm_mdl_0,path='hdfs://nameservice1/user/kesj/ajH2O_3/p4_0/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let me retry with an actual ENUM for the predictor/response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train4_0['former'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train4_0['former'] =train4_0['former'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o_gbm_mdl_b0 = h2o.gbm(y = \"former\", x = columns_for_modeling2, training_frame = train4_0, validation_frame = test4_0, ntrees = 500 , max_depth = 4, learn_rate=0.1,distribution=\"bernoulli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#h2o_gbm_mdl_b0\n",
    "pred4_b0 = h2o_gbm_mdl_b0.predict(eval4_frame).as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pred4_b0.predict.sum()\n",
    "pred4_b0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o.save_model(h2o_gbm_mdl_b0,path='hdfs://nameservice1/user/kesj/ajH2O_3/p4_b0/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def plot_conf_matrix(y_true,y_pred,normed=True,**kwargs):\n",
    "    my_c = metrics.confusion_matrix(y_true,y_pred)\n",
    "    \n",
    "    print metrics.matthews_corrcoef(y_true,y_pred)\n",
    "    if normed:\n",
    "        cm_normalized = my_c.astype('float') / my_c.sum(axis=1)[:, np.newaxis]\n",
    "        my_c = cm_normalized\n",
    "        plt.title('Normalized RF Classifier Confusion Matrix')\n",
    "    else:\n",
    "        plt.title('Random Forest Classifier Confusion Matrix')\n",
    "        \n",
    "    sns.heatmap(my_c, annot=True,  fmt='',cmap='Blues')\n",
    "    plt.ylabel('True')\n",
    "    #plt.yticks\n",
    "    plt.xlabel('Assigned')\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_roc_curve(target_test, target_predicted_proba):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "    \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y4eval,pred4_b0.predict.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(target_test, target_predicted_proba):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "    \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_pred = pred4_b0['p0'].copy()\n",
    "tmp_pred.ix[pred4_b0[pred4_b0.predict==0].index] = pred4_b0.ix[pred4_b0[pred4_b0.predict==0].index]['p1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred4_b0[pred4_b0.predict==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(pred4_b0.p0.values,tmp_pred.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tmp_pred.values\n",
    "plot_roc_curve(y4eval,np.vstack([1-tmp_pred.values, tmp_pred.values]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y4eval, pred4_b0[['p0','p1']].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y4eval, pred4_b0[['p0','p1']].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o_gbm_mdl_b0.varimp(return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eport the POJO to a local directory space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dest_dir = '/home/kesj/work/hrsepara/proc/h2o/gbm_4yr_sep_b0/'\n",
    "os.chdir(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!curl http://sfda74wbdn03.opr.statefarm.org:54321/3/h2o-genmodel.jar > h2o-genmodel.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!curl http://sfda74wbdn03.opr.statefarm.org:54321/3/Models.java/GBM_model_python_1444141461056_19 > GBM_model_python_1444141461056_19.java\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!javac -cp h2o-genmodel.jar -J-Xmx2g -J-XX:MaxPermSize=128m GBM_model_python_1444141461056_19.java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write a function to apply this each fold in a panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse4,roc_auc4,gbc_mdl4 = apply_tKfold_CV2('gbc',panel4, tfold4,  cols_to_use = columns_for_modeling3, tgt_column='former',ntrees=500)#['columns_for_modeling'],em2mod['former'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#h2o.H2ODisplay(python_obj= list(\n",
    "panel4[0].ix[tfold4[0][0]].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a set of all the current employees \n",
    "### October 28, 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw2002 = pd.read_csv('../eda/employees_after2001_raw.csv',dtype={'KEY':np.str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(raw2002),len(em2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the list of ACTRES1 for  ReTIREMENT\n",
    "uniq_action_reasons_1 = raw2002.ACTRES1.unique()\n",
    "print len(uniq_action_reasons_1)\n",
    "temp_list = [str(x).split(';') for x in uniq_action_reasons_1]\n",
    "from itertools import chain\n",
    "act_reason_1_list = list(chain.from_iterable(temp_list))\n",
    "print len(act_reason_1_list)\n",
    "act_reason_1_set = set(act_reason_1_list)\n",
    "print len(act_reason_1_set)\n",
    "possible_retire_codes = [x for x in act_reason_1_set if ('RET' in x and  'RETURN' not in x) ]\n",
    "possible_retire_codes.append('DISABILITY')\n",
    "len(possible_retire_codes)\n",
    "possible_retire_codes.sort()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_retired(x,ret_codes =possible_retire_codes):\n",
    "    try:\n",
    "        matched = [a for a in x.split(';') if a in ret_codes]\n",
    "        if len(matched):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except AttributeError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw2002['retired'] = raw2002.ACTRES1.apply(lambda x: identify_retired(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the one case where it is retired but not separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(raw2002[~((raw2002.status == 0)& (raw2002.retired == 1))])\n",
    "raw2002 = raw2002[~((raw2002.status == 0)& (raw2002.retired == 1))]\n",
    "print len(raw2002), len(em2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw2002[web_cols_to_keep].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em2['KEY']=raw2002['KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "web_cols_to_keep = ['KEY', 'HIRE_DT', 'BIRTHDATE', 'SAL1', 'MERIT1', 'PERF1', 'BOX1', 'SEX', 'HAVE_INS', 'HAVE_DEP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2[['HIRE_DT','BIRTHDATE']]= raw2002[['HIRE_DT','BIRTHDATE']]#web_cols_to_keep].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2[web_cols_to_keep].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_current = raw2002[raw2002.status==0].copy()\n",
    "print \"there are {0} current employees\".format(len(all_current))\n",
    "#all_current.to_csv('current_employees.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_current[web_cols_to_keep].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_current[['HAVE_INS','HAVE_DEP']]=all_current[['HAVE_INS','HAVE_DEP']].fillna('N').copy()\n",
    "all_current[web_cols_to_keep].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_current[web_cols_to_keep].to_csv('../../../lib/repo/hrseparation/web_app/uploads/current.ssv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"For retirement:\"\n",
    "print \"training set:\\t\",\n",
    "print em2.retired.value_counts()/len(em2)\n",
    "print \"evaluation set:\\t\",\n",
    "print em2eval.retired.value_counts()/len(em2eval)\n",
    "print \"For Separation\"\n",
    "print \"training set:\\t\",\n",
    "print em2.former.value_counts()/len(em2)\n",
    "print \"evaluation set:\\t\",\n",
    "print em2eval.former.value_counts()/len(em2eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE a Test-train split from this dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_indices = list(range(em2002.KEY.nunique()))\n",
    "print len(list_of_indices )\n",
    "random.seed(823321)\n",
    "#new_indices = [x for x in random.shuffle(list_of_indices)\n",
    "random.shuffle(list_of_indices)#, len(list_of_indices))\n",
    "em2002.index = list_of_indices # note that random.shuffle does this shuffling inplace\n",
    "em2002.sort_index(inplace=True)\n",
    "em2002.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what are the columns included?\n",
    "* examine building a model/models with minimal_input_col_list:\n",
    "    - minimal_input_col_list = ['KEY','HIRE_DT','BIRTHDATE','SAL1','HAVE_INS','HAVE_DEP','EMPL_TYPE','SEX', 'MAX_RT_ANNUAL','MIN_RT_ANNUAL','PERF1','MERIT1','BOX1','INTERN','HUBIND']\n",
    "* calculate Age_years & Tenure_years for each --> FeatureUnion\n",
    "\n",
    "## October -- making this bigger\n",
    "* go back to version 1.1 to see if I can construct the pipeline again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now deal with the columns used for modeling here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " = ['Age_years','Tenure_years','SAL1','MERIT1','PERF1','BOX1','SEX','HAVE_INS','HAVE_DEP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# repeat the split\n",
    "# break into evaluation and build sets\n",
    "print \"Starting with subest of {0} employees.\".format(len(em2002))\n",
    "eval_fraction = 0.20\n",
    "em2, em2eval = cross_validation.train_test_split(em2002,test_size=eval_fraction)\n",
    "print \"Evaluation set has {0} employees; training set has {1} employees.\".format(len(em2eval),len(em2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em2_tgt_retired = em2.retired\n",
    "em2_tgt_former = em2.former\n",
    "eval_tgt_retired = em2eval.retired\n",
    "eval_tgt_former = em2eval.former"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in an __ad hoc__ way convert these columns based upon our previous 'rules'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_required_cols = ['hire_tstmp','term_tstmp','birth_tstmp','former','retired']\n",
    "cols_for_model_prep = []\n",
    "cols_for_model_prep+=other_required_cols\n",
    "cols_for_model_prep+=columns_for_modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace the Y with 1 and N with 0, M with 1 and F with 0\n",
    "def apply_preprocess_small(df,cols_to_use =[]):\n",
    "    empl=df[cols_to_use].copy()\n",
    "    #all_cols = empl.columns.tolist()\n",
    "    empl['SEX'].replace({'M':1,'F':0},inplace=True)\n",
    "    empl[['HAVE_INS','HAVE_DEP']]=empl[['HAVE_INS','HAVE_DEP']].replace({'Y':1,'N':0}).copy()\n",
    "    empl['BOX1']=empl['BOX1'].replace({'H':3,'S':2,'L':1}).copy()\n",
    "    \n",
    "    # now deal with ints\n",
    "    \n",
    "    # fix the dollar amounts\n",
    "    min_sal1 = 17621.76 #(based upon training set I have: 5 %tile cut off)\n",
    "    min_min_rt_ann = 17900. # same as above\n",
    "    min_max_rt_ann = 33155.70\n",
    "\n",
    "    max_max_rt_ann = 133068.91\n",
    "    min_merit1 = 0.0\n",
    "    min_perf1 = 0.0\n",
    "    fix_min_outlier_col_dict = {'SAL1': min_sal1, 'MERIT1': min_merit1, 'PERF1': min_perf1}\n",
    "    fix_max_outlier_col_dict = {'MAX_RT_ANNUAL': max_max_rt_ann}\n",
    "\n",
    "    # replae these values\n",
    "    for key,value in fix_min_outlier_col_dict.iteritems():\n",
    "        idx_to_replace = empl[empl[key]<value].index\n",
    "        empl.loc[idx_to_replace,key]=value\n",
    "    \n",
    "    # now fill in missing with zero\n",
    "    empl.fillna(0,inplace=True)\n",
    "        \n",
    "        \n",
    "    return empl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2[cols_for_model_prep].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## so I want to use columns_for_modeling:\n",
    "['Age_years',\n",
    " 'Tenure_years',\n",
    " 'SAL1',\n",
    " 'MERIT1',\n",
    " 'PERF1',\n",
    " 'BOX1',\n",
    " 'SEX',\n",
    " 'HAVE_INS',\n",
    " 'HAVE_DEP']\n",
    "for my model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf,fp = create_temporal_kfolds(em2mod,full_date_range,5)\n",
    "len(kf),len(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(kf[0][0]), len(kf[0][1]), fp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "start_date = fp[i][0]\n",
    "end_date = fp[i][1]\n",
    "in_fold_idx=kf[i][0]\n",
    "target_col= 'former'\n",
    "cols_to_copy = ['SEX','Age_years','Tenure_years']\n",
    "cols_to_copy.append(target_col)\n",
    "cols_to_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "altered_fold_df = em2mod[cols_to_copy].copy()\n",
    "        # adjust these\n",
    "altered_fold_df.columns=['fold_mbr','adj_age','adj_tenure','adj_tgt']\n",
    "altered_fold_df.fold_mbr = 0\n",
    "adj_df =reset_years2(fp[i],in_fold_idx,em2mod)\n",
    "altered_fold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "altered_fold_df.loc[in_fold_idx,['adj_age','adj_tenure']]= adj_df.ix[in_fold_idx]\n",
    "altered_fold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mypanel5 = define_target_within_x_years(em2mod,fp,kf,5,'former')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mypanel5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mypanel5[0].ix[kf[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_for_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print columns_for_modeling[2:]\n",
    "X5fold = np.zeros((len(em2mod),len(columns_for_modeling),len(kf)))\n",
    "y5fold = []\n",
    "for i in xrange(0,len(kf)):\n",
    "    X5fold[:,:-2,i]=em2mod[columns_for_modeling[2:]].as_matrix().astype(np.float)\n",
    "    X5fold[:,-2:,i]=mypanel5[i][['adj_age','adj_tenure']]\n",
    "    my_y=mypanel5[i][['adj_tgt']].as_matrix().astype(np.int)\n",
    "    y5fold.append(my_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evalmod = apply_preprocess_small(em2eval,cols_for_model_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## now apply each model to my eval set\n",
    "def evaluate_models(model_list,Xeval):\n",
    "    eval_pred_class = np.zeros((len(Xeval),len(model_list)))\n",
    "    eval_pred_proba = np.zeros((len(Xeval),2,len(model_list)))\n",
    "\n",
    "    for i,mdl in enumerate(model_list):\n",
    "        eval_proba = mdl.predict_proba(Xeval)\n",
    "        eval_pred_class[:,i]=mdl.predict(Xeval)\n",
    "        eval_pred_proba[:,:,i]=eval_proba\n",
    "    #print np.shape(eval_prediction_proba3)\n",
    "    return eval_pred_class, eval_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reworking this\n",
    "1. preprocess the test data \n",
    "    0. transform all to numbers and fill in missing (```apply_preprocess_small```)\n",
    "    1. define the time_range\n",
    "    2. define the time fields (both timestamps and temporally dependent columns)\n",
    "        1. default_tstmps\n",
    "        2. _years columns: Age_years & Tenure_years\n",
    "    3. define the columns to use (for modeling)\n",
    "2. setup_tfold_models\n",
    "    * create_temporal_kfolds\n",
    "    * define_target_within_x_years\n",
    "    * \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contrary_case = []\n",
    "contrary_case += default_tstmps \n",
    "contrary_case.append('jobchg_tstmp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if [a for a in default_tstmps if a in em2mod.columns] == default_tstmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not [a for a in contrary_case if a in em2mod.columns] == contrary_case:\n",
    "    print \"some columns in contrary_case are missing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pan1 = transform_df_to_tfold(em2mod,kf,fp,5,columns_for_modeling,'former',default_tstmps,['Age_years','Tenure_years'])\n",
    "                      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pan1.items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[sum(pan1[a].former.isnull()) for a in xrange(0,len(pan1.items.tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pan1[8].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pan1[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(pan1[0].former.isnull()), len(kf[0][1]), len(kf[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10/01/15\n",
    "try gradient boosted classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse5,roc_auc5,rfmdl5 = apply_tKfold_CV2('gbc',pan1, kf,  cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopped here for LABOR DAY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel4, tfold4 = setup_tfolds(em2mod, 4, columns_for_modeling, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for training, testing in tfold4: #len(tfold4[0][1]), len(tfold4[0][0])\n",
    "    print len(training),len(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build a method/function to apply a model to the temporal_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#metrics.mean_squared_error\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_tKfold_CV(model, in_panel, tkfolds, cols_to_use, tgt_column = 'former' ):\n",
    "    \"\"\" Calculate the rmse for each cross-validated temporalFold\n",
    "    \n",
    "    Parameters:\n",
    "        model - a scikit learn model\n",
    "        in_panel  - a pandas Panel with the observed input data adjusted \n",
    "        in_y - a pandas Series with the observed outcome\n",
    "        k - number of cross validation folds (test set will be 1/k of the data)\n",
    "    \"\"\"\n",
    "    RMSE = []\n",
    "    for fold_id, indices in enumerate(tkfolds):\n",
    "        training = indices[0]\n",
    "        testing = indices[1]\n",
    "        print fold_id, len(training),len(testing)\n",
    "        X_train, X_test = in_panel[fold_id][cols_to_use].ix[training].as_matrix(), in_panel[fold_id][cols_to_use].ix[testing].as_matrix()\n",
    "        y_train, y_test = in_panel[fold_id][tgt_column].ix[training].as_matrix(), in_panel[fold_id][tgt_column].ix[testing].as_matrix()\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train,y_train)\n",
    "        # use the model to predict output\n",
    "        y_fitted = model.predict(X_test)\n",
    "        RMSE.append(np.sqrt(metrics.mean_squared_error(y_test,y_fitted)))\n",
    "    # leave the model fit to the entire dataset\n",
    "    #model.fit(in_x,in_y)\n",
    "    \n",
    "    return RMSE\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_tKfold_CV2(modeltype, in_panel, tkfolds, cols_to_use, tgt_column = 'former', ntrees=100):\n",
    "    \"\"\" Calculate the rmse for each cross-validated temporalFold\n",
    "    \n",
    "    Parameters:\n",
    "        model - a scikit learn model name\n",
    "        in_panel  - a pandas Panel with the observed input data adjusted \n",
    "        tgt_column -- the target variable\n",
    "        cols_to_use -- the input variables to be used in modeling\n",
    "        tkfolds -- teh temporal timefolds (list of dimension 2)\n",
    "    outputs:\n",
    "        models --> the list of fit models\n",
    "        RMSE --> the rmse error\n",
    "        \n",
    "    \"\"\"\n",
    "    RMSE = []\n",
    "    roc_auc = []\n",
    "    models = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for fold_id, indices in enumerate(tkfolds):\n",
    "        training = indices[0]\n",
    "        testing = indices[1]\n",
    "        #print fold_id, len(training),len(testing)\n",
    "        X_train, X_test = in_panel[fold_id][cols_to_use].ix[training].as_matrix(), in_panel[fold_id][cols_to_use].ix[testing].as_matrix()\n",
    "        y_train, y_test = in_panel[fold_id][tgt_column].ix[training].as_matrix(), in_panel[fold_id][tgt_column].ix[testing].as_matrix()\n",
    "        if modeltype == 'rfc':\n",
    "            model = ensemble.RandomForestClassifier(n_estimators=ntrees, max_features='auto', oob_score=True)\n",
    "        elif modeltype=='bgc':\n",
    "            model=ensemble.GradientBoostingClassifier(n_estimators=ntrees,max_features='auto')\n",
    "        else:\n",
    "            model=tree.DecisionTreeClassifier()\n",
    "            \n",
    "        # Train the model\n",
    "        model.fit(X_train,y_train)\n",
    "        # use the model to predict output\n",
    "        y_fitted = model.predict(X_test)\n",
    "        RMSE.append(np.sqrt(metrics.mean_squared_error(y_test,y_fitted)))\n",
    "        roc_auc.append(metrics.roc_auc_score(y_test,y_fitted))\n",
    "        models.append(model)\n",
    "    # leave the model fit to the entire dataset\n",
    "    #model.fit(in_x,in_y)\n",
    "    \n",
    "    return RMSE,roc_auc,models\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now setup protocol for generating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random_forest = ensemble.RandomForestClassifier(n_estimators=100, max_features='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse4,roc_auc4,rfmdl4 = apply_tKfold_CV2('rfc',panel4, tfold4, cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in xrange(0,len(panel4)):\n",
    "    print a, panel4[a][panel4[a].former==1].former.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply to the hold-out (EVAL) set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(roc_auc4).boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(a,rfmdl4[a].oob_score_) for a in xrange(0,len(rfmdl4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list= pan1[0].columns\n",
    "feature_list = columns_for_modeling\n",
    "feature_list\n",
    "fi_5df = create_fi_df(rfmdl5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_4df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fval_cols = [a for a in fi_4df.columns if 'value' in a]\n",
    "fi_4df[fval_cols].T.boxplot()\n",
    "plt.title('Feature Importances for 4year former')\n",
    "plt.ylabel('Feature Importances in Tfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4eval, y4eval = adjust_eval_by_x_years(evalmod,4,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4evalb, y4evalb = adjust_eval_by_x_years(evalmod,4,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beval_pred4class, beval_pred4proba = evaluate_models(rfmdl4,X4evalb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y4eval,map(eval_pred4class.mean(),np.int))\n",
    "plot_roc_curve(y4evalb,beval_pred4proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beval_pred4class.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beval_pred4class.min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y4evalb,map(np.int,beval_pred4class.mean(axis=1)+0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y4eval,map(eval_pred4class.mean(),np.int))\n",
    "plot_roc_curve(y4eval,eval_pred4proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y4eval,map(np.int,eval_pred4class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalmod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y5eval),len(evalmod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(evalmod[evalmod.Tenure_years <=5.0+.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel5[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X5eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalmod.former.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y5eval.sum()\n",
    "y5eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X5eval, y5eval = adjust_eval_by_x_years(evalmod,5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## try for 5year\n",
    "panel5, tfold5 = setup_tfolds(em2mod, 5, columns_for_modeling, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "rmse5,roc_auc5,rfmdl5 = apply_tKfold_CV2('gbc',panel5, tfold5, cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)\n",
    "X5eval, y5eval = adjust_eval_by_x_years(evalmod,5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Repeat for more trees\n",
    "rmse5b,roc_auc5b,rfmdl5b = apply_tKfold_CV2('gbc',panel5, tfold5, cols_to_use = columns_for_modeling, tgt_column='former',ntrees=500)#['columns_for_modeling'],em2mod['former'],)\n",
    "X5evalb,y5evalb = adjust_eval_by_x_years(evalmod,5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_scores5b = pd.DataFrame()\n",
    "cv_scores5b['rmse'] = rmse5b#pd.DataFrame(rmse5)#.boxplot()\n",
    "cv_scores5b['roc_auc']=roc_auc5b\n",
    "#pd.DataFrame(roc_auc5).boxplot()\n",
    "cv_scores5b.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_scores5 = pd.DataFrame()\n",
    "cv_scores5['rmse'] = rmse5#pd.DataFrame(rmse5)#.boxplot()\n",
    "cv_scores5['roc_auc']=roc_auc5\n",
    "#pd.DataFrame(roc_auc5).boxplot()\n",
    "cv_scores5.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse5, rmse5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ev5df = pd.DataFrame()\n",
    "ev5df['avg'] = eval_pred5class.mean(axis=1)\n",
    "#ev5df.head()\n",
    "ev5df['min'] = eval_pred5class.min(axis=1)\n",
    "ev5df['max']= eval_pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred5class, eval_pred5proba = evaluate_models(rfmdl5,X5eval)\n",
    "plot_conf_matrix(y5eval,map(np.int,eval_pred5class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y5eval,eval_pred5proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred5classb, eval_pred5probab = evaluate_models(rfmdl5b,X5eval)\n",
    "plot_conf_matrix(y5eval,map(np.int,eval_pred5classb.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(map(np.int,eval_pred5classb.mean(axis=1))), len(eval_pred5classb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y5eval,eval_pred5probab[:,:,:].mean(axis=2))\n",
    "plot_roc_curve(y5eval,eval_pred5proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_5df = create_fi_df(rfmdl5,columns_for_modeling)\n",
    "val_cols = [a for a in fi_5df.columns if 'value' in a]\n",
    "fi_5df[val_cols].T.boxplot()\n",
    "plt.title('Feature Importances for 5year former')\n",
    "plt.ylabel('Feature Importances in Tfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir 'gbc_5sep_pkl'\n",
    "%cd '/home/kesj/work/hrsepara/eda/gbc_5sep_pkl/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rfmdl5,open('gbc5.pkl','wb'))\n",
    "#len(flist_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try loading the previously pickled models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd '/home/kesj/work/hrsepara/eda/jl_5yr_100auto/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stored_mdl = jl.load('frf100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Seval_pred5class,Seval_pred5proba = evaluate_models(stored_mdl,X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y5eval,Seval_pred5proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat for 3 years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel3, tfold3 = setup_tfolds(em2mod, 3, columns_for_modeling, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "rmse3,roc_auc3,rfmdl3 = apply_tKfold_CV2('gbc',panel3, tfold3, cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)\n",
    "X3eval, y3eval = adjust_eval_by_x_years(evalmod,3,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred3class, eval_pred3proba = evaluate_models(rfmdl3,X3eval)\n",
    "plot_conf_matrix(y3eval,map(np.int,eval_pred3class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y3eval,eval_pred3proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(eval_pred3proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(0,len(panel3)):\n",
    "    #fpr,tpr,treshholds = roc_\n",
    "    plot_roc_curve(y3eval,eval_pred3proba[:,:,i])\n",
    "plot_roc_curve(y3eval,eval_pred3proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y3eval,eval_pred3proba[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel2, tfold2 = setup_tfolds(em2mod, 2, columns_for_modeling, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "rmse2,roc_auc2,rfmdl2 = apply_tKfold_CV2('rfc',panel2, tfold2, cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)\n",
    "X2eval, y2eval = adjust_eval_by_x_years(evalmod,2,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred2class, eval_pred2proba = evaluate_models(rfmdl2,X2eval)\n",
    "plot_conf_matrix(y2eval,map(np.int,eval_pred2class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel1, tfold1 = setup_tfolds(em2mod, 1, columns_for_modeling, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "rmse1,roc_auc1,rfmdl1 = apply_tKfold_CV2('rfc',panel1, tfold1, cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)\n",
    "X1eval, y1eval = adjust_eval_by_x_years(evalmod,1,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred1class, eval_pred1proba = evaluate_models(rfmdl1,X1eval)\n",
    "plot_conf_matrix(y1eval,map(np.int,eval_pred1class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(0,len(panel1)):\n",
    "    #fpr,tpr,treshholds = roc_\n",
    "    plot_roc_curve(y1eval,eval_pred1proba[:,:,i])\n",
    "plot_roc_curve(y1eval,eval_pred1proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel2[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try for 'retired'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "today = pd.to_datetime('2015-01-01')\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "evalmod[(evalmod['retired']==1) & (today - evalmod['term_tstmp']<= 1.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adjust_eval_by_x_yearsR(df,year_val,modeling_columns,endtime,tstmp_cols=default_tstmps,target_col='retired'):\n",
    "    # construct\n",
    "  \n",
    "    ## set up method to assess the eval set\n",
    "    print \"There are {0} elements in the evaluation set\".format(len(df))\n",
    "   \n",
    "    print \"original target variable value counts:\", df[target_col].value_counts()\n",
    "    # restructure to deal with time_frame retirement (target variable)\n",
    "    yr_cut_val = year_val+0.5\n",
    "    df['rel_yrs'] = df['term_tstmp'].apply(lambda x: (endtime - x).days/365.25)\n",
    "    # index of those that actually accomplish target within timeframe (allow 0.5 additional years)\n",
    "    #eval_within_time_target_index = df[(df[target_col]==1) & (endtime - df['term_tstmp'] <= yr_cut_val)].index\n",
    "    eval_within_time_target_index = df[(df[target_col]==1) & (df['rel_yrs'] <= yr_cut_val)].index\n",
    "    # exclude indices that are active and have tenure less than this time\n",
    "    eval_excluded_index = df[(df[target_col]==0) & (df.Tenure_years  <= yr_cut_val)].index\n",
    "    \n",
    "    # the rest become my not-terminated set\n",
    "    eval_active_index = set(df.index) - set(eval_within_time_target_index) - set(eval_excluded_index)\n",
    "    print len(eval_excluded_index),len(eval_within_time_target_index), len(eval_active_index)\n",
    "    eval_idx_to_use =df.ix[set(df.index)-set(eval_excluded_index)].index\n",
    "    #len(eval_idx_to_use)\n",
    "    # reset the target to 0 for active\n",
    "    eval_new_target = df[target_col].copy()\n",
    "    eval_new_target.ix[eval_active_index] = 0\n",
    "    print \"new target variable value counts: \"\n",
    "    print eval_new_target.ix[eval_idx_to_use].value_counts()\n",
    "    print \"_____\"\n",
    "    y_eval = eval_new_target.ix[eval_idx_to_use].as_matrix().astype(np.int) # true values\n",
    "    eval_adj_tenure = df.ix[eval_idx_to_use].Tenure_years.apply(lambda x: x-year_val if (x>float(year_val)) else 0).values\n",
    "    print len(eval_adj_tenure), len(y_eval)\n",
    "    # now adjust age by length of time; use hire_age if not in set to use.\n",
    "    eval_adj_age = df.ix[eval_idx_to_use].Age_years.apply(lambda x: x-year_val)\n",
    "    hire_age = (df.ix[eval_within_time_target_index]['birth_tstmp']-df.ix[eval_within_time_target_index]['hire_tstmp'])/np.timedelta64(1,'Y')#.days/days_in_year\n",
    "    eval_adj_age.ix[eval_within_time_target_index] = hire_age #df.ix[eval_within_time_target_index]['birth_tstmp'#df_dates['hire_age']\n",
    "    \n",
    "    # construct the evaluation X matrix\n",
    "    print \"input matrix has {0} features\".format(len(modeling_columns))\n",
    "    Xeval = np.zeros((len(eval_idx_to_use),len(modeling_columns)))\n",
    "    # drop 'Age_years' and Tenure_years from the list\n",
    "    cols_to_use = []\n",
    "    cols_to_use+=modeling_columns\n",
    "    cols_to_use.remove('Age_years')\n",
    "    cols_to_use.remove('Tenure_years')#.copy()\n",
    "    \"\"\"\n",
    "    Xeval[:,:-2] = df.ix[eval_idx_to_use][cols_to_use].as_matrix().astype(np.float)\n",
    "    # now put the adjusted tenure and ages into this matrix\n",
    "    Xeval[:,-2] = eval_adj_age.values\n",
    "    Xeval[:,-1]=eval_adj_tenure\n",
    "    #print len(modeling_columns),np.shape(Xeval)\n",
    "    \"\"\"\n",
    "    # this version matches the changed ording of columns\n",
    "    Xeval[:,0]=eval_adj_age.values\n",
    "    Xeval[:,1]=eval_adj_tenure\n",
    "    Xeval[:,2:] = df.ix[eval_idx_to_use][cols_to_use].as_matrix().astype(np.float)\n",
    "    return Xeval, y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel2, Rtfold2 = setup_tfolds(em2mod, 2, columns_for_modeling, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "Rrmse2,Rroc_auc2,Rrfmdl2 = apply_tKfold_CV2('rfc',Rpanel2, Rtfold2, cols_to_use = columns_for_modeling, tgt_column='retired')#['columns_for_modeling'],em2mod['former'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Reval_pred2class,Reval_pred2proba = evaluate_models(Rrfmdl2,RX2eval)\n",
    "plot_roc_curve(Ry2eval,Reval_pred2proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel5, Rtfold5 = setup_tfolds(em2mod, 5, columns_for_modeling, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "Rrmse5,Rroc_auc5,Rrfmdl5 = apply_tKfold_CV2('rfc',Rpanel5, Rtfold5, cols_to_use = columns_for_modeling, tgt_column='retired')#['columns_for_modeling'],em2mod['former'],)\n",
    "RX5eval, Ry5eval = adjust_eval_by_x_yearsR(evalmod,5,columns_for_modeling, today,target_col = 'retired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Reval_pred5class,Reval_pred5proba = evaluate_models(Rrfmdl5,RX5eval)\n",
    "plot_roc_curve(Ry5eval,Reval_pred5proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel4, Rtfold4 = setup_tfolds(em2mod,4, columns_for_modeling, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "Rrmse4,Rroc_auc4,Rrfmdl4 = apply_tKfold_CV2('rfc',Rpanel4, Rtfold5, cols_to_use = columns_for_modeling, tgt_column='retired')#['columns_for_modeling'],em2mod['former'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RX4eval, Ry4eval = adjust_eval_by_x_yearsR(evalmod,4,columns_for_modeling, today,target_col = 'retired')\n",
    "Reval_pred4class,Reval_pred4proba = evaluate_models(Rrfmdl4,RX4eval)\n",
    "plot_roc_curve(Ry4eval,Reval_pred4proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel3, Rtfold3 = setup_tfolds(em2mod, 3, columns_for_modeling, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "Rrmse3,Rroc_auc3,Rrfmdl3 = apply_tKfold_CV2('rfc',Rpanel3, Rtfold3, cols_to_use = columns_for_modeling, tgt_column='retired')#['columns_for_modeling'],em2mod['former'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RX3eval, Ry3eval = adjust_eval_by_x_yearsR(evalmod,3,columns_for_modeling,today, target_col = 'retired')\n",
    "Reval_pred3class,Reval_pred3proba = evaluate_models(Rrfmdl3,RX3eval)\n",
    "plot_roc_curve(Ry3eval,Reval_pred3proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel1, Rtfold1 = setup_tfolds(em2mod, 1, columns_for_modeling, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "Rrmse1,Rroc_auc1,Rrfmdl1 = apply_tKfold_CV2('rfc',Rpanel5, Rtfold5, cols_to_use = columns_for_modeling, tgt_column='retired')#['columns_for_modeling'],em2mod['former'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalmod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RX1eval[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(evalmod[(evalmod['retired']==1) & (today - evalmod['term_tstmp'] <= 5.5*365.25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5.5*365.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum((today - evalmod['term_tstmp']) <= 5.5*365.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RX1eval, Ry1eval = adjust_eval_by_x_yearsR(evalmod,1,columns_for_modeling, today, target_col = 'retired')\n",
    "Reval_pred1class,Reval_pred1proba = evaluate_models(Rrfmdl1,RX1eval)\n",
    "plot_roc_curve(Ry1eval,Reval_pred1proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir save_models_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd 'save_models_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sep\n",
    "!mkdir ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## define the base directories\n",
    "case_dir = ['sep/','ret/']\n",
    "## define the model cases\n",
    "nyrs = map(str,np.arange(1,6))\n",
    "base='rfmdl'\n",
    "model_listing = []\n",
    "pkl_file_dict = {}\n",
    "#dump_file_listing= []\n",
    "for case in case_dir:\n",
    "    #!cd {case_dir}\n",
    "    for yr in nyrs:\n",
    "        #dir_name = case+yr+'/'\n",
    "        #!mkdir {yr}\n",
    "        #!cd {yr}\n",
    "        model_name = base+yr\n",
    "        file_name = 'rf'\n",
    "        if case == 'ret/':\n",
    "            model_name = 'R'+model_name\n",
    "            file_name = 'R'+file_name\n",
    "        file_name+=yr\n",
    "        file_name+='.pkl'\n",
    "        \n",
    "        print dir_name, model_name, file_name\n",
    "        model_listing.append(model_name)\n",
    "        pkl_file_dict[model_name]=file_name\n",
    "        #file_list = jl.dump(model_name,file_name)\n",
    "        #dump_file_listing.append(file_list)\n",
    "        #!cd ../\n",
    "    #!cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store_dir = '/home/kesj/work/hrsepara/save_models_1/'\n",
    "dump_file_listing = []\n",
    "for mdl in model_listing:\n",
    "    if mdl.startswith('R'):\n",
    "        base_dir = store_dir + 'ret'\n",
    "        #!cd {base_dir}#/home/kesj/work/hrsepara/save_models_1/ret        \n",
    "    else:\n",
    "        base_dir = store_dir + 'sep'\n",
    "    \n",
    "    os.chdir(base_dir)#!cd {base_dir}\n",
    "    yr = mdl[-1]\n",
    "    #os.makedirs(yr)#!mkdir {yr}\n",
    "    #os.chdir(yr)#!cd {yr}\n",
    "    print yr,mdl\n",
    "    #file_list =jl.dump(mdl,pkl_file_dict[mdl])\n",
    "    #dump_file_listing.append(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/sep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.mkdir('1')\n",
    "os.chdir('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump_file_listing = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flist = jl.dump(rfmdl1,'rf1.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/sep')\n",
    "os.mkdir('2')\n",
    "os.chdir('2')\n",
    "flist = jl.dump(rfmdl2,'rf2.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/sep')\n",
    "os.mkdir('3')\n",
    "os.chdir('3')\n",
    "flist = jl.dump(rfmdl3,'rf3.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/sep')\n",
    "os.mkdir('4')\n",
    "os.chdir('4')\n",
    "flist = jl.dump(rfmdl4,'rf4.pkl')\n",
    "dump_file_listing.append(flist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/sep')\n",
    "os.mkdir('5')\n",
    "os.chdir('5')\n",
    "flist = jl.dump(rfmdl5,'rf5.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=5\n",
    "for yr in nyrs:\n",
    "    os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')\n",
    "    os.mkdir(yr)\n",
    "    os.chdir(yr)\n",
    "    flist = jl.dump(,'rf5.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.mkdir('1')\n",
    "os.chdir('1')\n",
    "flist = jl.dump(Rrfmdl1,'Rrf1.pkl')\n",
    "dump_file_listing.append(flist)\n",
    "\n",
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')\n",
    "os.mkdir('2')\n",
    "os.chdir('2')\n",
    "flist = jl.dump(Rrfmdl2,'Rrf2.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')\n",
    "os.mkdir('3')\n",
    "os.chdir('3')\n",
    "flist = jl.dump(Rrfmdl3,'Rrf3.pkl')\n",
    "dump_file_listing.append(flist)\n",
    "\n",
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')\n",
    "os.mkdir('4')\n",
    "os.chdir('4')\n",
    "flist = jl.dump(Rrfmdl4,'Rrf4.pkl')\n",
    "dump_file_listing.append(flist)\n",
    "\n",
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')\n",
    "os.mkdir('5')\n",
    "os.chdir('5')\n",
    "flist = jl.dump(Rrfmdl5,'Rrf5.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel4[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside:\n",
    "* KFold within sklearn does the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_folds = cross_validation.KFold(n=len(em2mod),n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for std_tr,std_test in std_folds:\n",
    "    print len(std_tr), len(std_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now build t_fold models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tfold5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "five_rf_mdl_100A = []\n",
    "for i in xrange(0,len(kf)):\n",
    "    train_y = y5fold[i].flatten()[kf[i][0]]\n",
    "    train_X = X5fold[kf[i][0],:,i]\n",
    "    rfmdl = ensemble.RandomForestClassifier(n_estimators=100,max_features='auto',n_jobs=1)\n",
    "    rfmdl.fit(train_X,train_y)\n",
    "#baseline_singleRFC = ensemble.RandomForestClassifier(n_jobs=50,n_estimators=500,max_features=None)\n",
    "#baseline_singleRFC.fit(X,y_term)\n",
    "#baseline_singleRFC_importances= baseline_singleRFC.feature_importances_\n",
    "    five_rf_mdl_100A.append(rfmdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_rf_mdl_100A[0].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X5eval, y5eval = adjust_eval_by_x_years(evalmod,5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_pred5class,eval_pred5proba = evaluate_models(five_rf_mdl_100A,X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5eval,map(np.int,eval_pred5class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y3eval,eval_prediction_proba3[:,])\n",
    "plot_roc_curve(y5eval,eval_pred5proba[:,:,:].mean(axis=2))\n",
    "plt.ylim([0,1.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### function to help explore the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to push feature_importances for a set of RF models into a dataframe\n",
    "def create_fi_df(mdl_list,feature_names):\n",
    "    list_feature_importances = []\n",
    "    col_list = []\n",
    "    for i,mdl in enumerate(mdl_list):\n",
    "        list_feature_importances.append(plotFI(mdl,feature_names,show_plot=False))\n",
    "        col_list.append('fold'+str(i)+'_value')\n",
    "        col_list.append('fold'+str(i)+'_std')\n",
    "\n",
    "    fi_df = pd.concat(list_feature_importances,axis=1)\n",
    "    # create column headings\n",
    "    fi_df.columns = col_list\n",
    "    # create the average of the values\n",
    "    value_cols = [x for x in col_list if x.endswith('value')]\n",
    "    \n",
    "    fi_df['avg_val']=fi_df[value_cols].mean(axis=1)\n",
    "    fi_df['avg_variance']=fi_df[value_cols].std(axis=1)\n",
    "#t2_eval_fi_df[['avg_val','avg_std']].sort('avg_val',ascending=False)\n",
    "    return fi_df\n",
    "\n",
    "def plotFI(forest,featureNames=[],show_plot=True):#,autoscale=True,headroom=0.05):\n",
    "    \"\"\"\n",
    "    forest is the model to be graphed.\n",
    "    featureNames is the list of features to be displayed\n",
    "    \n",
    "    \"\"\"\n",
    "    #if autoscale:\n",
    "    #    x_scale = forest.feature_importances_.max()+ headroom\n",
    "    #else:\n",
    "    #    x_scale = 1\n",
    "    \n",
    "    featureImportances=forest.feature_importances_\n",
    "    # sort the importances from biggest to least\n",
    "    indices = np.argsort(featureImportances)[::-1]\n",
    "    estimators = forest.estimators_\n",
    "    # calculate the variance over the forest \n",
    "    \n",
    "    std = np.std([tree.feature_importances_ for tree in estimators],axis=0)\n",
    "    # print summary statement\n",
    "    nfeatures = len(featureImportances)\n",
    "    print(\"Number of Features: %d\" % (nfeatures))\n",
    "    print(\"Number of Trees: %d\" %(len(estimators)))\n",
    "    \n",
    "    #print featureNames\n",
    "    if len(featureNames)==0:\n",
    "        featureNames = map(str,indices)\n",
    "    \n",
    "    fN2 = [featureNames[a] for a in indices]\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(len(indices)):\n",
    "        print(\"%d. feature %d=%s (%f)\" % (f + 1, indices[f], featureNames[indices[f]],featureImportances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    # define a cutoff in terms of feature_importance\n",
    "    if nfeatures <= 30:\n",
    "        kfeatures = nfeatures # keep all if smaller than 30\n",
    "    else:\n",
    "        kfeatures = 30\n",
    "        \n",
    "    kindices = indices[:kfeatures]\n",
    "    if show_plot:\n",
    "        plt.title(\"Feature importances\")\n",
    "        plt.barh(range(len(kindices)), featureImportances[kindices],\n",
    "           color=\"steelblue\", xerr=std[kindices], align=\"center\",ecolor='k')#,lw=2)\n",
    "    \n",
    "        plt.yticks(range(len(kindices)),fN2)\n",
    "        #grid(True)\n",
    "    \n",
    "    c1 = 'value'\n",
    "    c2 = 'std'\n",
    "    tdata = np.vstack([featureImportances[indices],std[indices]])\n",
    "    df = pd.DataFrame(data = tdata.T,index=fN2,columns=[c1,c2])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list = [a for a in columns_for_modeling if 'years' not in a]\n",
    "feature_list += columns_for_modeling[:2]\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[e for e in tree0.estimators_]\n",
    "np.shape(tree0.indices_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_5df = create_fi_df(five_rf_mdl_100A,feature_list)\n",
    "#tree0 = rfmdl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_5df.plot(kind='bar',y='avg_val')#,std='avg_var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_5df.plot(kind='bar',y='avg_variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##save this model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd '/home/kesj/work/hrsepara/eda/jl_5yr_100auto/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import joblib as jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../\n",
    "!du -h 'jl_5yr_100auto'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## work through evaluating based upon a set of existing models\n",
    "* I want to save all the separations to a data frame and then save it to disk\n",
    "* likewise with the retirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#os.chdir('../../')\n",
    "\n",
    "os.chdir(stgdir1local)\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_BASE_PATH='../save_models_1/'\n",
    "pred_cases = ['sep/','ret/']\n",
    "pred_years = map(np.str,np.arange(1,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep_proba_df = []\n",
    "ret_proba_df = []\n",
    "import joblib as jl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_models_simple(model_list,X,mode='mean',offset=0):\n",
    "    \"\"\" Function to apply a set of models to a given input and generate the predicted value(s)\n",
    "    :param model_list --> input list of models\n",
    "    :param X --> input array to apply models to\n",
    "    :param mode --> what sort of output to return; default is mean\n",
    "    intermediates\n",
    "        eval_pred_class --> array of classification prediction for each model\n",
    "        eval_pred_proba --> array of predicted probabilities for each model\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    eval_pred_class = np.zeros((len(X),len(model_list)))\n",
    "    eval_pred_proba = np.zeros((len(X),2,len(model_list)))\n",
    "\n",
    "    for i,mdl in enumerate(model_list):\n",
    "        eval_proba = mdl.predict_proba(X)\n",
    "        eval_pred_class[:,i]=mdl.predict(X)\n",
    "        eval_pred_proba[:,:,i]=eval_proba\n",
    "    if mode == 'mean':\n",
    "        # average the probabilities (for class=1) and return the mean predicted probability\n",
    "        prediction = np.mean(eval_pred_proba[:,1,:],axis=1)\n",
    "        #eval_pred_proba[:,1,:].mean(axis=2)\n",
    "\n",
    "    elif mode == 'class': # return the desired class prediction\n",
    "        prediction = map(np.int,eval_pred_class.mean(axis=1))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#del X\n",
    "np.shape(X5eval)\n",
    "X = X5eval[30:80,:]\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_proba_df = []\n",
    "for idx,pyr in enumerate(pred_years):\n",
    "    pkl_name ='rf'+pyr+'.pkl'#5.pkl'\n",
    "    path_name =MODEL_BASE_PATH+pred_cases[0]+pyr+'/'\n",
    "    print path_name, pkl_name\n",
    "    #path_name = MODEL_BASE_PATH+pred_cases[0]+\"5/\"#pred_years[0]+'/'\n",
    "        # load a model, evaluate it and return the 'average' probability for each person\n",
    "        #abs_mdl_name = os.path.abspath(path_name+pkl_name)\n",
    "    mdl_name = path_name+pkl_name\n",
    "    stored_mdl = jl.load(mdl_name)\n",
    "    stored_prediction = evaluate_models_simple(stored_mdl,X)#stored_pred,stored_pred_proba = evaluate_models(stored_mdl,X)\n",
    "\n",
    "    df = pd.DataFrame(stored_prediction.T)\n",
    "    df.columns=['sep'+pyr+'yr']\n",
    "    #df.#print stored_prediction\n",
    "    sep_proba_df.append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sep_proba_df)\n",
    "#sep_df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_df = pd.concat([a for a in sep_proba_df],axis=1)\n",
    "sep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sep_df.T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.rename(columns=['sep'+pyr+'yr'],inplace=True)\n",
    "df.columns=['sep'+pyr+'yr']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sep_proba_df = sep_proba_df[1:]\n",
    "pd.concat([a for a in sep_proba_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some miscellaneous, experimental visualizations of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(np.mean(eval_pred5proba[:,1,:],axis=1))\n",
    "ev5df = pd.DataFrame(eval_pred5proba[:,1,:])\n",
    "ev5df.head()\n",
    "#ev5df['avg'] = eval_pred5proba[:,0,:].mean(axis=2)\n",
    "#ev5df['avg'] = eval_pred5proba[:,0,:].min(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nshow = 21\n",
    "ev5df.head(nshow).T.boxplot(vert=False)\n",
    "plt.xlabel('predicted probability of separation')\n",
    "plt.ylabel('employee')\n",
    "plt.title('5 year window')\n",
    "#plt.plot(x=y5eval[:30],y=np.arange(0,30),color='darkgoldenrod',marker='*')\n",
    "for x,y in np.vstack([y5eval[:nshow],np.arange(0,nshow)]).T:\n",
    "    plt.plot(x,y,'D',color='darkgoldenrod')\n",
    "for x,yhat in np.vstack([map(np.int,eval_pred5class.mean(axis=1))[:nshow],np.arange(0,nshow)]).T:\n",
    "    plt.plot(x,yhat,'o',color='darkorchid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_class = ev5df.head(nshow).mean(axis=1) #map(np.int,ev5df.head(nshow).mean(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_class = p_class.apply(lambda x: round(x,0))\n",
    "#p_class['color']= 'red'\n",
    "p_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cname = ['red']*21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.violinplot(ev5df.head(nshow).T,vert=False)\n",
    "plt.xlabel('Probability of separation')\n",
    "plt.ylabel('employee')\n",
    "plt.xlim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create a scoring measure for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_kfold_cross_validation(model, all_X, all_y, k=5):\n",
    "    \"\"\"Calculate root mean squared error for each cross-validation fold.\n",
    "    \n",
    "    Parameters:\n",
    "        model - a scikit learn model\n",
    "        all_X - a pandas DataFrame with the observed input data\n",
    "        all_y - a pandas Series with the observed outcome\n",
    "        k - number of cross validation folds (test set will be 1/k of the data)\n",
    "    \n",
    "    Return value:\n",
    "        An array of length 'k' with the root mean squared error\n",
    "        for each fold.\n",
    "    \"\"\"\n",
    "    # 'folds' is a generator that will yield pairs of arrays (train, test)\n",
    "    # selecting row numbers for training/testing\n",
    "    folds = cross_validation.KFold(n=len(all_y), n_folds=k)\n",
    "    RMSE = []    # root mean squared errors\n",
    "    # Loop over the cross-validation folds\n",
    "    for training, testing in folds:\n",
    "        # Get the training and test splits\n",
    "        training = all_X.index[training]\n",
    "        testing = all_X.index[testing]\n",
    "        X_train, X_test = all_X.ix[training], all_X.ix[testing]\n",
    "        y_train, y_test = all_y.ix[training], all_y.ix[testing]\n",
    "    \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # Use the model to predict output\n",
    "        y_fitted = model.predict(X_test)\n",
    "        RMSE.append(np.sqrt(mean_squared_error(y_test, y_fitted)))\n",
    "    # Leave the model fit to the entire dataset\n",
    "    model.fit(all_X, all_y)\n",
    "    # And return the array of root mean squared errors\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first try to generalize the temporalKfold as a class\n",
    "* base this upon the KFold(_BaseKfold): class in scikitlearn\n",
    "* returns an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import _BaseKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class windowKFold(_BaseKFold):\n",
    "    \"\"\"windowed or temporal K-Folds cross validation iterator.\n",
    "    Provides train/test indices to split data in train test sets. Split\n",
    "    dataset into k consecutive folds (without shuffling).\n",
    "    Each fold is then used a validation set once while the k - 1 remaining\n",
    "    fold form the training set.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Total number of elements.\n",
    "    n_folds : int, default=3\n",
    "        Number of folds. Must be at least 2.\n",
    "    shuffle : boolean, optional\n",
    "        Whether to shuffle the data before splitting into batches.\n",
    "    random_state : None, int or RandomState\n",
    "        Pseudo-random number generator state used for random\n",
    "        sampling. If None, use default numpy RNG for shuffling\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn import cross_validation\n",
    "    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "    >>> y = np.array([1, 2, 3, 4])\n",
    "    >>> kf = cross_validation.KFold(4, n_folds=2)\n",
    "    >>> len(kf)\n",
    "    2\n",
    "    >>> print(kf)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    sklearn.cross_validation.KFold(n=4, n_folds=2, shuffle=False,\n",
    "                                   random_state=None)\n",
    "    >>> for train_index, test_index in kf:\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [2 3] TEST: [0 1]\n",
    "    TRAIN: [0 1] TEST: [2 3]\n",
    "    Notes\n",
    "    -----\n",
    "    The first n % n_folds folds have size n // n_folds + 1, other folds have\n",
    "    size n // n_folds.\n",
    "    See also\n",
    "    --------\n",
    "    StratifiedKFold: take label information into account to avoid building\n",
    "    folds with imbalanced class distributions (for binary or multiclass\n",
    "    classification tasks).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, n_folds=3, indices=None, shuffle=False,\n",
    "                 random_state=None):\n",
    "        super(KFold, self).__init__(n, n_folds, indices, shuffle, random_state)\n",
    "        self.idxs = np.arange(n)\n",
    "        if shuffle:\n",
    "            rng = check_random_state(self.random_state)\n",
    "            rng.shuffle(self.idxs)\n",
    "\n",
    "    def _iter_test_indices(self):\n",
    "        n = self.n\n",
    "        n_folds = self.n_folds\n",
    "        fold_sizes = (n // n_folds) * np.ones(n_folds, dtype=np.int)\n",
    "        fold_sizes[:n % n_folds] += 1\n",
    "        current = 0\n",
    "        for fold_size in fold_sizes:\n",
    "            start, stop = current, current + fold_size\n",
    "            yield self.idxs[start:stop]\n",
    "            current = stop\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '%s.%s(n=%i, n_folds=%i, shuffle=%s, random_state=%s)' % (\n",
    "            self.__class__.__module__,\n",
    "            self.__class__.__name__,\n",
    "            self.n,\n",
    "            self.n_folds,\n",
    "            self.shuffle,\n",
    "            self.random_state,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Size of the input set:\", input_data.shape)\n",
    "\n",
    "models = dict(\n",
    "    logistic = linear_model.LogisticRegression(),\n",
    "    gbc = ensemble.GradientBoostingClassifier(max_depth=5),\n",
    "    ridge = linear_model.RidgeClassifier(),\n",
    "    tree = tree.DecisionTreeClassifier(max_depth=5),\n",
    "    #svc = svm.LinearSVC(),\n",
    "    naive_bayes = naive_bayes.MultinomialNB(),  # Can only use if all inputs are positive\n",
    "    random_forest = ensemble.RandomForestClassifier(n_estimators=10, max_depth=5)\n",
    ")\n",
    "\n",
    "win = (spread > 0).astype(int)\n",
    "rmses = {}\n",
    "for name, model in models.items():\n",
    "    rmses[name] = perform_kfold_cross_validation(model, input_data, win, k=3)\n",
    "    \n",
    "pd.DataFrame(rmses).boxplot(vert=False, return_type='axes')\n",
    "plt.gcf().set_size_inches(9, 5)\n",
    "plt.xlabel(\"Error in prediction\"); plt.ylabel(\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try building a model with deeper splits? or more trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(X5fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_for_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jl.dump(five_rf_mdl_100A,'frf100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../\n",
    "%cd '/home/kesj/work/hrsepara/eda/jl_5yr_100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5.4 * 1000/250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "five_rf_mdl = []\n",
    "for i in xrange(0,len(tfold5)):\n",
    "    train_y = y5fold[i].flatten()#[tfold5[i][0]]\n",
    "    #train_X = #X5fold[tfold5[i][0],:,i]\n",
    "    train_X = X5fold[:,:,i]\n",
    "    rfmdl = ensemble.RandomForestClassifier(n_jobs=50,n_estimators=500,max_features=None)\n",
    "    rfmdl.fit(train_X,train_y)\n",
    "#baseline_singleRFC = ensemble.RandomForestClassifier(n_jobs=50,n_estimators=500,max_features=None)\n",
    "#baseline_singleRFC.fit(X,y_term)\n",
    "#baseline_singleRFC_importances= baseline_singleRFC.feature_importances_\n",
    "    five_rf_mdl.append(rfmdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(evalmod['hire_tstmp']-evalmod['birth_tstmp'])/np.timedelta64(1,'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred_5class, eval_pred_proba5 = evaluate_models(five_rf_mdl,X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_pred5class_100A, eval_pred5proba = evaluate_models(five_rf_mdl_100A,X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(eval_pred_5class), len(y5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5eval,map(int,eval_pred_5class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5eval,map(int,eval_pred5class_100A.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y3eval,eval_prediction_proba3[:,])\n",
    "plot_roc_curve(y5eval,eval_pred5proba[:,:,:].mean(axis=2))\n",
    "plt.ylim([0,1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5eval,map(int,eval_pred_5class.mean(axis=1)+0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(five_rf_mdl,'five_rf_mdljl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd five_rf_mdljl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frf= joblib.load('five_rf_mdljl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Beval_pred_5class, Beval_pred_proba5 = evaluate_models(frf,X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y3eval,eval_prediction_proba3[:,])\n",
    "plot_roc_curve(y5eval,Beval_pred_proba5[:,:,:].mean(axis=2))\n",
    "plt.ylim([0,1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Beval_pred5class0, Beval_pred5proba0 = evaluate_models(frf[0],X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Beval_pred_proba5[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y3eval,eval_prediction_proba3[:,])\n",
    "plot_roc_curve(y5eval,Beval_pred_proba5[:,:,4])\n",
    "plt.ylim([0,1.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try again with joblib directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib as jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../\n",
    "!mkdir jl_5yr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jldir = '/home/kesj/work/hrsepara/eda/jl_5yr/' \n",
    "os.chdir(jldir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat for 3 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfold3,tfold3_times,panel3term,X3fold,y3fold = setup_tfold_models(em2mod,3,columns_for_modeling)\n",
    "print len(tfold3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "three_rf_mdl_100 = []\n",
    "for i in xrange(0,len(tfold3)):\n",
    "    train_y = y3fold[i].flatten()\n",
    "    train_X = X3fold[:,:,i]\n",
    "    rfmdl = ensemble.RandomForestClassifier(n_estimators=100,max_features='auto',n_jobs=1)\n",
    "    rfmdl.fit(train_X,train_y)\n",
    "#baseline_singleRFC = ensemble.RandomForestClassifier(n_jobs=50,n_estimators=500,max_features=None)\n",
    "#baseline_singleRFC.fit(X,y_term)\n",
    "#baseline_singleRFC_importances= baseline_singleRFC.feature_importances_\n",
    "    three_rf_mdl_100.append(rfmdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dump the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd '../'\n",
    "!mkdir 'jl_3yr_100'\n",
    "%cd '/home/kesj/work/hrsepara/eda/jl_3yr_100'\n",
    "three_100_list = jl.dump(three_rf_mdl_100,'trf100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(three_100_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3eval, y3eval = adjust_eval_by_x_years(evalmod,3,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_pred3class,eval_pred3proba = evaluate_models(three_rf_mdl_100,X3eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y3eval,eval_pred3proba[:,:,:].mean(axis=2))\n",
    "plt.ylim([0,1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_conf_matrix(y3eval,eval_)\n",
    "plot_conf_matrix(y3eval,map(int,eval_pred3class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# omit those that have more than 25% missing:\n",
    "missing_threshold = 0.25\n",
    "columns_to_omit = list(sdf[sdf['x_missing'] > missing_threshold].Column.values)\n",
    "print len(columns_to_omit)\n",
    "print columns_to_omit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a simple DataFrame of employee dates using Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let me return to removing columns I don't want\n",
    "* keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "columns_to_remove = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"DF_Converter\", br.DataFrameConverter(columns=X.columns)),\n",
    "                     (\"Cat_Converter\", br.ConvertCategorical(categorical_columns=categorical_columns)),\n",
    "                     (\"Impute\", br.ImputeData()),\n",
    "                     (\"clf\", RandomForestClassifier(n_jobs=50))])\n",
    "pipeline.fit(X, y)\n",
    "pipeline.predict_proba(X_2014_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add/replace some relevant columns to this dataframe\n",
    "* POSTAL_SFI --> zip5 \n",
    "* unempl_rate by joining on unemployment\n",
    "* Age_hire\n",
    "* terminated \n",
    "* sep_status\n",
    "\n",
    "use a parallel dataframe for dates/timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnSelector(TransformerMixin):\n",
    "    \"\"\" Selects column(s) from a pandas DataFrame\n",
    "    \"\"\"\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols\n",
    "    def tranform(self, X, y=None):\n",
    "        return X[:,self.cols]\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Per discussion with HR COE team decide to truncate data after a particular date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions Follow\n",
    "* Most taken from ```bear.py```\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note make sure you have run kinit before the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now assign these values to the arrays\n",
    "emB['med_surv'] = emB['JOBCODE'].apply(lambda x: med_survival[x] )\n",
    "emB_eval['med_surv'] = emB_eval['JOBCODE'].apply(lambda x: med_survival[x] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeling_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(modeling_cols)\n",
    "sm_mod_cols = [a for a in modeling_cols]\n",
    "job_function_cols = [b for b in modeling_cols if b.startswith('JOB_FUNCTION')]\n",
    "job_function_cols\n",
    "#for a in ['JOBCODE','grade_code','loc_descr','job_fcode','']\n",
    "sm_mod_cols.remove('JOBCODE')\n",
    "sm_mod_cols+=['med_surv']\n",
    "print len(sm_mod_cols), len(modeling_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xp = emB[sm_mod_cols].as_matrix().astype(np.float)\n",
    "print np.shape(Xp)\n",
    "#y_tenure = emB.Tenure_years.as_matrix().astype(np.float)\n",
    "Xeval_p = emB_eval[sm_mod_cols].as_matrix().astype(np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "RFRforest2 = ensemble.RandomForestRegressor(n_jobs=50,n_estimators=500,max_features=None)\n",
    "RFRforest2.fit(Xp,y_tenure)\n",
    "#importances= forest.feature_importances_\n",
    "## apply to the eval subset from emB\n",
    "pred_tenure_eval_2 = RFRforest2.predict(Xeval_p)\n",
    "np.shape(pred_tenure_eval_2)#, np.shape(y_tenure_class.ix[eval_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_feature_importances(RFRforest2,sm_mod_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## working on using the pickled version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the application of a series of time-based model\n",
    "#pred_years = map(np.str,np.arange(1,6))\n",
    "\n",
    "def apply_survival_models(df,MDL_BASE_PATH,pkl_name,pred_years):\n",
    "    #proba_df = []\n",
    "    #import joblib as jl\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    mdl_name = MDL_BASE_PATH+pkl_name\n",
    "    #print mdl_name\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        stored_mdl = pickle.load(open(mdl_name,'rb'))\n",
    "        #stored_mdl = jl.load(mdl_name)\n",
    "                \n",
    "        sf_pred = stored_mdl.predict_survival_function(df)\n",
    "        sf_pred.index.name='years'\n",
    "        sf_pred.reset_index(inplace=True)\n",
    "        pred_proba = get_survival_prediction(df,sf_pred,yr_vals=pred_years)\n",
    "        \n",
    "        #df.loc[edf.index[employee_id]]=prob_vals\n",
    "        #except ValueError: # case when not found (because too young)\n",
    "        #    df.loc[edf.index[employee_id]]=0.0 # zero probability\n",
    "            #print employee_id, edf.index[employee_id]\n",
    "    #df.fillna(0.0,inplace=True) # fillin missing values with zero\n",
    "    #df[df<0] = 0.0 #replace negative probabilities with zero\n",
    "        \n",
    "    except IOError:\n",
    "        print \"requested pickle file not found {0}, using default parameters.\".format(mdl_name)\n",
    "        # TODO create default predictions from simple Survival model for retirement.\n",
    "        pred_proba = pd.DataFrame()\n",
    "        \n",
    "    return pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_pred = ret_model.predict_survival_function(em2002.tail())\n",
    "tmp_pred.index.name='years'\n",
    "tmp_pred.reset_index(inplace=True)\n",
    "tmp_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "for employee_id,age in enumerate(em2002.Age_years.tail()):\n",
    "    print employee_id, age\n",
    "    if age< 50.0:\n",
    "        proba\n",
    "    for idx,year in enumerate(yr_range):\n",
    "        ck_yr = age+year\n",
    "        \n",
    "        prior_idx = np.where(tmp_pred.years < ck_yr)[0][-1]\n",
    "        posterior_idx = np.where(tmp_pred.years > ck_yr)[0][0]\n",
    "        print idx,year,prior_idx, posterior_idx\n",
    "        x= [tmp_pred.ix[prior_idx]['years'], tmp_pred.ix[posterior_idx]['years']]\n",
    "        y= [tmp_pred.ix[prior_idx][employee_id],tmp_pred.ix[posterior_idx][employee_id]]\n",
    "        #print x,y, year\n",
    "                ## now interpolate these\n",
    "        y_interp = interpolate.interp1d(x,y)\n",
    "        proba = y_interp(ck_yr)\n",
    "#prior_idx = np.where(psf.years < ck_yr)[0][-1]\n",
    "#                posterior_idx = np.where(psf.years > ck_yr)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_survival_prediction(edf,psf, age_col='Age_years',yr_vals=[1,2,3,4,5]):\n",
    "    from scipy import interpolate\n",
    "    \n",
    "    pred_col_names = ['proba_'+str(y) for y in yr_vals]\n",
    "    df = pd.DataFrame(index=edf.index,columns=pred_col_names,dtype=float)\n",
    "    print pred_col_names\n",
    "    for employee_id,age in enumerate(edf['Age_years']):\n",
    "        if employee_id % 5000 ==0 :\n",
    "            print employee_id, age\n",
    "            \n",
    "        prob_vals =np.ones((len(yr_vals),))\n",
    "        #print prob_vals,\"\\n\"\n",
    "        if age >= 50.0: # only deal with over 50\n",
    "            for idx,year in enumerate(yr_vals):\n",
    "                ck_yr = age+year\n",
    "                try:\n",
    "                    prior_idx = np.where(psf.years < ck_yr)[0][-1]\n",
    "                    posterior_idx = np.where(psf.years > ck_yr)[0][0]\n",
    "                    #if employee_id == 0:\n",
    "                    #    print prior_idx, posterior_idx, employee_id\n",
    "                        \n",
    "                    x= [psf.ix[prior_idx]['years'], psf.ix[posterior_idx]['years']]\n",
    "                    y= [psf.ix[prior_idx][employee_id+1],psf.ix[posterior_idx][employee_id+1]]\n",
    "                    # there is an extra column in my processing\n",
    "                    #print x,y, year\n",
    "                    ## now interpolate these\n",
    "                    y_interp = interpolate.interp1d(x,y)\n",
    "                    proba = y_interp(ck_yr)\n",
    "                    #print proba\n",
    "                except IndexError:\n",
    "                    proba = psf.ix[np.where(psf.years == ck_yr)[0]][employee_id+1]\n",
    "            \n",
    "                prob_vals[idx] = proba\n",
    "                    \n",
    "        df.loc[edf.index[employee_id]]=prob_vals\n",
    "    df.fillna(1.0,inplace=True) # fillin missing values with zero\n",
    "    df[df<0] = 0.0 #replace negative probabilities with zero\n",
    "    \n",
    "    return 1-df # convert to probability of retirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for a,b in \n",
    "o50eval['Age_years'].tail().as_matrix()\n",
    "#    print a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    for idx,pyr in enumerate(pred_years):\n",
    "        #pkl_name ='rf'+pyr+'.pkl'#5.pkl'\n",
    "        #if pcase == 'ret/':\n",
    "        #    pkl_name = 'R'+pkl_name\n",
    "\n",
    "        #path_name =MODEL_BASE_PATH+pcase+pyr+'/'\n",
    "        #print path_name, pkl_name\n",
    "\n",
    "        # load a model, evaluate it and return the 'average' probability for each person\n",
    "        #abs_mdl_name = os.path.abspath(path_name+pkl_name)\n",
    "        #mdl_name = path_name+pkl_name\n",
    "        #stored_mdl = jl.load(mdl_name)\n",
    "        \n",
    "        stored_prediction = evaluate_models(stored_mdl,X)#stored_pred,stored_pred_proba = evaluate_models(stored_mdl,X)\n",
    "\n",
    "        df = pd.DataFrame(stored_prediction.T)\n",
    "        df.columns=[pcase[:-1]+pyr+'yr']\n",
    "\n",
    "        proba_df.append(df)\n",
    "\n",
    "    pred_df = pd.concat([a for a in proba_df], axis=1)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002[['Age_years','retired']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval['Age_years'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp2 = ret_model.predict_survival_function(o50eval.tail())\n",
    "tmp2.index.name = 'years'\n",
    "tmp2.reset_index(inplace=True)\n",
    "tmp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(tmp2.years < 61.947296)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yr_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MDL_BASE_PATH = '/home/kesj/work/hrsepara/proc/'\n",
    "yr_range = np.arange(1,6)\n",
    "ret_proba_df2 = apply_survival_models(o50eval.tail(),MDL_BASE_PATH,'retirement_sfA.pkl',yr_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ret_proba_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o50eval[['Age_years','retired']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current = em2002[em2002.status==0].copy()\n",
    "len(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_ret_prob = apply_survival_models(current,MDL_BASE_PATH,'retirement_sfA.pkl',yr_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
