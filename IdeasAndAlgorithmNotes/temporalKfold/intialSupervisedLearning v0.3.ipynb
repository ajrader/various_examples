{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Supervised Learning Analysis for the HR Separation (hrsepara) project\n",
    "## Start with output from initialEDA v0.6\n",
    "### Identify the correct working directory for source data\n",
    "* '/data/discovery/hrsepara/core/'\n",
    "### Identify the correct working directory for the analysis (both HDFS and LFS)\n",
    "* '/data/discovery/hrsepara/staging/eda' and  '/home/kesj/working/hrsepara/eda/'\n",
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coredir = '/data/discovery/hrsepara/core/'\n",
    "stgdir1 = '/data/discovery/hrsepara/staging/eda'\n",
    "stgdir1local = '/home/kesj/work/hrsepara/eda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from itertools import chain\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight') # Good looking plots\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check if the path exists\n",
    "os.path.exists(stgdir1local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hdfs_path_does_exist(path):\n",
    "    return subprocess.call(['hdfs','dfs','-ls',path])\n",
    "    # returns 0 if does_exist; 1 otherwise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make the remote directory\n",
    "if not hdfs_path_does_exist(stgdir1):\n",
    "    !hdfs dfs -mkdir {stgdir1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check if the path exists\n",
    "if not os.path.exists(stgdir1local):\n",
    "    # make the local directory\n",
    "    !mkdir {stgdir1local}\n",
    "    #'/home/kesj/work/hrsepara/eda'\n",
    "\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd {stgdir1local}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define the currentworking directory:\n",
    "cwd = os.path.abspath(os.curdir)\n",
    "print cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize_dataframe2(df,show_example=False,verbose=False):\n",
    "    nrow = len(df)\n",
    "    summary_df = pd.DataFrame(columns = ['Column','datatype','nmissing','arity','accepted values'])\n",
    "    len_df = len(summary_df)\n",
    "    for col in df.columns:\n",
    "        nmiss = nrow - df[col].value_counts().sum()\n",
    "        narity = len(df[col].unique())\n",
    "        if show_example:\n",
    "            print col, df[col].dtype,nmiss, \"\\t\", narity,\":\\t\", df[col].ix[8320]\n",
    "        elif verbose:\n",
    "            print col, df[col].dtype,nmiss, \"\\t\", narity\n",
    "        accept_val = None\n",
    "        if narity < 20:\n",
    "            accept_val = df[col].unique()\n",
    "        summary_df.loc[len_df] = [col,df[col].dtype,nmiss,narity,accept_val]\n",
    "        len_df+=1\n",
    "    # assing fraction of missing\n",
    "    summary_df['x_missing'] = summary_df['nmissing']/float(nrow)\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_factorized_df(input_df,column_name):\n",
    "    tmp_df = pd.get_dummies(input_df[column_name],prefix=column_name)\n",
    "    # now drop the largest category\n",
    "    lgst_category = input_df[column_name].value_counts().index[0]\n",
    "    #print tmp_df.shape, tmp_df.columns\n",
    "    #print lgst_category\n",
    "    base_category = column_name+'_'+str(lgst_category)\n",
    "    tmp_df.drop(base_category,axis=1,inplace=True)\n",
    "    print tmp_df.shape, base_category\n",
    "    return tmp_df,base_category\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ the data May 19, 2015\n",
    "* use employee_dataframe8.tsv --> contains text fields including dates for HIRE_DT..\n",
    "* use employee_df_[1,2].csv --> contains just numeric data.\n",
    "    - employee_df_1 has 180 columns:\n",
    "        + Historical data there \n",
    "        + max value of EXT_FUNC_ID_SFI and FUNC_ID_SFI (represents missing ) changed to 2000.\n",
    "        + median values used to fill missing values for float columns\n",
    "        + COMPANY dropped\n",
    "        + 'LOC_TYPE_DESCR_SFI','GRADE','LOC_STATE','JOB_FAMILY' label encoded\n",
    "        + ANNUAL_RT droped in lieu of SAL1\n",
    "        + BOX* kept; RATE*  dropped\n",
    "        + PTFTCNT* kept; PARTFULL dropped\n",
    "        + FTCNT* kept; FULLPART dropped\n",
    "    - keep only the most recent historical data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_df = pd.read_csv('employee_df_1.csv')\n",
    "empl_df.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "empl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_read_dict = {'KEY':np.str,'LOCATION':np.str,'EEO1CODE':np.str,'SKEY':np.str,'JOBCODE':np.str,'EMPL_CLASS':np.str, \n",
    "                        'COMPANY':np.str,'EXT_FUNC_ID_SFI':np.str,'FUNC_ID_SFI':np.str,\n",
    "                          'DIVISION_CODE_SFI':np.str,'JOB_FAMILY':np.str,'JOB_FUNCTION':np.str,'ACTRES1':np.str,\n",
    "                          'ACTRES2':np.str,'ACTRES3':np.str,'ACTRES4':np.str,'ACTRES5':np.str,'ACTRES6':np.str,\n",
    "                          'ACTRES7':np.str,'ACTRES8':np.str,'ACTRES9':np.str,'ACTRES10':np.str,'zip5':np.str}\n",
    "emplfull = pd.read_csv('employee_dataframe8.tsv',sep='\\t',dtype={'KEY':np.str,'SKEY':np.str,'zip5':np.str})#,dtype=new_read_dict)\n",
    "print emplfull.shape\n",
    "emplfull.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## So what columns are present in empl_df? (numerics)\n",
    "sdf = summarize_dataframe2(empl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(emplfull.JOBCODE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[ a for a in empl_df.columns if a.startswith('FULL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_df.plot(kind='scatter',x='FUNC_ID_SFI',y='EXT_FUNC_ID_SFI')\n",
    "print empl_df[['FUNC_ID_SFI','EXT_FUNC_ID_SFI']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This data is now ready to use as input into scikitLearn as a matrix\n",
    "The standard notation is to define this as X and save it as a float type\n",
    "Don't forget to create a response variable, y\n",
    "\n",
    "### I will begin by looking to see if there are columns that have strong correlations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_empl_df_correlation = empl_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arank = full_empl_df_correlation.apply(np.argsort, axis=1)\n",
    "ranked_cols = full_empl_df_correlation.columns.to_series()[arank.values[:,::-1][:,:2]]\n",
    "new_frame = pd.DataFrame(ranked_cols,index=full_empl_df_correlation.index)\n",
    "new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print full_empl_df_correlation.loc['SAL9','SAL10']\n",
    "empl_df.plot(kind='scatter',x='SAL9',y='SAL10',alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List collumns that are highly correlated (over thresh = 0.95) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xcol = new_frame[0].values\n",
    "ycol = new_frame[1].values\n",
    "for id in xrange(0,len(xcol)):\n",
    "    #print xcol[id],ycol[id]\n",
    "    max_pair_corr = full_empl_df_correlation.loc[xcol[id],ycol[id]]\n",
    "    if max_pair_corr > 0.95:\n",
    "        print max_pair_corr, xcol[id],ycol[id]\n",
    "#full_empl2_df_correlation.loc[new_frame[0],new_frame[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(full_empl_df_correlation), len(empl_df.columns)\n",
    "set(empl_df.columns) - set(full_empl_df_correlation.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in empl_df.FUNC_ID_SFI.unique() if x > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(empl_df.RELOCATE_ALL_SFI,empl_df.RELO_STATE_CNT_SFI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at relationship between Tenure_year and Age_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_df.plot(kind='scatter', x = 'Tenure_years',y = 'Age_years', alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how do the various tenures depend on Box10 values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_range = [empl_df.Tenure_years.min(),empl_df.Tenure_years.max()]\n",
    "nbins = 40\n",
    "empl_df[empl_df.BOX10==0].Tenure_years.hist(normed=True,range=my_range,bins=nbins,label='BOX10 = 0')\n",
    "empl_df[empl_df.BOX10!=0].Tenure_years.hist(normed=True,range=my_range,bins=nbins,alpha=0.8,label='BOX10 >0')\n",
    "#empl2[empl2.BOX10==1].Tenure_years.hist(normed=True,alpha=0.8,range=my_range,bins=nbins)\n",
    "#empl2[empl2.BOX10==2].Tenure_years.hist(normed=True,alpha=0.6,range=my_range,bins=nbins)\n",
    "#empl2[empl2.BOX10==3].Tenure_years.hist(normed=True,alpha=0.4,range=my_range,bins=nbins)\n",
    "plt.xlabel('Tenure (years)')\n",
    "plt.legend()\n",
    "plt.ylabel('Normalized Counts')\n",
    "print \" so BOX10 values of 0 are overwhelmingly linked to low tenure (i.e. under 10 years)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further refine/remove columns because of this discrepancy/lack of historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_list = empl_df.columns.tolist()\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_df[['MERIT1','MERIT10']].describe()#hist(bins=150)\n",
    "#empl_df.MERIT1.hist(bins=150,alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_df[['SAL1','SAL10']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### clean-up historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "three_cols = [x for x in col_list if x.endswith('CNT3')]\n",
    "five_cols = [x for x in col_list if x.endswith('CNT5')]\n",
    "ten_cols = [x for x in col_list if x.endswith('CNT10')]\n",
    "# drop all BOX, MERIT, SAL, PERF and add back in those from last year\n",
    "to_drop_cols = [x for x in col_list if x.startswith('PERF')]\n",
    "to_drop_cols+= [x for x in col_list if x.startswith('SAL')]\n",
    "to_drop_cols += [x for x in col_list if x.startswith('MERIT')]\n",
    "to_drop_cols += [x for x in col_list if x.startswith('BOX')]\n",
    "to_drop_cols+=three_cols\n",
    "to_drop_cols+=five_cols\n",
    "to_drop_cols+=ten_cols\n",
    "to_add_cols = ['BOX1','SAL1','MERIT1','PERF1']\n",
    "empl = empl_df.copy()\n",
    "empl.drop(to_drop_cols,inplace=True,axis=1)\n",
    "empl[to_add_cols] = empl_df[to_add_cols].copy()\n",
    "print empl.shape ## this is the same as if I read in employee_df_2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### get time_sensitive measures\n",
    "temporal_cols = [x for x in empl.columns if x.endswith('MOS')]\n",
    "#temporal_cols.append('Age_years')\n",
    "#temporal_cols.append('Tenure_years')\n",
    "temporal_cols#.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct a simple df of employee dates (use timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[a for a in emplfull.columns if a.startswith('BIR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_dates=pd.DataFrame()\n",
    "empl_dates[['hire_tstmp','term_tstmp','birth_tstmp']] = emplfull[['HIRE_DT','TERMINATION_DT','BIRTHDATE']].apply(lambda x: pd.to_datetime(x))\n",
    "#['hire_month'] = emplxtra_df['HIRE_DT'].apply(lambda x: int(str(x)[5:7])\n",
    "#emplxtra_df['hire_month'].hist(bins=12,color='darkorchid')\n",
    "#plt.xlabel('Month of Hire')\n",
    "#plt.ylabel('counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create procedure for time selections.\n",
    "def split_on_time(dates_df, split_tstmp):\n",
    "    #split_tstmp = pd.to_datetime(split_date_str)\n",
    "    #print split_tstmp\n",
    "    \n",
    "    before_idx = dates_df[(dates_df.hire_tstmp < split_tstmp)].index\n",
    "    after_idx = list(set(dates_df.index) -set(before_idx))\n",
    "    print len(after_idx), len(dates_df)\n",
    "    print \"Splitting on {0} amounts to a hold-out fraction of {1}\".format(split_tstmp,len(after_idx)/float(len(dates_df)))\n",
    "    return before_idx, after_idx\n",
    "                                                                        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Begin the Prediction(s)\n",
    "* first need to create a means to hold out current data\n",
    "* also revise time-sensitive data for relative date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get date information\n",
    "bidx,aidx = split_on_time(empl_dates,'2005-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temporal_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_time_split(df,dates_df,split_date_str,target_col,time_columns,tgt_type=np.float,omit_columns=None):\n",
    "    \"\"\"Inputs: employee data_frame (df)\n",
    "               dates_data_frame (dates_df) same length & index as df. has timestamps of hire, term and birth dates.\n",
    "               split_date_str --> string of format 'YYYY-MM-DD' to split into train & test dfs\n",
    "               time_columns == list of columns that are time dependent (age, tenure, MOS that need to be updated in training set)\n",
    "               omit_columns =  list of columns to exclude from analysis\n",
    "               \n",
    "    \"\"\"\n",
    "    # create timestamp based upon split-date_str\n",
    "    split_tstmp = pd.to_datetime(split_date_str)\n",
    "    # obtain indices corresponding to before and after the split timestamp\n",
    "    before_idx, after_idx = split_on_time(dates_df, split_tstmp)\n",
    "    # drop unnecessary columns\n",
    "    if omit_columns is not None:\n",
    "        df.drop(omit_columns,axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    # identify the set of training data that needs time adjustment -- i.e. if date is \n",
    "    indices_to_fix = dates_df[(dates_df.hire_tstmp< split_tstmp) & (dates_df.term_tstmp >= split_tstmp)].index\n",
    "    print \"{0} indices need time adjustment\".format(len(indices_to_fix))\n",
    "    \n",
    "    # create test and training sets.\n",
    "    train_df = df.ix[before_idx].copy()\n",
    "    test_df = df.ix[after_idx].copy()\n",
    "    \n",
    "    # correct status/sep_status, retired, etc. from training df\n",
    "    train_df.loc[indices_to_fix,['status','sep_status','retired']]= 0 # reset to zero because term date is after split_tstmp\n",
    "    # recalculate Age_years & Tenure_years\n",
    "    ## now calculate age at termination date\n",
    "    age_years = (split_tstmp - dates_df['birth_tstmp'])/np.timedelta64(1,'Y')\n",
    "    tenure_years = (split_tstmp - dates_df['hire_tstmp'])/np.timedelta64(1,'Y')\n",
    "    train_df['Age_years'] = age_years[before_idx]\n",
    "    train_df['Tenure_years'] = tenure_years[before_idx]\n",
    "    \n",
    "    # correct time-sensitve columns --> concern is for recent job changes.\n",
    "    \"\"\"# assume today is '01-01-2015'\n",
    "    today_tstmp = pd.to_datetime('2015-01-01')\n",
    "    months_ago = (today_tstmp - split_tstmp)/np.timedelta64(1,'M')\n",
    "    print months_ago\n",
    "    for tcol in time_columns:\n",
    "        print tcol\n",
    "        if tcol == 'TELE_MOS':\n",
    "    \"\"\"        \n",
    "    characteristic_cols = ['status','sep_status','retired']\n",
    "    \n",
    "    y_train = train_df[target_col].as_matrix().astype(tgt_type)\n",
    "    #other_to_drop = characteristic_cols.remove(target_col[0])\n",
    "    tdf = train_df.drop(characteristic_cols,axis=1).copy()\n",
    "    feature_names = tdf.columns.tolist() # save the features_names\n",
    "    X_train = tdf.as_matrix().astype(np.float)\n",
    "    y_test = test_df[target_col].as_matrix().astype(tgt_type)\n",
    "    tdf = test_df.drop(characteristic_cols,axis=1).copy()\n",
    "    X_test = tdf.as_matrix().astype(np.float)\n",
    "    \n",
    "    return (X_train,y_train,X_test,y_test,feature_names,indices_to_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y,Xtest,ytest,feature_names,fix_idx = create_time_split(empl,empl_dates,'2005-01-01','status',temporal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## check balance of status:\n",
    "print \"Training set has {0}\".format(sum(y)/float(len(X)))\n",
    "print \"Test set has {0}\".format(sum(ytest)/float(len(Xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run through a RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a K-fold CV set of models (assumes roughly balanced\n",
    "def kfold_cv(X, y, clf_class, shuffle=True, n_folds=10, **kwargs):\n",
    "    k_fold = cross_validation.KFold(len(y), n_folds=n_folds, shuffle=shuffle)\n",
    "    #y_pred = y.copy()\n",
    "    kf_fits = []\n",
    "    for ii, jj in k_fold:\n",
    "        X_train, X_test = X[ii], X[jj]\n",
    "        y_train = y[ii]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        kf_fits.append(clf)\n",
    "        #y_pred[jj] = clf.predict(X_test)\n",
    "    return k_fold,kf_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "CVscores = []\n",
    "rfc_500trees, rfc_500fits = kfold_cv(X,y, ensemble.RandomForestClassifier,n_estimators =500, n_jobs=50)\n",
    "for idx,(ii, jj) in enumerate(rfc_500trees):\n",
    "    #print len(ii), len(jj)#, idx\n",
    "    cv_train, cv_test = X[ii],X[jj]\n",
    "    cv_score = rfc_500fits[idx].score(cv_test,y[jj])\n",
    "    print idx,\"\\t\",cv_score\n",
    "    CVscores.append(cv_score)\n",
    "print \"Average CV score is {0}\".format(np.mean(CVscores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for combining an ensemble of estimators (i.e. one generated by KFold)\n",
    "def combine_rf_estimators(rf_a,rf_b):\n",
    "    rf_a.estimators_ += rf_b.estimators_\n",
    "    rf_a.n_estimators = len(rf_a.estimators_)\n",
    "    return rf_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc_combo = reduce(combine_rf_estimators, rfc_500fits)\n",
    "rfc_combo.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some functions for plotting results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot ROC curve (requires probability being predicted)\n",
    "def plot_roc_curve(target_test, target_predicted_proba):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "    \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return roc_auc\n",
    "\n",
    "# plot FI bar\n",
    "# function to plot feature_importances for RF\n",
    "def plotFI(forest,featureNames=[],cname='steelblue'):\n",
    "    featureImportances=forest.feature_importances_\n",
    "    # sort the importances from biggest to least\n",
    "    indices = np.argsort(featureImportances)[::-1]\n",
    "    estimators = forest.estimators_\n",
    "    # calculate the variance over the forest \n",
    "    \n",
    "    std = np.std([tree.feature_importances_ for tree in estimators],axis=0)\n",
    "    # print summary statement\n",
    "    nfeatures = len(featureImportances)\n",
    "    print(\"Number of Features: %d\" % (nfeatures))\n",
    "    print(\"Number of Trees: %d\" %(len(estimators)))\n",
    "    \n",
    "    #print featureNames\n",
    "    if len(featureNames)==0:\n",
    "        featureNames = map(str,indices)\n",
    "    \n",
    "    fN2 = [featureNames[a] for a in indices]\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(len(indices)):\n",
    "        print(\"%d. feature %d=%s (%f)\" % (f + 1, indices[f], featureNames[indices[f]],featureImportances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    # define a cutoff in terms of feature_importance\n",
    "    if nfeatures <= 30:\n",
    "        kfeatures = nfeatures # keep all if smaller than 30\n",
    "    else:\n",
    "        kfeatures = 30\n",
    "        \n",
    "    kindices = indices[:kfeatures]\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.barh(range(len(kindices)), featureImportances[kindices],\n",
    "       color=cname, xerr=std[kindices], align=\"center\",ecolor='k')#,lw=2)\n",
    "    plt.yticks(range(len(kindices)),fN2)\n",
    "    #grid(True)\n",
    "    c1 = 'value'\n",
    "    c2 = 'std'\n",
    "    tdata = np.vstack([featureImportances[indices],std[indices]])\n",
    "    df = pd.DataFrame(data = tdata.T,index=fN2,columns=[c1,c2])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fi500a = plotFI(rfc_combo,feature_names,'indianred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test accuracy by applying to set within time-slice that had to be changed. \n",
    "###(i.e. term_date/hire_date were within today-slice date range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create accuracy test set:\n",
    "\n",
    "df_acc = empl.ix[fix_idx].copy()\n",
    "print len(df_acc)\n",
    "y_acc = df_acc.status.as_matrix().astype(np.float)\n",
    "df_acc.drop(['status','sep_status','retired'],inplace=True,axis=1)\n",
    "X_acc = df_acc.as_matrix().astype(np.float)\n",
    "rfc_combo.score(X_acc,y_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_accuracy_set(df,fix_idx,tgt_col,char_col=['status','sep_status','retired']):\n",
    "    df_acc = df.ix[fix_idx].copy()\n",
    "    print len(df_acc)\n",
    "    y_acc = df_acc[tgt_col].as_matrix().astype(np.float)\n",
    "    df_acc.drop(char_col,inplace=True,axis=1)\n",
    "    X_acc = df_acc.as_matrix().astype(np.float)\n",
    "    return (X_acc,y_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc_combo.score(Xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc_score = plot_roc_curve(ytest,rfc_combo.predict_proba(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ytest_pred = rfc_combo.predict(Xtest)\n",
    "rfc_conf_matrix_tenure = metrics.confusion_matrix(ytest,ytest_pred)\n",
    "sns.heatmap(rfc_conf_matrix_tenure, annot=True,  fmt='')\n",
    "plt.title('Random Forest Classifier Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.matthews_corrcoef(ytest,ytest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(model,y_true,myX):\n",
    "    # predict\n",
    "    y_pred = model.predict(myX)\n",
    "    y_pred_proba = model.predict_proba(myX)\n",
    "    accuracy = model.score(myX,y_true)\n",
    "    \n",
    "    mcc = metrics.matthews_corrcoef(y_true,y_pred)\n",
    "    #conf_matrix = metrics.confusion_matrix(y_true,y_pred)\n",
    "    #sns.heatmap(conf_matrix, annot=True,  fmt='')\n",
    "    #plt.title('Confusion Matrix')\n",
    "    auc_score = plot_roc_curve(y_true,y_pred_proba)\n",
    "    return([accuracy,mcc, auc_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_metrics(rfc_combo,ytest,Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_metrics(rfc_combo,y_acc,X_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now do this for a series of different time slices \n",
    "(just for fun)\n",
    "\n",
    "* go in 1 year increments from 1998 to 2014\n",
    "* calc scores for Accuracy set and Future set\n",
    "* retain fraction of hold out data, date, combo score, auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_slices_range = ['2000-01-01','2005-01-01','2010-01-01']#['1995-01-01','2000-01-01','2005-01-01','2010-01-01']#,'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measures = []\n",
    "dsets = []\n",
    "models = []\n",
    "for tslice in time_slices_range:\n",
    "    print tslice\n",
    "    X,y,Xtest,ytest,feature_names,fix_idx = create_time_split(empl,empl_dates,tslice,'status',temporal_cols)\n",
    "    #extract accuracy set\n",
    "    X_acc,y_acc = create_accuracy_set(empl,fix_idx,'status')\n",
    "    # do a single RF\n",
    "    single_rfc_500trees = ensemble.RandomForestClassifier(n_estimators=500,n_jobs=50)\n",
    "    rfc_mdl = single_rfc_500trees.fit(X,y) # fit on training data\n",
    "    models.append(rfc_mdl)\n",
    "    dsets.append([X,Xtest,X_acc,y,ytest,y_acc])\n",
    "    m_acc_a,m_acc_m,m_acc_r = calculate_metrics(rfc_mdl,y_acc,X_acc)\n",
    "    m_new_a,m_new_m,m_new_r = calculate_metrics(rfc_mdl,ytest,Xtest)\n",
    "    measures.append([m_acc_a,m_acc_m, m_acc_r, m_new_a, m_new_m, m_new_r])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(dsets)\n",
    "len(dsets[0])\n",
    "#conf_matrix = metrics.confusion_matrix(y_true,y_pred)\n",
    "    #sns.heatmap(conf_matrix, annot=True,  fmt='')\n",
    "    #plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx= 0\n",
    "conf_matrix = metrics.confusion_matrix(dsets[idx][4],models[idx].predict(dsets[idx][1]))\n",
    "sns.heatmap(conf_matrix,annot=True,fmt='')\n",
    "plt.title('confusion matrix (new)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx= 0\n",
    "conf_matrix = metrics.confusion_matrix(dsets[idx][5],models[idx].predict(dsets[idx][2]))\n",
    "sns.heatmap(conf_matrix,annot=True,fmt='')\n",
    "plt.title('confusion matrix (accuracy)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx= 2\n",
    "conf_matrix = metrics.confusion_matrix(dsets[idx][4],models[idx].predict(dsets[idx][1]))\n",
    "sns.heatmap(conf_matrix,annot=True,fmt='')\n",
    "plt.title('confusion matrix (new)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx= 2\n",
    "conf_matrix = metrics.confusion_matrix(dsets[idx][5],models[idx].predict(dsets[idx][2]))\n",
    "sns.heatmap(conf_matrix,annot=True,fmt='')\n",
    "plt.title('confusion matrix (accuracy)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Okay so now I can do the following:\n",
    "0. monitor the parameters for a given model and dataset\n",
    "1. optimize for accuracy in my model\n",
    "2. consider using stratified kfold if classes become unbalanced\n",
    "3. create a version of the above that takes a window of time instead of a strict split into 2 datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# push the data/parameters into a small df\n",
    "rfmodels_df = pd.DataFrame(data=measures,index=time_slices_range,columns=['Acc_in','MCC_in','AUC_in','Acc_post','MCC_post','AUC_post'])\n",
    "rfmodels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_size = []\n",
    "for b in xrange(0,len(dsets)):\n",
    "    ds_size.append([len(dsets[b][a]) for a in xrange(0,len(dsets))])\n",
    "\n",
    "ds_size=np.array(ds_size) # convert to an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfmodels_df = pd.DataFrame(data=measures,index=time_slices_range,columns=['Acc_in','MCC_in','AUC_in','Acc_post','MCC_post','AUC_post']) \n",
    "rfmodels_df.head()\n",
    "\n",
    "rfmodels_df['Train_size'] = ds_size[:,0]\n",
    "rfmodels_df['in_size' ] = ds_size[:,1]\n",
    "rfmodels_df['post_size'] = ds_size[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfmodels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### also want to to get balance in class sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create procedure for time selections.\n",
    "def divide_by_start_end_time(dates_df, start_tstmp, end_tstmp):\n",
    "    # eliminate those who left before start_tstmp\n",
    "    drop_initial_dates_idx = dates_df[(dates_df.term_tstmp < start_tstmp)].index\n",
    "    drop_after_dates_idx = dates_df[(dates_df.hire_tstmp >= end_tstmp)].index\n",
    "    keep_range_idx = list(set(dates_df.index)-set(drop_initial_dates_idx)-set(drop_after_dates_idx))\n",
    "    \n",
    "    #before_idx = dates_df[(dates_df.hire_tstmp < split_tstmp)].index\n",
    "    \n",
    "    print len(keep_range_idx), len(dates_df), len(drop_initial_dates_idx),len(drop_after_dates_idx)\n",
    "    print \"Desired range to keep is between {0} and {1}.\".format(start_tstmp,end_tstmp)\n",
    "    print \"This amounts to a training set of {0} elements and a test set of {1}\".format(len(keep_range_idx),len(drop_after_dates_idx))\n",
    "        \n",
    "    return keep_range_idx, drop_after_dates_idx.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_idx, after_idx = divide_by_start_end_time(empl_dates,pd.to_datetime('2000-01-01'),pd.to_datetime('2005-01-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train_idx), len(after_idx), len(empl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_dates.ix[after_idx].term_tstmp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ed = pd.to_datetime('2010-01-01')\n",
    "st = pd.to_datetime('2005-01-01')\n",
    "diff_in_years = int(round((ed-st).total_seconds()/(60.*60.*24.*365.25),0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def add_years(d, years):\n",
    "    \"\"\"Return a date that's `years` years after the date (or datetime)\n",
    "    object `d`. Return the same calendar date (month and day) in the\n",
    "    destination year, if it exists, otherwise use the following day\n",
    "    (thus changing February 29 to March 1).\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return d.replace(year = d.year + years)\n",
    "    except ValueError:\n",
    "        return d + (date(d.year + years, 1, 1) - date(d.year, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_time_segment(df,dates_df,start_date_str,end_date_str,target_col,time_columns,tgt_type=np.float,omit_columns=None):\n",
    "    \"\"\"Inputs: employee data_frame (df)\n",
    "               dates_data_frame (dates_df) same length & index as df. has timestamps of hire, term and birth dates.\n",
    "               start_date_str --> string of format 'YYYY-MM-DD' to split into train & test dfs\n",
    "               end_date_str --> string of format 'YYYY-MM-DD' to split into train & test dfs\n",
    "               time_columns == list of columns that are time dependent (age, tenure, MOS that need to be updated in training set)\n",
    "               omit_columns =  list of columns to exclude from analysis\n",
    "               \n",
    "    \"\"\"\n",
    "    # convert to datetime.date (let pandas deal with tstmp comparisons)\n",
    "    MAX_DATE = date(2014,12,31) # current max date\n",
    "    # create timestamp based upon split-date_str\n",
    "    #start_tstmp = pd.to_datetime(start_date_str)\n",
    "    #end_tstmp = pd.to_datetime(end_date_str)\n",
    "    start_dt = date(int(start_date_str[:4]),int(start_date_str[5:7]),int(start_date_str[-2:]))\n",
    "    end_dt = date(int(end_date_str[:4]),int(end_date_str[5:7]),int(end_date_str[-2:]))\n",
    "    # obtain indices corresponding to before and after the split timestamp\n",
    "    train_idx, after_idx = divide_by_start_end_time(dates_df,start_dt,end_dt)\n",
    "    # further split 2nd set to have same time length (if possible)\n",
    "    range_in_years = int(np.round((end_dt - start_dt).total_seconds()/(60.*60.*24.*365.25),0))\n",
    "    # add_years\n",
    "    final_dt = add_years(end_dt,range_in_years)\n",
    "    if final_dt > MAX_DATE:\n",
    "        final_dt = MAX_DATE\n",
    "    \n",
    "    test_idx, holdout_idx = divide_by_start_end_time(dates_df,end_dt,final_dt)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #before_idx, after_idx = split_on_time(dates_df, start_tstmp)\n",
    "    #before_idx2, after_idx2 = split_on_time(dates_df, end_tstmp)\n",
    "    \n",
    "    # drop unnecessary columns\n",
    "    if omit_columns is not None:\n",
    "        df.drop(omit_columns,axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    # identify the set of training data that needs time adjustment -- i.e. if date is \n",
    "    indices_to_fix = dates_df[(dates_df.hire_tstmp< end_dt) & (dates_df.term_tstmp >= end_dt)].index\n",
    "    print \"{0} indices need time adjustment\".format(len(indices_to_fix))\n",
    "    \n",
    "    # create test and training sets.\n",
    "    train_df = df.ix[train_idx].copy()\n",
    "    test_df = df.ix[test_idx].copy()\n",
    "    holdout_df = df.ix[holdout_idx].copy()\n",
    "    # calculate fraction in each class\n",
    "    x_separated_train = train_df[target_col].value_counts().ix[1]/float(len(train_df))\n",
    "    x_separated_test = test_df[target_col].value_counts().ix[1]/float(len(test_df))\n",
    "    x_separated_holdout = holdout_df[target_col].value_counts().ix[1]/float(len(holdout_df))\n",
    "    # correct status/sep_status, retired, etc. from training df\n",
    "    train_df.loc[indices_to_fix,['status','sep_status','retired']]= 0 # reset to zero because term date is after split_tstmp\n",
    "    # recalculate Age_years & Tenure_years\n",
    "    ## now calculate age at termination date\n",
    "    age_years = (end_dt - dates_df['birth_tstmp'])/np.timedelta64(1,'Y')\n",
    "    tenure_years = (end_dt - dates_df['hire_tstmp'])/np.timedelta64(1,'Y')\n",
    "    train_df['Age_years'] = age_years[train_idx]\n",
    "    train_df['Tenure_years'] = tenure_years[train_idx]\n",
    "    \n",
    "    # correct time-sensitve columns --> concern is for recent job changes.\n",
    "    \"\"\"# assume today is '01-01-2015'\n",
    "    today_tstmp = pd.to_datetime('2015-01-01')\n",
    "    months_ago = (today_tstmp - split_tstmp)/np.timedelta64(1,'M')\n",
    "    print months_ago\n",
    "    for tcol in time_columns:\n",
    "        print tcol\n",
    "        if tcol == 'TELE_MOS':\n",
    "    \"\"\"        \n",
    "    characteristic_cols = ['status','sep_status','retired']\n",
    "    \n",
    "    y_train = train_df[target_col].as_matrix().astype(tgt_type)\n",
    "    #other_to_drop = characteristic_cols.remove(target_col[0])\n",
    "    tdf = train_df.drop(characteristic_cols,axis=1).copy()\n",
    "    feature_names = tdf.columns.tolist() # save the features_names\n",
    "    X_train = tdf.as_matrix().astype(np.float)\n",
    "    y_test = test_df[target_col].as_matrix().astype(tgt_type)\n",
    "    tdf = test_df.drop(characteristic_cols,axis=1).copy()\n",
    "    X_test = tdf.as_matrix().astype(np.float)\n",
    "    frac_class = [x_separated_train, x_separated_test, x_separated_holdout]\n",
    "    \n",
    "    return (X_train,y_train,X_test,y_test,feature_names,indices_to_fix,frac_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trX,tr_y,teX,te_y,featuresCols,indx_to_Fix, frac_classes = create_time_segment(empl,empl_dates,'2004-01-01','2008-01-01','status',temporal_cols)\n",
    "    #df,dates_df,start_date_str,end_date_str,target_col,time_columns,tgt_type=np.float,omit_columns=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(empl_dates[(empl_dates.hire_tstmp < date(2005,1,1)) & (empl_dates.term_tstmp >= date(2005,1,1))].index), len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frac_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_time_slice(df,dates_df,start_date_str,end_date_str,target_col,time_columns,tgt_type=np.float,omit_columns=None):\n",
    "    \"\"\"Inputs: employee data_frame (df)\n",
    "               dates_data_frame (dates_df) same length & index as df. has timestamps of hire, term and birth dates.\n",
    "               start_date_str --> string of format 'YYYY-MM-DD' to split into train & test dfs\n",
    "               end_date_str --> string of format 'YYYY-MM-DD' to split into train & test dfs\n",
    "               time_columns == list of columns that are time dependent (age, tenure, MOS that need to be updated in training set)\n",
    "               omit_columns =  list of columns to exclude from analysis\n",
    "               \n",
    "    \"\"\"\n",
    "    # convert to datetime.date (let pandas deal with tstmp comparisons)\n",
    "    MAX_DATE = date(2014,12,31) # current max date\n",
    "    # create timestamp based upon split-date_str\n",
    "    #start_tstmp = pd.to_datetime(start_date_str)\n",
    "    #end_tstmp = pd.to_datetime(end_date_str)\n",
    "    start_dt = date(int(start_date_str[:4]),int(start_date_str[5:7]),int(start_date_str[-2:]))\n",
    "    end_dt = date(int(end_date_str[:4]),int(end_date_str[5:7]),int(end_date_str[-2:]))\n",
    "    # obtain indices corresponding to before and after the split timestamp\n",
    "    train_idx, test_idx = divide_by_start_end_time(dates_df,start_dt,end_dt)\n",
    "    range_in_years = int(np.round((end_dt - start_dt).total_seconds()/(60.*60.*24.*365.25),0))\n",
    "    \n",
    "    \n",
    "    #before_idx, after_idx = split_on_time(dates_df, start_tstmp)\n",
    "    #before_idx2, after_idx2 = split_on_time(dates_df, end_tstmp)\n",
    "    \n",
    "    # drop unnecessary columns\n",
    "    if omit_columns is not None:\n",
    "        df.drop(omit_columns,axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    # identify the set of training data that needs time adjustment -- i.e. if date is \n",
    "    indices_to_fix = dates_df[(dates_df.hire_tstmp< end_dt) & (dates_df.term_tstmp >= end_dt)].index\n",
    "    # take the intersection of this and the training set\n",
    "    idx_to_fix = list(set(indices_to_fix.tolist()).intersection(set(train_idx)))\n",
    "    print \"{0} indices need time adjustment\".format(len(idx_to_fix))\n",
    "    \n",
    "    # create test and training sets.\n",
    "    train_df = df.ix[train_idx].copy()\n",
    "    test_df = df.ix[test_idx].copy()\n",
    "    #holdout_df = df.ix[holdout_idx].copy()\n",
    "    # calculate fraction in each class\n",
    "    print len(train_df),len(test_df)\n",
    "    print train_df[target_col].value_counts()\n",
    "    x_class_train = train_df[target_col].value_counts().ix[1]/float(len(train_df))\n",
    "    x_class_test = test_df[target_col].value_counts().ix[1]/float(len(test_df))\n",
    "    print x_class_train, x_class_test\n",
    "    #x_separated_holdout = holdout_df[target_col].value_counts().ix[1]/float(len(holdout_df))\n",
    "    # correct status/sep_status, retired, etc. from training df\n",
    "    characteristic_cols = ['status','sep_status','retired']\n",
    "    train_df.loc[idx_to_fix,characteristic_cols]= 0 # reset to zero because term date is after split_tstmp\n",
    "    # recalculate Age_years & Tenure_years\n",
    "    ## now calculate age at termination date\n",
    "    age_years = (end_dt - dates_df['birth_tstmp'])/np.timedelta64(1,'Y')\n",
    "    tenure_years = (end_dt - dates_df['hire_tstmp'])/np.timedelta64(1,'Y')\n",
    "    train_df['Age_years'] = age_years[train_idx]\n",
    "    train_df['Tenure_years'] = tenure_years[train_idx]\n",
    "    \n",
    "    # correct time-sensitve columns --> concern is for recent job changes.\n",
    "    \"\"\"# assume today is '01-01-2015'\n",
    "    today_tstmp = pd.to_datetime('2015-01-01')\n",
    "    months_ago = (today_tstmp - split_tstmp)/np.timedelta64(1,'M')\n",
    "    print months_ago\n",
    "    for tcol in time_columns:\n",
    "        print tcol\n",
    "        if tcol == 'TELE_MOS':\n",
    "    \"\"\"        \n",
    "    \n",
    "    \n",
    "    y_train = train_df[target_col].as_matrix().astype(tgt_type)\n",
    "    #other_to_drop = characteristic_cols.remove(target_col[0])\n",
    "    tdf = train_df.drop(characteristic_cols,axis=1).copy()\n",
    "    feature_names = tdf.columns.tolist() # save the features_names\n",
    "    X_train = tdf.as_matrix().astype(np.float)\n",
    "    y_test = test_df[target_col].as_matrix().astype(tgt_type)\n",
    "    tdf = test_df.drop(characteristic_cols,axis=1).copy()\n",
    "    X_test = tdf.as_matrix().astype(np.float)\n",
    "    frac_class = [x_class_train, x_class_test]\n",
    "    \n",
    "    return (X_train,y_train,X_test,y_test,feature_names,idx_to_fix,frac_class,range_in_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_time_slice(empl,empl_dates,'2007-01-01','2012-01-01','retired',temporal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y,Xtest,ytest,feature_names,fix_idx,fc_vals,time_range_years = create_time_slice(empl,empl_dates,'2009-01-01','2012-01-01','status',temporal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_idx, test_idx = divide_by_start_end_time(empl_dates,date(2009,1,1),date(2012,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.ix[train_idx][empl_dates.ix[train_idx].term_tstmp > date(2012,1,1)].status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xhh,yhh = create_accuracy_set(empl,fix_idx,'status')\n",
    "#len(Xhh), len(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_dates.ix[142113][['term_tstmp','hire_tstmp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftmp = empl.ix[train_idx][empl_dates.ix[train_idx].term_tstmp >= date(2012,1,1)].copy()\n",
    "y_holdout = dftmp.status.as_matrix().astype(np.float)\n",
    "dftmp.drop(['status','sep_status','retired'],inplace=True,axis=1)\n",
    "X_holdout = dftmp.as_matrix().astype(np.float)\n",
    "y_hh_pred = rfc_mdl.predict(X_holdout)\n",
    "sns.heatmap(metrics.confusion_matrix(y_holdout,y_hh_pred), annot=True)\n",
    "#plt.scatter(y_holdout,y_hh_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hh_proba = rfc_mdl.predict_proba(X_holdout)\n",
    "plot_roc_curve(y_holdout,y_hh_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_proba = rfc_mdl.predict_proba(Xtest)\n",
    "plt.scatter(y_holdout,y_hh_proba[:,0],alpha=0.3,color='darkgreen')\n",
    "plt.scatter(ytest+0.2,y_test_proba[:,0],alpha=0.3,color='dodgerblue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = rfc_mdl.predict(Xtest)\n",
    "sns.heatmap(metrics.confusion_matrix(ytest,y_test_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_rfc_500trees = ensemble.RandomForestClassifier(n_estimators=500,n_jobs=50)\n",
    "rfc_mdl = single_rfc_500trees.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_metrics(rfc_mdl,ytest,Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(y_hh_pred)/float(len(y_hh_pred)), sum(y_holdout)/float(len(y_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date(2015,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_dates.term_tstmp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_str_list = [str(a)+'-01-01' for a in xrange(1987,2015)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = time_str_list[3::5]\n",
    "for first, second in zip(A, A[1:]):\n",
    "    print first, second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(time_str_list[3::5]), len(time_str_list[2::5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Begin with predicting retirements\n",
    "* look at different time intervals\n",
    "* shoot much more class imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_time_slice_models(df,dates,times_list,tgt_col,time_columns,ntrees=500):\n",
    "    measures =[]\n",
    "    Xsets =[]\n",
    "    ysets = []\n",
    "    models =[]\n",
    "    balance_fracs =[]\n",
    "    \n",
    "    for st_date,ed_date in zip(times_list,times_list[1:]):\n",
    "        print st_date, ed_date\n",
    "        X,y,Xtest,ytest,feature_names,fix_idx,fc_vals,duration = create_time_slice(df,dates,st_date,ed_date,tgt_col,time_columns)\n",
    "        # check the set that we know the answer about\n",
    "        Xknown,yknown = create_accuracy_set(empl,fix_idx,tgt_col)\n",
    "        # construct a single RF\n",
    "        single_rfc = ensemble.RandomForestClassifier(n_estimators=ntrees,n_jobs=50)\n",
    "        rfc_mdl = single_rfc.fit(X,y) # fit on training data\n",
    "        # append model to list of models\n",
    "        models.append(rfc_mdl)\n",
    "        # append datasets\n",
    "        Xsets.append([X,Xtest,Xknown])\n",
    "        ysets.append([y,ytest,yknown])\n",
    "        plt.figure()\n",
    "        m_acc_a,m_acc_m,m_acc_r = calculate_metrics(rfc_mdl,y_acc,X_acc)\n",
    "        m_new_a,m_new_m,m_new_r = calculate_metrics(rfc_mdl,ytest,Xtest)\n",
    "        measures.append([m_acc_a,m_acc_m, m_acc_r, m_new_a, m_new_m, m_new_r,st_date,ed_date,duration,len(y),len(ytest),len(yknown),fc_vals[0],fc_vals[1]])\n",
    "    \n",
    "    mdl_df = pd.DataFrame(data=measures,columns=['Acc_in','MCC_in','AUC_in','Acc_post','MCC_post','AUC_post',\n",
    "                                                 'start_date','end_date','nyears','train_size','test_size','in_size',\n",
    "                                                 'class_frac_train','class_frac_test'])\n",
    "    #mdl_df_list.append(mdl_df)\n",
    "\n",
    "    #dl_df = pd.DataFrame(mdl_df_list)\n",
    "        #mdl_df.iloc[k,:] =measures\n",
    "    return mdl_df,models,Xsets,ysets\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mm = build_time_slice_models(empl,empl_dates,A,'retired',temporal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_year_windows_df_list = []\n",
    "five_year_windows_data = []\n",
    "five_year_windows_models =[]\n",
    "for i in xrange(0,5):\n",
    "    print i, time_str_list[i::5]\n",
    "    dd,mdl,xsets,ysets = build_time_slice_models(empl,empl_dates,time_str_list[i::5],'status',temporal_cols)\n",
    "    five_year_windows_df_list.append(dd)\n",
    "    five_year_windows_data.append([xsets,ysets])\n",
    "    five_year_windows_models.append(mdl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m0 = build_time_slice_models(empl,empl_dates,time_str_list[::5],'retired',temporal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(five_year_windows_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_yr_df = pd.concat(five_year_windows_df_list,ignore_index=True)\n",
    "five_yr_df.sort('start_date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_yr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_yr_df['MCC_post'].plot('o')\n",
    "#.plot(kind='scatter',x='start_date',y='AUC_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_yr_df.plot(kind='scatter',x='AUC_in',y='AUC_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = five_yr_df.plot(kind='scatter',y='AUC_in',x='class_frac_train')\n",
    "five_yr_df.plot(kind='scatter',y='AUC_post',x='class_frac_test',color='deeppink',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_yr_df.plot(kind='scatter',x='AUC_post',y='test_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.tools.plotting.scatter_matrix(five_yr_df[['Acc_in','AUC_in','Acc_post','AUC_post','class_frac_train','class_frac_test']], figsize=(10, 10), diagonal='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## look at the Five year time slices Data Frame\n",
    "* built on prediction of status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_yr_df.sort('AUC_post',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what are the features ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_yr_win_X = []\n",
    "five_yr_win_Y = []\n",
    "five_yr_win_mdl = []\n",
    "for a in xrange(0,len(five_year_windows_data)):\n",
    "    five_yr_win_X+=[x for x in five_year_windows_data[a][0]]\n",
    "    five_yr_win_Y+=[x for x in five_year_windows_data[a][1]]\n",
    "    five_yr_win_mdl+=[x for x in five_year_windows_models[a]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = empl.columns.tolist()\n",
    "for xname in ['status','sep_status','retired']:\n",
    "    feature_names.remove(xname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_yr_win_feature_importances = []\n",
    "for i,mdl in enumerate(five_yr_win_mdl):\n",
    "    five_yr_win_feature_importances.append(plotFI(mdl,feature_names))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(five_yr_win_feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_yr_win_feature_importances[15].sort('value',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what is the ratio of the test size to the train size?\n",
    "five_yr_df['tt_ratio'] = five_yr_df['test_size']/five_yr_df['train_size']\n",
    "five_yr_df.tt_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(five_yr_df['class_frac_train'],five_yr_df['AUC_post'],s=10/five_yr_df['tt_ratio'])\n",
    "plt.xlabel('Fraction of Train Set Separating')\n",
    "plt.ylabel('AUC on test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_yr_df[five_yr_df.AUC_post > 0.7].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for my_idx in [8,3,13,21,17]:\n",
    "    \n",
    "    plt.figure()\n",
    "    my_date = five_yr_df.loc[my_idx,'start_date']\n",
    "    plt.title(my_date)\n",
    "    five_yr_win_feature_importances[my_idx].sort('value',ascending=False)['value'].head(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repeat for 3 year intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "three_year_windows_df_list = []\n",
    "three_year_windows_data = []\n",
    "three_year_windows_models =[]\n",
    "# generate the datasets, models and begin analysis.\n",
    "for i in xrange(0,3):\n",
    "    print i, time_str_list[i::3]\n",
    "    dd,mdl,xsets,ysets = build_time_slice_models(empl,empl_dates,time_str_list[i::3],'status',temporal_cols)\n",
    "    three_year_windows_df_list.append(dd)\n",
    "    three_year_windows_data.append([xsets,ysets])\n",
    "    three_year_windows_models.append(mdl)\n",
    "    \n",
    "# join and sort the dataFrame\n",
    "three_yr_df = pd.concat(three_year_windows_df_list,ignore_index=True)\n",
    "three_yr_df.sort('start_date',inplace=True)\n",
    "# add colum for test-train ratio:\n",
    "three_yr_df['tt_ratio'] = three_yr_df['test_size']/three_yr_df['train_size']\n",
    "\n",
    "# now flatten output\n",
    "three_yr_win_X = []\n",
    "three_yr_win_Y = []\n",
    "three_yr_win_mdl = []\n",
    "for a in xrange(0,len(three_year_windows_data)):\n",
    "    three_yr_win_X+=[x for x in three_year_windows_data[a][0]]\n",
    "    three_yr_win_Y+=[x for x in three_year_windows_data[a][1]]\n",
    "    three_yr_win_mdl+=[x for x in three_year_windows_models[a]]\n",
    "\n",
    "# obtain the feature importances    \n",
    "three_yr_win_feature_importances = []\n",
    "for i,mdl in enumerate(three_yr_win_mdl):\n",
    "    three_yr_win_feature_importances.append(plotFI(mdl,feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(three_yr_df['class_frac_train'],three_yr_df['AUC_post'],s=10/three_yr_df['tt_ratio'],color='darkgoldenrod')\n",
    "plt.xlabel('Training Separated Fraction')\n",
    "plt.ylabel('Test AUC') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get top AUC results\n",
    "topAUCresults = three_yr_df[three_yr_df.AUC_post > 0.7].sort('AUC_post',ascending=False)\n",
    "top_idx_list = topAUCresults.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for my_idx in top_idx_list:    \n",
    "    plt.figure()\n",
    "    my_date = three_yr_df.loc[my_idx,'start_date']\n",
    "    my_auc = three_yr_df.loc[my_idx,'AUC_post']\n",
    "    plt.title('Start date: '+my_date+'  AUC= '+str(my_auc))\n",
    "    three_yr_win_feature_importances[my_idx].sort('value',ascending=False)['value'].head(10).plot(kind='barh',color='darkgoldenrod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(three_yr_win_Y[3][1]), three_yr_df.ix[3]['test_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at the Confusion matrices of some of these 'top results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for my_idx in top_idx_list:    \n",
    "    plt.figure()\n",
    "    my_date = three_yr_df.loc[my_idx,'start_date']\n",
    "    my_auc = three_yr_df.loc[my_idx,'AUC_post']\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.suptitle('Start date: '+my_date+'  AUC= '+str(my_auc))\n",
    "    sns.heatmap(metrics.confusion_matrix(three_yr_win_Y[my_idx][1],three_yr_win_mdl[my_idx].predict(three_yr_win_X[my_idx][1])),annot=True,fmt=\"d\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a general sense these models are UNDER predicting Separations ('1')\n",
    "* try to rescale the threshold using known results??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(three_yr_df['AUC_in'],three_yr_df['AUC_post'])\n",
    "plt.xlabel('AUC_vetted')\n",
    "plt.ylabel('AUC_test')\n",
    "plt.title('3 year windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iix = 22\n",
    "my_mdl = three_yr_win_mdl[iix]\n",
    "plot_roc_curve(three_yr_win_Y[iix][2],my_mdl.predict_proba(three_yr_win_X[iix][2]))\n",
    "plot_roc_curve(three_yr_win_Y[iix][1],my_mdl.predict_proba(three_yr_win_X[iix][1]))\n",
    "#plt.title('Within set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(metrics.confusion_matrix(three_yr_win_Y[iix][2],three_yr_win_mdl[iix].predict(three_yr_win_X[iix][2])),annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(three_yr_win_Y[iix][2],'o')\n",
    "#plt.figure()\n",
    "plt.plot(three_yr_win_mdl[iix].predict_proba(three_yr_win_X[iix][2])[:,0],'o',color='midnightblue',alpha=0.3)\n",
    "plt.plot(three_yr_win_mdl[iix].predict_log_proba(three_yr_win_X[iix][2])[:,0],'o',color='skyblue',alpha=0.3)\n",
    "plt.plot(three_yr_win_mdl[iix].predict(three_yr_win_X[iix][2]),'*',color='indianred',alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_pred_prob0 = three_yr_win_mdl[iix].predict_proba(three_yr_win_X[iix][2])[:,0]\n",
    "my_pred_logprob0 = three_yr_win_mdl[iix].predict_log_proba(three_yr_win_X[iix][2])[:,0]\n",
    "plt.hist(my_pred_prob0,range=[0,1],bins=50,color='darkorchid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.round(1-my_pred_prob0,0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_tru = three_yr_win_Y[iix][2]\n",
    "shift_pred = 1-my_pred_prob0 + 0.48#,np.round(x,0))\n",
    "#sns.heatmap(metrics.confusion_matrix(my_tru,shfit_pred),annot=True,fmt=\"d\")\n",
    "np.round(shift_pred,0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(metrics.confusion_matrix(my_tru,np.round(shift_pred,0)),annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.matthews_corrcoef(my_tru,np.round(shift_pred,0)),three_yr_df.ix[iix]['MCC_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_shift_pred = 1-(1-three_yr_win_mdl[iix].predict_proba(three_yr_win_X[iix][2]) + 0.48)\n",
    "plot_roc_curve(my_tru,my_shift_pred)#,np.round(x,0))plot_roc_curve(my_tru,shift_pred)\n",
    "plot_roc_curve(my_tru,three_yr_win_mdl[iix].predict_proba(three_yr_win_X[iix][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_test_y = three_yr_win_Y[iix][1]\n",
    "my_test_y_proba = my_mdl.predict_proba(three_yr_win_X[iix][1])\n",
    "my_test_y_pred = my_mdl.predict(three_yr_win_X[iix][1])\n",
    "my_shift_pred_int = np.round(1-my_test_y_proba[:,0]+0.48,0)\n",
    "metrics.matthews_corrcoef(my_test_y,my_shift_pred_int), three_yr_df.ix[iix]['MCC_post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "sns.heatmap(metrics.confusion_matrix(my_test_y,my_shift_pred_int),annot=True,fmt=\"d\")\n",
    "plt.title('After making shift')\n",
    "plt.subplot(122)\n",
    "sns.heatmap(metrics.confusion_matrix(my_test_y,my_test_y_pred),annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "three_yr_df.sort('MCC_post',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Aside predict retirements\n",
    "* same procedure of taking a range of time and holding out a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RET_measures = []\n",
    "RET_dsets = []\n",
    "RET_models = []\n",
    "for tslice in time_slices_range:\n",
    "    print tslice\n",
    "    X,y,Xtest,ytest,feature_names,fix_idx = create_time_split(empl,empl_dates,tslice,'retired',temporal_cols)\n",
    "    #extract accuracy set\n",
    "    X_acc,y_acc = create_accuracy_set(empl,fix_idx,'retired')\n",
    "    # do a single RF\n",
    "    single_rfc_500trees = ensemble.RandomForestClassifier(n_estimators=500,n_jobs=50)\n",
    "    rfc_mdl = single_rfc_500trees.fit(X,y) # fit on training data\n",
    "    RET_models.append(rfc_mdl)\n",
    "    RET_dsets.append([X,Xtest,X_acc,y,ytest,y_acc])\n",
    "    m_acc_a,m_acc_m,m_acc_r = calculate_metrics(rfc_mdl,y_acc,X_acc)\n",
    "    m_new_a,m_new_m,m_new_r = calculate_metrics(rfc_mdl,ytest,Xtest)\n",
    "    RET_measures.append([m_acc_a,m_acc_m, m_acc_r, m_new_a, m_new_m, m_new_r])\n",
    "    \n",
    "    \n",
    "# push the data/parameters into a small df\n",
    "RETrfmodels_df = pd.DataFrame(data=RET_measures,index=time_slices_range,columns=['Acc_in','MCC_in','AUC_in','Acc_post','MCC_post','AUC_post'])\n",
    "RETrfmodels_df.head()\n",
    "\n",
    "# transform to get the dataset sizes\n",
    "RETds_size = []\n",
    "for b in xrange(0,len(RET_dsets)):\n",
    "    RETds_size.append([len(RET_dsets[b][a]) for a in xrange(0,len(RET_dsets))])\n",
    "\n",
    "RETds_size=np.array(RETds_size) # convert to an array\n",
    "# add to the dataframe\n",
    "RETrfmodels_df['Train_size'] = RETds_size[:,0]\n",
    "RETrfmodels_df['in_size' ] = RETds_size[:,1]\n",
    "RETrfmodels_df['post_size'] = RETds_size[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RETrfmodels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at some jobcodes \n",
    "* 6200 == CRC CallRep\n",
    "* 1876, 1877 == QB Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(emplfull.JOBCODE==6200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplfull[emplfull.JOBCODE==6200]['JOB_FAMILY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(emplfull.JOB_FAMILY=='QBSREP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(emplfull.JOB_FAMILY=='CLMREP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(emplfull.JOB_FAMILY.unique()),len(empl.job_fcode.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(emplfull.JOBCODE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplfull[emplfull.JOBCODE==1876]['JOB_FAMILY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.columns[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rscrep_idx = emplfull[emplfull.JOB_FAMILY=='RSCREP'].index\n",
    "empl.ix[rscrep_idx].grade_code.unique(), empl.ix[rscrep_idx].job_fcode.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival Analysis (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## baseline KM Fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmf0 = KaplanMeierFitter()\n",
    "plt.figure(figsize=(14,6))\n",
    "kmf0.fit(emplfull.Tenure_months,event_observed=emplfull.status)\n",
    "kmf0.plot(color='darkslategray')\n",
    "plt.ylabel('Survival Distribution Function (Separation)')\n",
    "plt.xlabel('Tenure months')\n",
    "plt.title('KaplanMeier Survival: ALL employees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmf0 = KaplanMeierFitter()\n",
    "plt.figure(figsize=(14,6))\n",
    "kmf0.fit(emplfull.Tenure_months,event_observed=emplfull.status)\n",
    "kmf0.plot(color='darkslategray')\n",
    "plt.ylabel('Survival Distribution Function (Separation)')\n",
    "plt.xlabel('Tenure months')\n",
    "plt.title('KaplanMeier Survival: ALL employees')\n",
    "plt.xlim(0,96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "job_family_value_counts = emplfull.JOB_FAMILY.value_counts()\n",
    "job_family_value_counts[job_family_value_counts > 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# work with those Job_families that have more than 700 members\n",
    "job_family_value_counts[job_family_value_counts > 700].sum(), len(job_family_value_counts[job_family_value_counts > 700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create groups\n",
    "jfam_grps = job_family_value_counts.iloc[:23].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jfam_index_dict = {}\n",
    "for family in jfam_grps:\n",
    "    jfam_index_dict[family] = emplfull[emplfull.JOB_FAMILY == family].index.tolist()\n",
    "print len(jfam_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplfull.Tenure_months.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tenure_month_range = [0,600]\n",
    "tenure_month_range = np.linspace(0,600,601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list = ['darkmagenta','midnightblue','darkolivegreen','darkgreen','darkred','aquamarine',\n",
    "            'deeppink','darkorange','darksalmon','darkturquoise','darkkhaki','lime','darkgoldenrod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jfam_grps[1], len(jfam_index_dict[jfam_grps[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,16))\n",
    "ax1 = fig.add_subplot(411)\n",
    "ax2 = fig.add_subplot(412)\n",
    "ax3 = fig.add_subplot(413)\n",
    "ax4 = fig.add_subplot(414)\n",
    "kmf_jf0 = KaplanMeierFitter()\n",
    "kmf_jf0.fit(emplfull.Tenure_months, timeline=tenure_month_range, event_observed=emplfull.status,label='All')\n",
    "jfcn_sf_df = pd.DataFrame(kmf_jf0.survival_function_)\n",
    "#ax = fig.add_subplot(111)\n",
    "kmf_jf0.plot(ax=ax1,c='darkslategray')\n",
    "kmf_jf0.plot(ax=ax2,c='darkslategray')\n",
    "kmf_jf0.plot(ax=ax3,c='darkslategray')\n",
    "kmf_jf0.plot(ax=ax4,c='darkslategray')\n",
    "for jfx in xrange(0,23):#[1,2,3,4,5,6]:#jfx = 1\n",
    "    jf = jfam_grps[jfx]\n",
    "    jfid = jfam_index_dict[jf]\n",
    "    print jfx,jf,len(jfid)\n",
    "    kmf_jf0.fit(emplfull.Tenure_months.ix[jfid], timeline=tenure_month_range, event_observed=emplfull.status.ix[jfid],label=jf)\n",
    "#kmf_mgr1.fit(vc_empl4[~mgrA].Tenure_months, timeline=tenure_month_range,event_observed=vc_empl4[~mgrA].status,label='non-')\n",
    "    if jfx % 4 == 0:\n",
    "        ax = ax1\n",
    "    elif jfx % 4 == 1:\n",
    "        ax = ax2\n",
    "    elif jfx % 4 == 2:\n",
    "        ax = ax3\n",
    "    else:\n",
    "        ax= ax4\n",
    "    cname = col_list[jfx % len(col_list)]\n",
    "    #if jfx > len(col_list):\n",
    "    #    cname = col_list[jfx % 7]\n",
    "    kmf_jf0.plot(ax=ax,color=cname)\n",
    "    jfcn_sf_df = pd.concat([jfcn_sf_df,kmf_jf0.survival_function_],axis=1)\n",
    "\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Repeat looking only at <= 8 years == 96 months\n",
    "fig = plt.figure(figsize=(12,16))\n",
    "ax1 = fig.add_subplot(411)\n",
    "ax2 = fig.add_subplot(412)\n",
    "ax3 = fig.add_subplot(413)\n",
    "ax4 = fig.add_subplot(414)\n",
    "subplot_axis_list = [ax1, ax2, ax3, ax4]\n",
    "kmf_jf0 = KaplanMeierFitter()\n",
    "kmf_jf0.fit(emplfull.Tenure_months, timeline=tenure_month_range, event_observed=emplfull.status,label='All')\n",
    "jfcn_sf_df = pd.DataFrame(kmf_jf0.survival_function_)\n",
    "#ax = fig.add_subplot(111)\n",
    "kmf_jf0.plot(ax=ax1,c='darkslategray')\n",
    "kmf_jf0.plot(ax=ax2,c='darkslategray')\n",
    "kmf_jf0.plot(ax=ax3,c='darkslategray')\n",
    "kmf_jf0.plot(ax=ax4,c='darkslategray')\n",
    "for jfx in xrange(0,23):#[1,2,3,4,5,6]:#jfx = 1\n",
    "    jf = jfam_grps[jfx]\n",
    "    jfid = jfam_index_dict[jf]\n",
    "    print jfx,jf,len(jfid)\n",
    "    kmf_jf0.fit(emplfull.Tenure_months.ix[jfid], timeline=tenure_month_range, event_observed=emplfull.status.ix[jfid],label=jf)\n",
    "#kmf_mgr1.fit(vc_empl4[~mgrA].Tenure_months, timeline=tenure_month_range,event_observed=vc_empl4[~mgrA].status,label='non-')\n",
    "    if jfx % 4 == 0:\n",
    "        ax = ax1\n",
    "    elif jfx % 4 == 1:\n",
    "        ax = ax2\n",
    "    elif jfx % 4 == 2:\n",
    "        ax = ax3\n",
    "    else:\n",
    "        ax= ax4\n",
    "    cname = col_list[jfx % len(col_list)]\n",
    "    #if jfx > len(col_list):\n",
    "    #    cname = col_list[jfx % 7]\n",
    "    kmf_jf0.plot(ax=ax,color=cname)\n",
    "    jfcn_sf_df = pd.concat([jfcn_sf_df,kmf_jf0.survival_function_],axis=1)\n",
    "[my_ax.set_xlim([0,96]) for my_ax in subplot_axis_list]\n",
    "plt.ylim(0,1.05)\n",
    "#plt.xlim(0,96)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jfcn_sf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about hazards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cf_tenure = CoxPHFitter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myCols = ['HAVE_INS','SEX','Age_years','job_fcode','Tenure_years','status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cf_tenure.fit(empl[myCols],'Tenure_years',event_col ='status')\n",
    "cf_tenure.hazards_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.exp(cf_tenure.hazards_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_tenure.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_tenure.baseline_cumulative_hazard_.ix[:6].diff().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_tenure.confidence_intervals_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_tenure.baseline_hazard_.ix[:6].plot()\n",
    "##plt.ylim(0,1)\n",
    "#plt.xlim(0,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so this is fine  -- except that job_fcode is label encoded but not in a meaningful (i.e. ordinal way)\n",
    "* Better to treat it as categorical. \n",
    "* 1456 categories seems like a lot. Lookint at KMF above for top 23 categories each contain more than 7000 members and account for 72% of the observations.\n",
    "* create a function to group these better?!\n",
    "    - there are 272 job_families that have only 1 member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \" there are {0} job_fcode (JOB_FAMILYs) that have only 1 element\".format(sum(empl.job_fcode.value_counts() == 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \" there are {0} job_fcode (JOB_FAMILYs) that have only 2 elements\".format(sum(empl.job_fcode.value_counts() == 2))\n",
    "print \" there are {0} job_fcode (JOB_FAMILYs) that have only 3 elements\".format(sum(empl.job_fcode.value_counts() == 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplfull.JOB_FAMILY.value_counts().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplfull[emplfull.JOB_FAMILY == 'FSCCRD'][['GRADE', 'JOBCODE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplfull[emplfull.JOBCODE == 90][['GRADE','JOB_FAMILY','status','TERMINATION_DT','JOBCODE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplfull[emplfull.JOBCODE == 36].GRADE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " emplfull.JOBCODE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import patsy\n",
    "Xll = patsy.dmatrix('Age_years + SEX + C(job_fcode) +HAVE_INS + SAL1', empl, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print Xll.shape\n",
    "Xll['T' ] =empl.Tenure_years\n",
    "Xll['E'] = empl.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at which categorical job_fcodes have more than 500 members "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_job_fcode_to_keep = [x for x in Xll.columns if x.startswith('C(job') and sum(Xll[x]) >= 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_to_keep =['Age_years','SEX','HAVE_INS','SAL1','T','E']\n",
    "col_to_keep += cat_job_fcode_to_keep\n",
    "len(col_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "cf = CoxPHFitter()\n",
    "cf.fit(Xll[col_to_keep],'T',event_col ='E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplfull.JOB_FAMILY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### plot the cumulative hazards\n",
    "#cf.baseline_survival_.ix[:8].plot()\n",
    "cf.baseline_cumulative_hazard_.ix[:8].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expbeta = np.exp(cf.hazards_).T\n",
    "expbeta.sort('coef',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#C(job_fcode)[T.885]\t1.243266\n",
    "#C(job_fcode)[T.1108]\t1.172821\n",
    "#C(job_fcode)[T.327]\t1.139246\n",
    "#C(job_fcode)[T.1061]\t1.124839\n",
    "#C(job_fcode)[T.796]\n",
    "top_hazard_job_fcode = [885,1108,327,1061,796]\n",
    "\n",
    "for code in top_hazard_job_fcode:\n",
    "    jfcd_cat = 'C(job_fcode)[T.'+str(code)+']'\n",
    "    expHazard = expbeta.ix[jfcd_cat].values[0]\n",
    "    case1 = empl[empl['job_fcode']==code].index[0]\n",
    "    print code, len(empl[empl['job_fcode']==code]), emplfull.ix[case1].JOB_FAMILY,expHazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expbeta.ix[jfcd_cat].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to group singletons of a categorical object\n",
    "def truncate_categorical(df,column,min_thresh,group_singletons=True):\n",
    "    vc = df.column.value_counts()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lifelines.utils import k_fold_cross_validation\n",
    "\n",
    "cf = CoxPHFitter()\n",
    "#empl[myCols],'Tenure_years',event_col ='status')\n",
    "scores = k_fold_cross_validation(cf, empl[myCols], 'Tenure_years', event_col='status', k=3)\n",
    "print scores\n",
    "print scores.mean()\n",
    "print scores.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lifelines import AalenAdditiveFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_tenure = AalenAdditiveFitter(penalizer=1.0, fit_intercept = True)\n",
    "aaf_tenure.fit(Xll, 'T','E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_tenure.hazards_['Age_years'].ix[:8].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_tenure.hazards_['job_fcode'].ix[:5].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#aaf_tenure.plot(columns=['baseline','Age_years','INTERN','SEX','ANNUAL_RT'],ix=slice(1,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_tenure.hazards_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_tenure.smoothed_hazards_()[['job_fcode','SAL1']].ix[:5].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmf_jfothr = KaplanMeierFitter()\n",
    "fnm = 'BOMISD'\n",
    "kmf_jfothr.fit(emplfull[emplfull['JOB_FAMILY']==fnm].Tenure_months, timeline=tenure_month_range, event_observed=emplfull[emplfull['JOB_FAMILY']=='SAKBSY'].status,label=fnm)\n",
    "kmf_jfothr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin prediction of tenure year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try RF regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = empl3['Tenure_years'].values.astype(np.float)\n",
    "df = empl3.drop(['Tenure_years','status','sep_status','retired'],axis=1).copy()\n",
    "X = df.as_matrix().astype(np.float)\n",
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_tenure_class = pd.cut(empl3.Tenure_years,np.arange(0,empl3.Tenure_years.max()+1,1))\n",
    "y_tenure_class = pd.cut(empl2.Tenure_years,[0,1,3,5,10,15,25,200],labels=False,right=False)#,labels=[1,2,3,4,5,6,7,8])#.values\n",
    "#y_tenure_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.value_counts(y_tenure_class).plot(kind='bar')#.reindex(y_tenure_class.levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tenure_years classes = {0:[0,1),1:[1,3),2:[3,5),3:[5,10),4:[10,15),5:[15,25),6:[25,end)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print('RF Classifier: {:.2f}'.format(metrics.accuracy_score(y_tenure_class, kfold_cv(X, y_tenure_class, ensemble.RandomForestClassifier))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_conf_matrix = metrics.confusion_matrix(y_tenure_class, kfold_cv(X, y_tenure_class, ensemble.RandomForestClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(rfc_conf_matrix, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "forest = ensemble.ExtraTreesClassifier(n_jobs=20)\n",
    "forest.fit(X,y_tenure_class)\n",
    "importances= forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest_std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = df.columns[indices].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for f in range(20):\n",
    "nfeat = 30\n",
    "plt.barh(range(nfeat),importances[indices[:nfeat]],yerr=forest_std[indices[:nfeat]],align=\"center\")\n",
    "plt.yticks(range(nfeat),feature_names[:nfeat])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now take this model and predict into the future:\n",
    "* first define set of currently employeed (not-separated) employees\n",
    "* augment time_sensitive measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_active = empl3[empl3.status == 0].copy()\n",
    "empl_active.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl3[temporal_cols[:-3]].apply(lambda x: x+12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = empl3.drop(['Tenure_years','status','sep_status','retired'],axis=1).copy()\n",
    "X = df.as_matrix().astype(np.float)\n",
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_tenure_class = y_tenure_class[empl_active.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_active[empl_active.REMOTE==0].TELE_MOS.values.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_for_prediction(df,time_columns,delta_time=0.0,cols_to_drop = ['Tenure_years','status','sep_status','retired']):\n",
    "    monthly_cols = [x for x in time_columns if x.endswith('MOS')]\n",
    "    d2 = df.copy()\n",
    "    d2[monthly_cols[:-1]]= df[monthly_cols[:-1]].apply(lambda x: x+12.0*delta_time)\n",
    "    # special column is TELE_MOS\n",
    "    d2[d2.REMOTE==1][monthly_cols[-1]] = df[df.REMOTE==1][monthly_cols[-1]].apply(lambda x:x+delta_time*12.0)\n",
    "    \n",
    "    annual_cols = [x for x in time_columns if x.endswith('years')]\n",
    "    d2[annual_cols]=df[annual_cols].apply(lambda x: x+1.0*delta_time)\n",
    "    d2.drop(cols_to_drop,axis=1,inplace=True)\n",
    "    X = d2.as_matrix().astype(np.float)\n",
    "    print X.shape\n",
    "    return X,df.Tenure_years.values+1.0*delta_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myX,myY = prep_for_prediction(empl_active,temporal_cols,delta_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myY[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_tenure_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest.predict(myX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest.predict_proba(myX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_active['Tenure_years'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## May 12, 2015 \n",
    "### Attempt RandomForest Regressor (of Tenure Years)\n",
    "1. use all data --> simple test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_fraction = 0.3\n",
    "X_train, X_test , y_train, y_test = cross_validation.train_test_split(X,y,test_size=test_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "RFR = ensemble.RandomForestRegressor(n_estimators=200,max_features=\"sqrt\",n_jobs=30)\n",
    "RFR.fit(X_train,y_train)\n",
    "RFR_importances= RFR.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RFR.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RFR_importances_std = np.std([tree.feature_importances_ for tree in RFR.estimators_], axis=0)\n",
    "RFR_indices = np.argsort(RFR_importances)[::-1]\n",
    "RFR_feature_names = df.columns[RFR_indices].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for f in range(20):\n",
    "nfeat = 30\n",
    "plt.barh(range(nfeat),RFR_importances[RFR_indices[:nfeat]],yerr=RFR_importances_std[RFR_indices[:nfeat]],color='darkturquoise')#align=\"center\")\n",
    "plt.yticks(range(nfeat),RFR_feature_names[:nfeat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obtain_feature_importances(classifier,plot_flag=True):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make a scatter plot of the prediction and actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_prediction = RFR.predict(X)\n",
    "plt.scatter(y,y_prediction,alpha=0.3)\n",
    "plt.xlabel('True Tenure (years)')\n",
    "plt.ylabel('Predicted Tenure (years)')\n",
    "x_line_val = np.arange(0,60)\n",
    "plt.plot(x_line_val,x_line_val,lw=3,color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#zoom in on <=10 years\n",
    "y_prediction = RFR.predict(X)\n",
    "plt.scatter(y,y_prediction,alpha=0.3)\n",
    "plt.xlabel('True Tenure (years)')\n",
    "plt.ylabel('Predicted Tenure (years)')\n",
    "x_line_val = np.arange(0,11)\n",
    "plt.plot(x_line_val,x_line_val,lw=3,color='k')\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at current employees.\n",
    "np.shape(y[empl_active.index]), np.shape(X[empl_active.index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_active_pred = RFR.predict(X[empl_active.index,:])\n",
    "plt.scatter(y[empl_active.index],y_active_pred,alpha=0.3,color='chocolate')\n",
    "plt.xlabel('True Tenure (years)')\n",
    "plt.ylabel('Predicted Tenure (years)')\n",
    "x_line_val = np.arange(0,11)\n",
    "plt.plot(x_line_val,x_line_val,lw=3,color='k')\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_for_prediction(df,time_columns,delta_time=0.0,cols_to_drop = ['Tenure_years','status','sep_status','retired']):\n",
    "    monthly_cols = [x for x in time_columns if x.endswith('MOS')]\n",
    "    d2 = df.copy()\n",
    "    d2[monthly_cols[:-1]]= df[monthly_cols[:-1]].apply(lambda x: x+12.0*delta_time)\n",
    "    # special column is TELE_MOS\n",
    "    d2[d2.REMOTE==1][monthly_cols[-1]] = df[df.REMOTE==1][monthly_cols[-1]].apply(lambda x:x+delta_time*12.0)\n",
    "    \n",
    "    annual_cols = [x for x in time_columns if x.endswith('years')]\n",
    "    d2[annual_cols]=df[annual_cols].apply(lambda x: x+1.0*delta_time)\n",
    "    d2.drop(cols_to_drop,axis=1,inplace=True)\n",
    "    X = d2.as_matrix().astype(np.float)\n",
    "    print X.shape\n",
    "    return X,df.Tenure_years.values+1.0*delta_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RFR.score(X[empl_active.index,:],y[empl_active.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what about applying this model to a future workforce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_future_workforce(df,time_columns,delta_time=0.0,cols_to_drop = ['Tenure_years','status','sep_status','retired']):\n",
    "    # deal with monthly columns\n",
    "    monthly_cols = [x for x in time_columns if x.endswith('MOS')]\n",
    "    d2 = df.copy()\n",
    "    d2[monthly_cols[:-1]]= df[monthly_cols[:-1]].apply(lambda x: x+12.0*delta_time)\n",
    "    # special column is TELE_MOS\n",
    "    d2.loc[d2.REMOTE==1,monthly_cols[-1]] = df[df.REMOTE==1][monthly_cols[-1]].apply(lambda x:x+delta_time*12.0)\n",
    "    #deal with annual columns\n",
    "    annual_cols = [x for x in time_columns if x.endswith('years')]\n",
    "    d2[annual_cols]=df[annual_cols].apply(lambda x: x+1.0*delta_time)\n",
    "    d2.drop(cols_to_drop,axis=1,inplace=True)\n",
    "    X = d2.as_matrix().astype(np.float)\n",
    "    print X.shape\n",
    "    return X,df.Tenure_years.values+1.0*delta_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myX,future_y = create_future_workforce(empl_active,temporal_cols,delta_time=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "future_y[:4], y[empl_active.index[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_active_pred = RFR.predict(X[empl_active.index,:])\n",
    "plt.scatter(y[empl_active.index],y_active_pred,alpha=0.3,color='lightgreen')\n",
    "plt.xlabel('True Tenure (years)')\n",
    "plt.ylabel('Predicted Tenure (years)')\n",
    "x_line_val = np.arange(0,61)\n",
    "plt.plot(x_line_val,x_line_val,lw=3,color='k')\n",
    "#plt.xlim(0,10)\n",
    "#plt.ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_active_pred_one = RFR.predict(myX)\n",
    "plt.scatter(future_y,y_active_pred_one,alpha=0.3,color='chocolate')\n",
    "plt.xlabel('True Tenure (years)')\n",
    "plt.ylabel('Predicted Tenure (years)')\n",
    "x_line_val = np.arange(0,61)\n",
    "plt.plot(x_line_val,x_line_val,lw=3,color='k')\n",
    "#plt.xlim(0,10) \n",
    "#plt.ylim(0,10)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "y_temp = (np.vstack([future_y, np.ones(len(future_y))])).T\n",
    "#np.shape(y_temp)\n",
    "lm.fit(y_temp,y_active_pred_one)\n",
    "\n",
    "# print intercept and coefficients\n",
    "print lm.intercept_\n",
    "print lm.coef_\n",
    "xx = np.linspace(0,60,120)\n",
    "yy = lm.intercept_+lm.coef_[0]*xx\n",
    "plt.plot(xx,yy,lw=2,color='mediumvioletred')\n",
    "r2 = metrics.r2_score(future_y,y_active_pred_one)\n",
    "mse = np.mean((y_active_pred_one- future_y)**2)\n",
    "print \" R^2 is {0} and MSE is {1}\".format(r2, mse)\n",
    "# plot an interval around this of 1 year\n",
    "ci_alpha = 0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(y_active_pred_one), np.shape(future_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.OLS(y_active_pred_one,future_y)\n",
    "results = model.fit()\n",
    "print \" Parameters are: \"\n",
    "print results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_one_mat = np.array(y_active_pred_one)\n",
    "np.shape(pred_one_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm.fit(y_temp\n",
    "       ,future_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(future_y - y_active_pred_one,color='crimson',bins=30)\n",
    "plt.xlabel('Difference between future tenure and predicted tenure')\n",
    "plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare to ExtraTreesRegressor and Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## so next question is whether or not there are differences in terms of the individuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approach:\n",
    "### Simply classify as separated or not --> status is target variable\n",
    "* use reduced dataset\n",
    "* whiten the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = empl3['status'].values.astype(np.float)\n",
    "df = empl3.drop(['sep_status','retired','status'],axis=1).copy()\n",
    "X = df.as_matrix().astype(np.float)\n",
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"Fraction of separated: {0}\".format(sum(y)/float(len(y)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocess this data set (whiten it)\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## define my classifiers\n",
    "classifiers_list = [\n",
    "    linear_model.PassiveAggressiveClassifier,\n",
    "    linear_model.LogisticRegression,\n",
    "    neighbors.KNeighborsClassifier,\n",
    "    svm.SVC,\n",
    "    tree.DecisionTreeClassifier,\n",
    "    ensemble.RandomForestClassifier,\n",
    "    ensemble.GradientBoostingClassifier]\n",
    "\n",
    "#neighbors.KNeighborsClassifier(n_neighbors=3),\n",
    "#    svm.SVC(kernel=\"linear\", C=0.025),\n",
    "#    svm.SVC(gamma=2, C=1),\n",
    "#    tree.DecisionTreeClassifier(max_depth=10,max_features='auto'),\n",
    "#    ensemble.RandomForestClassifier(max_depth=10, n_estimators=500, max_features='auto',n_jobs=30),\n",
    "#    ensemble.GradientBoostingClassifier(),\n",
    "    #AdaBoostClassifier(),\n",
    "    #linear_model.LogisticRegression()]\n",
    "    #GaussianNB(),\n",
    "    #LDA(),\n",
    "    #QDA()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = kfold_cv(X,y,classifiers_list[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc_score = metrics.accuracy_score(y,y_pred)\n",
    "print auc_score, classifiers_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Dump Classifier: {:.2f}'.format(metrics.accuracy_score(y, [0 for ii in y.tolist()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc_conf_matrix_tenure = metrics.confusion_matrix(y,y_pred)\n",
    "sns.heatmap(rfc_conf_matrix_tenure, annot=True,  fmt='')\n",
    "plt.title('Random Forest Classifier Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## okay so what are the features responsible for this??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_cv2(X, y, clf_class, shuffle=True, n_folds=10, **kwargs):\n",
    "    k_fold = cross_validation.KFold(len(y), n_folds=n_folds, shuffle=shuffle)\n",
    "    #y_pred = y.copy()\n",
    "    kf_fits = []\n",
    "    for ii, jj in k_fold:\n",
    "        X_train, X_test = X[ii], X[jj]\n",
    "        y_train = y[ii]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        kf_fits.append(clf)\n",
    "        #y_pred[jj] = clf.predict(X_test)\n",
    "    return k_fold,kf_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf_rfc,kf_fits = kfold_cv2(X,y,classifiers_list[-2])\n",
    "print len(kf_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf_fits[0].get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to plot feature_importances for RF\n",
    "def plotFI(forest,featureNames=[]):\n",
    "    featureImportances=forest.feature_importances_\n",
    "    # sort the importances from biggest to least\n",
    "    indices = np.argsort(featureImportances)[::-1]\n",
    "    estimators = forest.estimators_\n",
    "    # calculate the variance over the forest \n",
    "    \n",
    "    std = np.std([tree.feature_importances_ for tree in estimators],axis=0)\n",
    "    # print summary statement\n",
    "    nfeatures = len(featureImportances)\n",
    "    print(\"Number of Features: %d\" % (nfeatures))\n",
    "    print(\"Number of Trees: %d\" %(len(estimators)))\n",
    "    \n",
    "    #print featureNames\n",
    "    if len(featureNames)==0:\n",
    "        featureNames = map(str,indices)\n",
    "    \n",
    "    fN2 = [featureNames[a] for a in indices]\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(len(indices)):\n",
    "        print(\"%d. feature %d=%s (%f)\" % (f + 1, indices[f], featureNames[indices[f]],featureImportances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    # define a cutoff in terms of feature_importance\n",
    "    if nfeatures <= 30:\n",
    "        kfeatures = nfeatures # keep all if smaller than 30\n",
    "    else:\n",
    "        kfeatures = 30\n",
    "        \n",
    "    kindices = indices[:kfeatures]\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.barh(range(len(kindices)), featureImportances[kindices],\n",
    "       color=\"steelblue\", xerr=std[kindices], align=\"center\",ecolor='k')#,lw=2)\n",
    "    plt.yticks(range(len(kindices)),fN2)\n",
    "    #grid(True)\n",
    "    c1 = 'value'\n",
    "    c2 = 'std'\n",
    "    tdata = np.vstack([featureImportances[indices],std[indices]])\n",
    "    df = pd.DataFrame(data = tdata.T,index=fN2,columns=[c1,c2])\n",
    "    return df\n",
    "                      #indices, std\n",
    "    #xticks(range(len(indices)), indices)\n",
    "#xlim([-1, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### push all of the feature importances to a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fivehund_5= plotFI(kf_fits500[5],df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fivehund_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_hundred_feature_importances = []\n",
    "for mdl in kf_fits500:\n",
    "    five_hundred_feature_importances.append(plotFI(mdl,df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fhfeature = pd.concat(five_hundred_feature_importances,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fhfeature.columns = ['M1value','M1std','M2value','M2std','M3value','M3std','M4value','M4std','M5value','M5std',\n",
    "                     'M6value','M6std','M7value','M7std','M8value','M8std','M9value','M9std','M10value','M10std']\n",
    "fhfeature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "value_columns = [x for x in fhfeature.columns if x.endswith('value')]\n",
    "fhfeature[value_columns].mean(axis=1).order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fhfeature[value_columns].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for mx in value_columns:\n",
    "    print fhfeature[fhfeature[mx] == fhfeature[mx].max()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.HAVE_INS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_active.HAVE_INS.value_counts(), empl_sep.HAVE_INS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[kf_fits500[a].predict_proba(activX[1]) for a in xrange(0,len(kf_fits500))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[kf_fits500[a].predict_proba(separX[1]) for a in xrange(0,len(kf_fits500))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### does a great job of predicitng the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf_fits500[5].feature_importances_[indxa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_feature_importances(forest,column_names):\n",
    "    importances= forest.feature_importances_\n",
    "    importances_std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    feature_names = column_names[indices].tolist()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotFI(kf_fits[0],df.columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotFI(kf_fits[1],df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotFI(kf_fits[2],df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob = np.zeros((len(y),2))\n",
    "for ii, jj in kf:\n",
    "        X_train, X_test = X[ii], X[jj]\n",
    "        y_train = y[ii]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_prob[jj] = clf.predict_proba(X_test)\n",
    "        # so the prediction for the jj_th row is the prediction against the other set.\n",
    "    return y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_prob = np.zeros((len(y),2))\n",
    "for idx,(ii, jj) in enumerate(kf_rfc):\n",
    "    #print len(ii), len(jj)#, idx\n",
    "    X_train, X_test = X[ii],X[jj]\n",
    "    #y_train = y[ii]\n",
    "    print idx,\"\\t\",kf_fits[idx].score(X_test,y[jj])\n",
    "    y_prob[jj] = kf_fits[idx].predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(target_test, target_predicted_proba):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "    \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "10*(len(jj)+1)-1 == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y,y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_active.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_sep  =empl3[empl3.status == 1].copy()\n",
    "empl_sep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#separX = empl_sep[df.columns].as_matrix().astype(np.float) # DONT\" DO THIS I scaled X first; use the following assignment\n",
    "separX = X[empl_sep.index,:]\n",
    "activX = X[empl_active.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#activX = empl_active[df.columns].as_matrix().astype(np.float)\n",
    "activy = y[empl_active.index]# = df.as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf_fits[1].predict_proba(activX)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf_fits[1].predict_proba(separX)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf_rfc500,kf_fits500 = kfold_cv2(X,y,classifiers_list[-2],n_jobs=30,n_estimators=500)\n",
    "print len(kf_fits500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "kf_rfc1k,kf_fits1k= kfold_cv2(X,y,classifiers_list[-2],n_jobs=50,n_estimators=1000)\n",
    "print len(kf_fits1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_prob_1k = np.zeros((len(y),2))\n",
    "for idx,(ii, jj) in enumerate(kf_rfc1k):\n",
    "    #print len(ii), len(jj)#, idx\n",
    "    X_train, X_test = X[ii],X[jj]\n",
    "    #y_train = y[ii]\n",
    "    print idx,\"\\t\",kf_fits1k[idx].score(X_test,y[jj])\n",
    "    y_prob_1k[jj] = kf_fits1k[idx].predict_proba(X_test)\n",
    "print \"__________________________\"\n",
    "plot_roc_curve(y,y_prob_1k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for 1000 trees, get feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importances_list_1k= []\n",
    "for mdl in kf_fits1k:\n",
    "    feature_importances_list_1k.append(plotFI(mdl,df.columns))\n",
    "fi_1k_df = pd.concat(feature_importances_list_1k,axis=1)\n",
    "fi_1k_df.columns = fhfeature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.MIN_RT_ANNUAL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the most important feature: 'FUNC_CNT'\n",
    "* this is the number of employees with the same give function\n",
    "* index # is 52\n",
    "* range shown below\n",
    "* plot the unscaled versus scaled\n",
    "* plot histogram of values in active vs inactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_index = list(fi_1k_df.index).index('FUNC_CNT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print fc_index, fi_1k_df.ix[fc_index].name\n",
    "X[:,52].min(), X[:,52].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_scaled_range = [X[:,fc_index].min(),X[:,fc_index].max()]\n",
    "fc_unscaled_range = [df['FUNC_CNT'].min(),df['FUNC_CNT'].max()]\n",
    "#:,fc_index].min(),X[:,fc_index].max()]\n",
    "print fc_scaled_range, fc_unscaled_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X[:,fc_index])\n",
    "len(df['FUNC_CNT'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['FUNC_CNT'].values,X[:,fc_index],alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(activX[:,52],range=fc_scaled_range,normed=True,bins=30)\n",
    "plt.hist(separX[:,52],range=fc_scaled_range,normed=True,alpha=0.5,bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try applying all models to the test case and checking result.\n",
    "* predict is a nX1 array; value of 0 means class 0, value of 1 means class 1.\n",
    "* predict proba is a nX2 array; 1st column is prediction for class 0.\n",
    "* average over this value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class0_pred = [rf_model.predict(activX) for rf_model in kf_fits]\n",
    "avg_class0_pred_active = np.mean(np.vstack(class0_pred).T, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class0_pred_sep = [rf_model.predict(separX) for rf_model in kf_fits]\n",
    "avg_class0_pred_sep = np.mean(np.vstack(class0_pred_sep).T, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_class0_pred_sep = np.min(np.vstack(class0_pred_sep).T, axis=1)\n",
    "min_class0_pred_sep.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class0_pred_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_sep['status'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.min(avg_class0_pred_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_val = np.min([np.min(avg_class0_pred_active),np.min(avg_class0_pred_sep)])\n",
    "max_val = np.max([np.max(avg_class0_pred_active),np.max(avg_class0_pred_sep)])\n",
    "plt.hist(avg_class0_pred_active,bins=30,range=[min_val,max_val],color='indianred')\n",
    "plt.hist(avg_class0_pred_sep,bins=30,range=[min_val,max_val],color='steelblue',alpha= 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AH THIS IS WHAT I EXPECTED -- clear separation between the active and retired (see above figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# May 14, 2015\n",
    "## Repeat RF with unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape, empl.shape, empl2.shape, empl3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u = empl3.status.as_matrix().astype(np.int)\n",
    "df = empl3.drop(['status','sep_status','retired'],axis=1).copy()\n",
    "V = df.as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf1k_kfold,rf1k_kfoldfits= kfold_cv2(V,u,classifiers_list[-2],n_jobs=50,n_estimators=1000)\n",
    "print len(rf1k_kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curve and get AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_kfold_proba(X,y,kfold_mdl,kfold_fits):\n",
    "    y_proba = np.zeros((len(y),2))\n",
    "    for idx,(ii,jj) in enumerate(kfold_mdl):\n",
    "        X_train, X_test = X[ii],X[jj]\n",
    "        print idx, \"\\t\", kfold_fits[idx].score(X_test,y[jj])\n",
    "        y_proba[jj] = kfold_fits[idx].predict_proba(X_test)\n",
    "    print \"++++++++++++++++++++++++++++++\"\n",
    "    return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_prob_1k = return_kfold_proba(V,u, rf1k_kfold,rf1k_kfoldfits)\n",
    "\n",
    "plot_roc_curve(u,u_prob_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_1knew_list = []\n",
    "for mdl in rf1k_kfoldfits:\n",
    "    fi_1knew_list.append(plotFI(mdl,df.columns))\n",
    "    \n",
    "# join these together\n",
    "fi_1krf_df = pd.concat(fi_1knew_list,axis=1)\n",
    "fi_1krf_df.columns = fhfeature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activV = V[empl_active.index,:]\n",
    "separV = V[empl_sep.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.FUNC_CNT.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl3[empl3.FUNC_CNT == 1].status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(activV[:,52],range=fc_unscaled_range,normed=True,bins=30)\n",
    "#plt.hist(separV[:,52],range=fc_unscaled_range,normed=True,alpha=0.5,bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try omitting FUNC_CNT and EXTFUNC_CNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = empl3.drop(['status','sep_status','retired','FUNC_CNT','EXTFUNC_CNT'],axis=1).copy()\n",
    "Z = df3.as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf500new,rf500fits= kfold_cv2(Z,u,classifiers_list[-2],n_jobs=50,n_estimators=500)\n",
    "#print len(rf1k_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_prob500n = return_kfold_proba(Z,u, rf500new, rf500fits)\n",
    "\n",
    "plot_roc_curve(u,u_prob500n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_500new_list = []\n",
    "for mdl in rf500fits:\n",
    "    fi_500new_list.append(plotFI(mdl,df3.columns))\n",
    "    \n",
    "# join these together\n",
    "rffi_500n_df = pd.concat(fi_500new_list,axis=1)\n",
    "rffi_500n_df.columns = fhfeature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rffi_500n_df[value_columns].sort([value_columns[0]],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rffi_500n_df[value_columns].mean(axis=1).order().tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so apply time-shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temporal_cols_indices = [list(rffi_500n_df.index).index(tc) for tc in temporal_cols]\n",
    "[(tc, list(rffi_500n_df.index).index(tc)) for tc in temporal_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx,tci in enumerate(temporal_cols_indices):\n",
    "    print temporal_cols[idx],Z[:,tci].min(),Z[:,tci].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activZ = Z[empl_active.index,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temporal_cols_indices[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## time shift rules\n",
    "tdelta = 3.0\n",
    "p3_actZ = activZ\n",
    "p3_actZ[:,temporal_cols_indices[:6]] = activZ[:,temporal_cols_indices[:6]]+12.0*tdelta\n",
    "p3_actZ[:,[1,97]] = p3_actZ[:,[1,97]]+tdelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "u_act = u[empl_active.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_active_pred3_a = rf500fits[0].pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_active_pred_a = rf500fits[0].predict(p1_actZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(u_active_pred_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[rf500fits[a].predict_proba(p3_actZ[400])[:,0] for a in xrange(0,len(rf500fits))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[rf500fits[a].predict_proba(activZ[400])[:,0] for a in xrange(0,len(rf500fits))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## to combine the CV folds use , min, max, avg, median?\n",
    "def generate_probabilies(X,model_list,my_class=0,method='avg'):\n",
    "    class_proba = [mdl.predict_proba(X)[:,my_class] for mdl in model_list]\n",
    "    gp_class_proba= np.vstack(class_proba).T\n",
    "    if method == 'avg':\n",
    "        agg_proba = np.mean(gp_class_proba,axis=1)\n",
    "    elif method == 'max':\n",
    "        agg_proba = np.max(gp_class_proba,axis=1)\n",
    "    elif method == 'min':\n",
    "        agg_proba = np.min(gp_class_proba,axis=1)\n",
    "    elif method == 'median':\n",
    "        agg_proba = np.median(gp_class_proba,axis=1)\n",
    "    else:\n",
    "        print \"The method {0} has not been implemented yet\".format(method)\n",
    "        return 0\n",
    "    return agg_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_avg_1yr = generate_probabilies(p1_actZ,rf500fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_avg_3yr = generate_probabilies(p3_actZ,rf500fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_avg_0yr = generate_probabilies(activZ,rf500fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(act_avg_0yr,act_avg_1yr,label='1 year',alpha=0.5)\n",
    "plt.scatter(act_avg_0yr,act_avg_3yr,label='3 year',color='indianred',alpha=0.3)\n",
    "plt.xlabel('Avg Probability TODAY')\n",
    "plt.ylabel('Avg Probability $n$ year')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some questions\n",
    "1. how many people leave in a given year -- what is the turnover rate?\n",
    "2. can I post-date the temporal components to create a validation set for a model I've made?\n",
    "3. can I create a view of the predicted probability of remaining as a function of time?\n",
    "    - is this just a poor-mans survival analysis?\n",
    "4. what is the effect of restricting the feature space to mostly temporal features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplxtra_df = pd.read_csv('employee_dataframe8.tsv',sep='\\t')\n",
    "emplxtra_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(emplxtra_df.Age_years - empl3.Age_years) #confirms that the difference in age is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emplxtra_df.HIRE_DT.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplxtra_df['hire_year'] = emplxtra_df['HIRE_DT'].apply(lambda x: int(str(x)[:4]))\n",
    "emplxtra_df.hire_year.hist(bins=70)\n",
    "plt.xlabel('Year of Hire')\n",
    "plt.ylabel('Counts')\n",
    "emplxtra_df.hire_year.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Construct a dataframe of # active employees given the end of the month\n",
    "monthly_range_terminations = pd.date_range(emplxtra_df.TERMINATION_DT.min(),emplxtra_df.TERMINATION_DT.max(),freq='M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monthly_range_terminations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(emplxtra_df['HIRE_DT'].apply(lambda x: pd.to_datetime(x)) < monthly_range_terminations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ccreate listing where they are timestamps for comparisions\n",
    "empl_dates = pd.DataFrame()\n",
    "empl_dates[['hire_tstmp','term_tstmp']] = emplxtra_df[['HIRE_DT','TERMINATION_DT']].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(empl_dates[(empl_dates.hire_tstmp < monthly_range_terminations[0]) & (empl_dates.term_tstmp > monthly_range_terminations[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monthly_range_terminations[0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nactive = []\n",
    "nsep2 = []\n",
    "nhired = []\n",
    "prev_date = monthly_range_terminations[0]-1\n",
    "#nsep.append(0.0)\n",
    "for idx, my_date in enumerate(monthly_range_terminations):\n",
    "    nactive.append( len(empl_dates[(empl_dates.hire_tstmp < my_date) &(empl_dates.term_tstmp > my_date)]))\n",
    "    if idx == 0:\n",
    "        nsep2.append(len(empl_dates[(empl_dates.term_tstmp <= my_date) & (empl_dates.hire_tstmp < my_date)]))\n",
    "        nhired.append( len(empl_dates[(empl_dates.hire_tstmp <= my_date) &(empl_dates.hire_tstmp > prev_date)]))\n",
    "    else:\n",
    "        nsep2.append(len(empl_dates[(empl_dates.term_tstmp <= my_date) & (empl_dates.hire_tstmp < my_date) &( empl_dates.term_tstmp > monthly_range_terminations[idx-1])]))\n",
    "        nhired.append( len(empl_dates[(empl_dates.hire_tstmp <= my_date) &(empl_dates.hire_tstmp > monthly_range_terminations[idx-1])]))\n",
    "        \n",
    "    #    nsep.append(sum(empl_dates.term_tstmp <= my_date) - nsep[idx-1]) \n",
    "            #ntermed = sum (empl_dates.term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(monthly_range_terminations,nsep)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Worforce Cumulative Separations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(monthly_range_terminations,nsep2)\n",
    "plt.plot(monthly_range_terminations,nhired)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Worforce Separations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(monthly_range_terminations,nactive)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Worforce Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workforce= pd.DataFrame(data =nactive,index=monthly_range_terminations,columns=['Active'])\n",
    "delta = workforce.diff()\n",
    "workforce['netChange'] = delta\n",
    "workforce['Separations'] = nsep2\n",
    "workforce['Hires'] = nhired\n",
    "workforce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workforce.Active.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workforce[workforce.Separations > 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annualwf = pd.DataFrame()\n",
    "annualwf = workforce[['Separations','Hires']].resample('A',how='sum')#.plot()\n",
    "annualwf['Active'] =workforce['Active'].resample('A',how='last')\n",
    "annualwf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annualwf['NetChange'] = annualwf.Active.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## restrict to after 1987\n",
    "annualwf.ix['1988-1-31':,[0,1,3]].plot()\n",
    "plt.xlabel('Date')\n",
    "plt.axhline(0,color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annualwf['TurnoverRate'] = annualwf['Separations']/annualwf['Active']*100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Working on post-dating my dataset\n",
    "plan is to take a snapshot from year-end 2013 (so I know the outcome of status after 1 year) and apply my model to this to test predictive accuracy.\n",
    "* Requires:\n",
    "    1. elimination of employees who started (HIRE_DT) after 2013-12-31\n",
    "    2. subtraction of temporal feaures by 1 year for those remaining.\n",
    "* use the date information loaded for annualwf above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_date1 = pd.to_datetime('2014-01-01')\n",
    "set2014active_idx = empl_dates[(empl_dates.hire_tstmp < test_date1) &(empl_dates.term_tstmp > test_date1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplxtra_df.ix[set2014active_idx].status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zz_active_true = empl3.ix[set2014active_idx].status.as_matrix().astype(np.int)\n",
    "#u = empl3.status.as_matrix().astype(np.int)\n",
    "#y = empl3['Tenure_years'].values.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ZZ = Z[set2014active_idx,:]\n",
    "zz_active_predproba0 = rf500fits[0].predict_proba(ZZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(zz_active_true,zz_active_predproba0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zz_active_pred0 = rf500fits[0].predict(ZZ)\n",
    "my_conf_matrix_2014 = metrics.confusion_matrix(zz_active_true,zz_active_pred0)\n",
    "sns.heatmap(my_conf_matrix_2014, annot=True,  fmt='')\n",
    "plt.title('Random Forest Classifier Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.matthews_corrcoef(zz_active_true, zz_active_pred0), metrics.accuracy_score(zz_active_true, zz_active_pred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (metrics.classification_report(zz_active_true, zz_active_pred0,target_names=['current','separated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl3.ix[set2014active_idx].status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dumb-classifier\n",
    "zz_all_stay = np.zeros(len(zz_active_true))\n",
    "print (metrics.classification_report(zz_active_true,zz_all_stay))\n",
    "sns.heatmap(metrics.confusion_matrix(zz_active_true,zz_all_stay), annot=True,  fmt='')\n",
    "plt.title('Random Forest Classifier Confusion Matrix: Dumb Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(zz_active_true,np.vstack([zz_all_stay,np.ones(len(zz_all_stay))]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print [mdl.score(ZZ,zz_active_true) for mdl in rf500fits]\n",
    "np.mean([mdl.score(ZZ,zz_active_true) for mdl in rf500fits])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining these estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_rf_estimators(rf_a,rf_b):\n",
    "    rf_a.estimators_ += rf_b.estimators_\n",
    "    rf_a.n_estimators = len(rf_a.estimators_)\n",
    "    return rf_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf500combo = reduce(combine_rf_estimators,rf500fits) # create a combined RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf500combo.score(ZZ,zz_active_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zz_sep_indx = np.where(zz_active_true == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(rf500combo.predict_proba(ZZ)[zz_sep_indx,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zz_active_pred_combo = rf500combo.predict(ZZ)\n",
    "my_CM = metrics.confusion_matrix(zz_active_true,zz_active_pred_combo)\n",
    "sns.heatmap(my_CM, annot=True,  fmt='')\n",
    "plt.title('Random Forest Classifier Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I legitimately fear overfitting\n",
    "Let me try to reduce my dataset to employees prior to 2011, reset their status, train a model and then predict on employees from 2011 to present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_date2 = pd.to_datetime('2010-01-01')\n",
    "#test_date1 = pd.to_datetime('2014-01-01')\n",
    "before2010_idx = empl_dates[(empl_dates.hire_tstmp < test_date2)].index# &(empl_dates.term_tstmp > test_date2)].index\n",
    "after2010_idx = list(set((empl3.index))-set(before2010_idx))\n",
    "print len(before2010_idx), len(after2010_idx)\n",
    "print \" this amounts to a hold-out fraction of {0}\".format(len(after2010_idx)/float(len(empl3)))\n",
    "#len(empl3.ix[~before2011_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into test-train split\n",
    "train_df = empl3.ix[before2010_idx].copy()\n",
    "test_df = empl3.ix[after2010_idx].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset the status of train_df if term_tstmp > test-date; also fix tenure/age, etc.\n",
    "indices_to_fix = empl_dates[(empl_dates.hire_tstmp < test_date2) & (empl_dates.term_tstmp >= test_date2)].index\n",
    "len(indices_to_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print empl3.status.value_counts(),\n",
    "print empl3.ix[before2010_idx].status.value_counts()\n",
    "print empl3.ix[indices_to_fix].status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.loc[indices_to_fix,'status'] = 0\n",
    "train_df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_dates.ix[46]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try to clean up time-sensitive data in train_df\n",
    "* leave MOS; just change Tenure & Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df[['Tenure_years','Age_years']].ix[indices_to_fix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = train_df.status.as_matrix().astype(np.int)\n",
    "df = train_df.drop(['status','sep_status','retired'],axis=1).copy()\n",
    "V = df.as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "rfc_500trees = ensemble.RandomForestClassifier(n_estimators=500,n_jobs=50)\n",
    "CVscores = cross_validation.cross_val_score(rfc_500trees, V, y_train, cv=10)\n",
    "print CVscores\n",
    "CVscores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myRFC = rfc_500trees.fit(V,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = test_df.status.as_matrix().astype(np.int)\n",
    "V_test = test_df.drop(['status','sep_status','retired'],axis=1).as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## apply this to the test-set\n",
    "v_test_pred = rfc_500trees.predict(V_test)\n",
    "v_test_predproba = rfc_500trees.predict_proba(V_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## apply this to the test-set\n",
    "v_test_pred1 = myRFC.predict(V_test)\n",
    "v_test_predproba1 = myRFC.predict_proba(V_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_conf_matrix = metrics.confusion_matrix(y_test,v_test_pred1)\n",
    "sns.heatmap(my_conf_matrix, annot=True,  fmt='')\n",
    "plt.title('Random Forest Classifier Confusion Matrix: built on pre 2010 data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test,v_test_predproba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myRFC.score(V_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotFI(myRFC,df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to combine the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf_fits_combo = reduce(combine_rf_estimators,kf_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf_fits_combo.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(kf_fits_combo.predict(separX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class0_proba = [rf_model.predict_proba(activX)[:,0] for rf_model in kf_fits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class0_proba_sep = [rf_model.predict_proba(separX)[:,0] for rf_model in kf_fits]\n",
    "avg_sep_proba = np.mean(np.vstack(class0_proba_sep).T,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_proba = np.mean(np.vstack(class0_proba).T,axis=1)\n",
    "avg_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(activy,avg_proba, marker='d',alpha=0.3)\n",
    "plt.plot(y[empl_sep.index],avg_sep_proba,marker='h',alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x.T for x in class0_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import cross_val_score\n",
    "rfc_500trees = ensemble.RandomForestClassifier(n_estimators=500,n_jobs=30)\n",
    "CVscores = cross_validation.cross_val_score(rfc_500trees, X, y, cv=10)\n",
    "CVscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CVscores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(clf,metrics.accuracy_score(y,kfold_cv(X,y,clf))) for clf in classifiers_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble.GradientBoostingClassifier?\n",
    "#r(n_estimators=100, max_depth=3, loss='ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define classes as [0,1,2,3,4,5,6-10,11-15,over]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_tenure_class = pd.cut(empl2.Tenure_years,[-1,0,1,2,3,4,5,10,15,200],labels=False)#,labels=[1,2,3,4,5,6,7,8])#.values\n",
    "y_tenure_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = empl2.drop(['Tenure_years','status','sep_status','retired'],axis=1).copy()\n",
    "X = df.as_matrix().astype(np.float)\n",
    "y_tenure_class.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tenure_classes = list(set(list(y_tenure_class)))\n",
    "print tenure_classes\n",
    "[(x,list(y_tenure_class).count(x)) for x in tenure_classes]\n",
    "#list(y_tenure_class).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_cv(X, y, clf_class, shuffle=True, n_folds=10, **kwargs):\n",
    "    k_fold = cross_validation.KFold(len(y), n_folds=n_folds, shuffle=shuffle)\n",
    "    y_pred = y.copy()\n",
    "    for ii, jj in k_fold:\n",
    "        X_train, X_test = X[ii], X[jj]\n",
    "        y_train = y[ii]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[jj] = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_cv_proba(X, y, clf_class, shuffle=True, n_folds=10, **kwargs):\n",
    "    k_fold = cross_validation.KFold(len(y), n_folds=n_folds, shuffle=shuffle)\n",
    "    y_prob = np.zeros((len(y),2))\n",
    "    for ii, jj in k_fold:\n",
    "        X_train, X_test = X[ii], X[jj]\n",
    "        y_train = y[ii]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_prob[jj] = clf.predict_proba(X_test)\n",
    "    return y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Dump Classifier: {:.2f}'.format(metrics.accuracy_score(y_tenure_class, [0 for ii in y_tenure_class.tolist()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print('K Nearest Neighbor Classifier: {:.2f}'.format(metrics.accuracy_score(y_tenure_class, kfold_cv(X, y_tenure_class, neighbors.KNeighborsClassifier))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_neighbors_conf_matrix = metrics.confusion_matrix(y_tenure_class, kfold_cv(X, y_tenure_class, neighbors.KNeighborsClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(k_neighbors_conf_matrix, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# truth: \n",
    "[(a,sum(y_tenure_class==a)) for a in tenure_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_tenure_class = kfold_cv(X,y_tenure_class, neighbors.KNeighborsClassifier)\n",
    "len(pred_tenure_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(k_neighbors_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_neighbors_conf_matrix[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_neighbors_conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## well this is OK, but not great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('K Nearest Neighbor Classifier:\\n {}\\n'.format(metrics.classification_report(y_tenure_class, kfold_cv(X, y_tenure_class, neighbors.KNeighborsClassifier))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_tenure = empl2.Tenure_years.apply(lambda x: np.round(x,0))\n",
    "#y_tenure.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### since the goal is to determine number of separation in a future time point, maybe I should create a target that is the number of tenure years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## first test is to predict on separation at all (status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = empl.status.as_matrix().astype(np.int)\n",
    "df = empl.drop(['status','sep_status','retired'],axis=1).copy()\n",
    "X = df.as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I have 199419 instances and 203 features\n",
    "\n",
    "####Next scale them by removing mean and dividing by standar deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_validation.KFold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use K-fold Cross-validation --> my classes are not too unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_cv(X, y, clf_class, shuffle=True, n_folds=10, **kwargs):\n",
    "    k_fold = cross_validation.KFold(len(y), n_folds=n_folds, shuffle=shuffle)\n",
    "    y_pred = y.copy()\n",
    "    for ii, jj in k_fold:\n",
    "        X_train, X_test = X[ii], X[jj]\n",
    "        y_train = y[ii]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[jj] = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = cross_validation.KFold(len(y),n_folds =10,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kfold_cv(X,y,linear_model.PassiveAggressiveClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Passive Aggressive Classifier: {:.2f}'.format(metrics.accuracy_score(y, kfold_cv(X, y, linear_model.PassiveAggressiveClassifier))))\n",
    "print('Gradient Boosting Classifier:  {:.2f}'.format(metrics.accuracy_score(y, kfold_cv(X, y, ensemble.GradientBoostingClassifier))))\n",
    "print('Support vector machine(SVM):   {:.2f}'.format(metrics.accuracy_score(y, kfold_cv(X, y, svm.SVC))))\n",
    "print('Random Forest Classifier:      {:.2f}'.format(metrics.accuracy_score(y, kfold_cv(X, y, ensemble.RandomForestClassifier))))\n",
    "print('K Nearest Neighbor Classifier: {:.2f}'.format(metrics.accuracy_score(y, kfold_cv(X, y, neighbors.KNeighborsClassifier))))\n",
    "print('Logistic Regression:           {:.2f}'.format(metrics.accuracy_score(y, kfold_cv(X, y, linear_model.LogisticRegression))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Dump Classifier: {:.2f}'.format(metrics.accuracy_score(y, [0 for ii in y.tolist()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass_agg_conf_matrix = metrics.confusion_matrix(y,kfold_cv(X, y, linear_model.PassiveAggressiveClassifier))\n",
    "grad_ens_conf_matrix = metrics.confusion_matrix(y, kfold_cv(X, y, ensemble.GradientBoostingClassifier))\n",
    "decision_conf_matrix = metrics.confusion_matrix(y, kfold_cv(X, y, tree.DecisionTreeClassifier))\n",
    "ridge_clf_conf_matrix = metrics.confusion_matrix(y, kfold_cv(X, y, linear_model.RidgeClassifier))\n",
    "svm_svc_conf_matrix = metrics.confusion_matrix(y, kfold_cv(X, y, svm.SVC))\n",
    "random_forest_conf_matrix = metrics.confusion_matrix(y, kfold_cv(X, y, ensemble.RandomForestClassifier))\n",
    "k_neighbors_conf_matrix = metrics.confusion_matrix(y, kfold_cv(X, y, neighbors.KNeighborsClassifier))\n",
    "logistic_reg_conf_matrix = metrics.confusion_matrix(y, kfold_cv(X, y, linear_model.LogisticRegression))\n",
    "dumb_conf_matrix = metrics.confusion_matrix(y, [0 for ii in y.tolist()]); # ignore the warning as they are all 0\n",
    "\n",
    "conf_matrix = {\n",
    "                1: {\n",
    "                    'matrix': pass_agg_conf_matrix,\n",
    "                    'title': 'Passive Aggressive',\n",
    "                   },\n",
    "                2: {\n",
    "                    'matrix': grad_ens_conf_matrix,\n",
    "                    'title': 'Gradient Boosting',\n",
    "                   },\n",
    "                3: {\n",
    "                    'matrix': decision_conf_matrix,\n",
    "                    'title': 'Decision Tree',\n",
    "                   },\n",
    "                4: {\n",
    "                    'matrix': ridge_clf_conf_matrix,\n",
    "                    'title': 'Ridge',\n",
    "                   },\n",
    "                5: {\n",
    "                    'matrix': svm_svc_conf_matrix,\n",
    "                    'title': 'Support Vector Machine',\n",
    "                   },\n",
    "                6: {\n",
    "                    'matrix': random_forest_conf_matrix,\n",
    "                    'title': 'Random Forest',\n",
    "                   },\n",
    "                7: {\n",
    "                    'matrix': k_neighbors_conf_matrix,\n",
    "                    'title': 'K Nearest Neighbors',\n",
    "                   },\n",
    "                8: {\n",
    "                    'matrix': logistic_reg_conf_matrix,\n",
    "                    'title': 'Logistic Regression',\n",
    "                   },\n",
    "                9: {\n",
    "                    'matrix': dumb_conf_matrix,\n",
    "                    'title': 'Dumb',\n",
    "                   },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(figsize=(16, 12))\n",
    "plt.suptitle('Confusion Matrix of Various Classifiers')\n",
    "for ii, values in conf_matrix.items():\n",
    "    matrix = values['matrix']\n",
    "    title = values['title']\n",
    "    plt.subplot(3, 3, ii) # starts from 1\n",
    "    plt.title(title);\n",
    "    sns.heatmap(matrix, annot=True,  fmt='');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get hire year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "atime = empl_bene['HIRE_DT'].ix[0]\n",
    "str(atime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str(atime)[5:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how many are there if we require hire_date > some date?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_bene.HIRE_DT.ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_hire_date = pd.to_datetime('2002-11-30') #datetime(2002,11,30)\n",
    "test_hire_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplB = empl_bene[empl_bene.HIRE_DT > test_hire_date].copy()\n",
    "print len(emplB)\n",
    "print emplB.status.value_counts()\n",
    "print emplB.sep_status.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_term_date = #test_hire_date\n",
    "test_term_date = pd.to_datetime('2002-12-31')\n",
    "emplC= empl[empl.TERMINATION_DT > test_term_date].copy()\n",
    "print len(emplC)\n",
    "print emplC.status.value_counts()\n",
    "print emplC.sep_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplC.RATE1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_rate_column(x):\n",
    "    list_of_defined_values = ['R1C1','R1C2','R1C3',\n",
    "                              'R2C1','R2C2','R2C3',\n",
    "                              'R3C1','R3C2','R3C3']\n",
    "    #rcol=[]\n",
    "    #ccol=[]\n",
    "    if x in list_of_defined_values:\n",
    "        rval = int(x[1])#col.append(x[1])\n",
    "        cval = int(x[3]) #col.append(x[3])\n",
    "        #print x[1],x[3]\n",
    "    else:\n",
    "        #rcol.append(0)\n",
    "        #ccol.append(0)\n",
    "        rval = 0\n",
    "        cval = 0\n",
    "    return rval,cval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rcol,ccol = \n",
    "input_column = 'RATE1'\n",
    "rval = [x[0] for x in emplC[input_column].apply(lambda(x): split_rate_column(x)).as_matrix()]\n",
    "cval = [x[1] for x in emplC[input_column].apply(lambda(x): split_rate_column(x)).as_matrix()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplC[input_column+'_R'] = rval\n",
    "emplC[input_column+'_C'] = cval\n",
    "emplC[['RATE1','RATE1_R','RATE1_C']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_rate_column(df,input_column):\n",
    "    rval = [x[0] for x in df[input_column].apply(lambda(x): split_rate_column(x)).as_matrix()]\n",
    "    cval = [x[1] for x in df[input_column].apply(lambda(x): split_rate_column(x)).as_matrix()]\n",
    "    df[input_column+'_R'] = rval\n",
    "    df[input_column+'_C'] = cval\n",
    "    df.drop(input_column,inplace=True,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### convert the RATINGS columns\n",
    "for col in ['RATE1','RATE2','RATE3','RATE4','RATE5','RATE6','RATE7','RATE8','RATE9','RATE10']:\n",
    "    print col\n",
    "    emplC = convert_rate_column(emplC,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplC.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## begin to Standardize some of these other columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.EMPL_CLASS.value_counts(), empltbl3.EMPL_CLASS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.EMPL_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(empltbl3.EMPL_TYPE,empltbl3.EMPL_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(empl.COMPANY,empl.EMPL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at these distributions\n",
    "plt.figure(figsize=(12,8))\n",
    "emplC[emplC.status==0].Age_years.hist(bins=70,range=[15,84],color='darkred',label='current',alpha=0.8,normed=True)\n",
    "emplC[emplC.status==1].Age_years.hist(bins=70,range=[15,84],color='dodgerblue',label='former',alpha=0.5,normed=True)\n",
    "plt.legend()\n",
    "plt.xlabel('Age in years')\n",
    "plt.ylabel('Normed Counts')\n",
    "plt.title('Distribution of Worforce Ages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at these distributions\n",
    "plt.figure(figsize=(12,8))\n",
    "emplB[emplB.status==0].Tenure_years.hist(bins=36,range=[0,35],color='darkred',label='current',alpha=0.8,normed=True)\n",
    "emplB[emplB.status==1].Tenure_years.hist(bins=36,range=[0,35],color='dodgerblue',label='former',alpha=0.5,normed=True)\n",
    "plt.legend()\n",
    "plt.xlabel('Age in years')\n",
    "plt.ylabel('Normed Counts')\n",
    "plt.title('Distribution of Worforce Ages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_bene.zip5.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_bene.COMP_FREQUENCY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "empl_bene['COMP_FREQ_ANNUAL'] = 1\n",
    "empl_bene.loc[empl_bene['COMP_FREQUENCY']=='H','COMP_FREQ_ANNUAL'] = 0\n",
    "empl_bene.drop('COMP_FREQUENCY',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save this dataframe as a tab separated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outfile1 = 'employee_dataframe.tsv'\n",
    "save_dataframe_file = True\n",
    "if save_dataframe_file:\n",
    "    empltbl3.to_csv(outfile1,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert datetime64[ns] format to a string ---> YYYY-MM-DD \n",
    "use date_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in date_columns:\n",
    "    empltbl3[c]= empltbl3[c].apply(lambda x: str(x).split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in empltbl3.columns:\n",
    "    my_dtype = empltbl3[col].dtype\n",
    "    if my_dtype != 'object' and my_dtype != 'float64' and my_dtype != 'int64':\n",
    "        print col, \"\\t\", empltbl3[col].dtype, \"\\t\",empltbl3[col].ix[8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### try converting the timedeltas to floats\n",
    "empltbl3['Age_tdelta'].ix[3].astype('float')/(60*60*24*10**9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nano2days = 60.*60.*24.*10**9\n",
    "empltbl3['Age_days'] = empltbl3['Age_tdelta'].apply(lambda x: x.astype('float')/(nano2days))\n",
    "empltbl3['Tenure_days'] = empltbl3['Tenure_tdelta'].apply(lambda x: x.astype('float')/(nano2days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.drop(['Age_tdelta','Tenure_tdelta'], axis=1,inplace=True)\n",
    "empltbl3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(empltbl3.Age_days.unique()), len(empltbl3.Tenure_days.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl.Age_years.ix[:10].apply(lambda x: int(np.round(x,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keep just the year\n",
    "empltbl_dates = empltbl[date_columns].copy() # save the dates.\n",
    "for c in date_columns:\n",
    "    #print c\n",
    "    if c.endswith('DT'):\n",
    "        c2 = c[:-2]+'YEAR'\n",
    "    else:\n",
    "        c2 = c[:-4]+'_YEAR'\n",
    "    #print c2\n",
    "    empltbl[c2]= empltbl[c].apply(lambda x: x[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl.drop(date_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empltbl['Age_year_int'] = empltbl['Age_years'].apply(lambda x: int(np.round(x,0)))\n",
    "empltbl['Tenure_year_int'] = empltbl['Tenure_months'].apply(lambda x: int(np.round(x/12,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(empltbl.Age_year_int.unique()), len(empltbl.Tenure_year_int.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl.Tenure_year_int.value_counts().plot(kind='bar',color='darkslateblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now save this version for H2O\n",
    "outfile2 = 'employee_dataframe2.ssv'\n",
    "save_dataframe_file = True\n",
    "if save_dataframe_file:\n",
    "    empltbl.to_csv(outfile2,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# duplicated employee keys:\n",
    "#[empltbl.KEY.value_counts() > 1]\n",
    "dup_empl_keys = []\n",
    "empltblKEYcounts = empltbl.KEY.value_counts()\n",
    "for a in empltblKEYcounts[empltblKEYcounts>1].index:\n",
    "    print a\n",
    "    dup_empl_keys.append(a)\n",
    "\n",
    "for empkey in dup_empl_keys:\n",
    "    print empltbl[empltbl.KEY == empkey]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue to Refine the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(empltbl3.zip5.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3[empltbl3.zip5=='SW18 '].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3[empltbl3['STATE'].isnull()][['POSTAL_SFI','zip5','LOC_STATE','ADDRESS1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf = summarize_dataframe2(empltbl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Examine cleaning up the different feature (covariate) columns for anylysis on them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### restrict the dataframe to do linear-regression on.\n",
    "* first attempt is _ad hoc_ reduction of 185 columns\n",
    "    * keep age_years, tenure_months, status, sex for sure\n",
    "* look at cases where there is 'significant' correlation between columns:\n",
    "    * for example JOBCNTx, LOCCNTx, DEPTCNTx, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the set of columns that have missing values smaller than some threshold \n",
    "sdf['x_missing'] = sdf['nmissing']/len(empltbl3)\n",
    "len(sdf[sdf['x_missing'] > 0]), len(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf['y_arity'] = sdf['arity']/len(empltbl)\n",
    "sdf['y_arity'].hist(bins=30,color='deepskyblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf['x_missing'].hist(bins=30,color='deeppink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf.to_csv('employee_table_summary_3.csv')\n",
    "# save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now apply some logic to these columns for keeping and not\n",
    "columns_to_fix_missing = []\n",
    "columns_to_fix_NY = []\n",
    "columns_to_omit = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgrA_sf_df['managers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12.5,5))\n",
    "\n",
    "kmf_mgr1=KaplanMeierFitter()\n",
    "\n",
    "kmf_mgr1.fit(vc_empl4[mgrA].Tenure_months, timeline=tenure_month_range, event_observed=vc_empl4[mgrA].status,label='managers')\n",
    "mgrA_sf_df = pd.DataFrame(kmf_mgr1.survival_function_)\n",
    "ax = fig.add_subplot(111)\n",
    "kmf_mgr1.plot(ax=ax,c='darkgreen')\n",
    "kmf_mgr1.fit(vc_empl4[~mgrA].Tenure_months, timeline=tenure_month_range,event_observed=vc_empl4[~mgrA].status,label='non-managers')\n",
    "kmf_mgr1.plot(ax=ax,color='darkslategray')\n",
    "mgrA_sf_df = pd.concat([mgrA_sf_df,kmf_mgr1.survival_function_],axis=1)\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgrA_surv_prob = calc_future_survival_proba(vc_empl4,mgrA,mgrA_sf_df['managers'],future_years_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(future_years_list,mgrA_surv_prob.sum()/len(mgrA_surv_prob),'*:',color='steelblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgrA_surv_prob.sum()/len(mgrA_surv_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ues = vc_empl4.GRADE=='UES'\n",
    "print sum(ues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(vc_empl4.GRADE,vc_empl4.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12.5,5))\n",
    "\n",
    "kmf_ues=KaplanMeierFitter()\n",
    "\n",
    "kmf_ues.fit(vc_empl4[ues].Tenure_months, timeline=tenure_month_range, event_observed=vc_empl4[ues].status,label='UES')\n",
    "tmp_df = pd.DataFrame(kmf_ues.survival_function_)\n",
    "ax = fig.add_subplot(111)\n",
    "kmf_ues.plot(ax=ax,c='darkorange')\n",
    "kmf_ues.fit(vc_empl4[~ues].Tenure_months, timeline=tenure_month_range,event_observed=vc_empl4[~ues].status,label='non-UES')\n",
    "kmf_ues.plot(ax=ax,color='darkslategray')\n",
    "tmp_df = pd.concat([tmp_df,kmf_ues.survival_function_],axis=1)\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vc_empl4[ues][vc_empl4['status']==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#kmf_grade.survival_function_\n",
    "#tmp_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ues_surv_prob = calc_future_survival_proba(vc_empl4,ues,tmp_df['UES'],future_years_list)\n",
    "ues_surv_prob.sum()/len(vc_empl4[ues][vc_empl4.status==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ues_surv_prob.sum()/sum(ues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vc_empl4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode the VOLINVOL column as ['INVOLUNTARY':2,'VOLUNTARY':1,'NOT':0,'\n",
    "empltbl4['sep_status'] = empltbl4['VOLINVOL'].replace({'NOT':0,'VOLUNTARY':1,'INVOLUNTARY':2,'OTHER':3,'UNKNOWN':3})\n",
    "empltbl4.sep_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(empltbl4.status,empltbl4.sep_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore differences between voluntary/involuntary and Not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volunt = empltbl3[empltbl3.VOLINVOL=='VOLUNTARY'].copy()\n",
    "current = empltbl3[empltbl3.VOLINVOL=='NOT'].copy()\n",
    "involu = empltbl3[empltbl3.VOLINVOL=='INVOLUNTARY'].copy()\n",
    "empl_df_list = [current,volunt,involu]\n",
    "print [len(a) for a in empl_df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(empltbl3[(empltbl3.VOLINVOL=='VOLUNTARY') |(empltbl3.VOLINVOL=='NOT')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl_df_list_colors =['indianred','steelblue','darkkhaki']\n",
    "empl_df_list_alphas =[1.0,0.7,0.4]\n",
    "empl_df_list_label = ['current','voluntary','involuntary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## define histogram bin ranges\n",
    "tenure_year_bin_range = [0,59]\n",
    "age_year_bin_range = [15,84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for idx in xrange(0,len(empl_df_list)):\n",
    "    my_color = empl_df_list_colors[idx]\n",
    "    my_alpha = empl_df_list_alphas[idx]\n",
    "    empl_df_list[idx].Age_years.hist(bins=70,range=age_year_bin_range,color=my_color,alpha=my_alpha,normed=True,label=empl_df_list_label[idx])\n",
    "    plt.legend()\n",
    "    plt.xlabel('Age in Years')\n",
    "    plt.ylabel('Normed Counts')\n",
    "    plt.title('Distribution of Workforce Ages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(empltbl3[(empltbl3.VOLINVOL=='VOLUNTARY') & (empltbl3.Age_years > 54)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for idx in xrange(0,len(empl_df_list)):\n",
    "    my_color = empl_df_list_colors[idx]\n",
    "    my_alpha = empl_df_list_alphas[idx]\n",
    "    empl_df_list[idx].Tenure_years.hist(bins=60,range=tenure_year_bin_range,color=my_color,alpha=my_alpha,normed=True,label=empl_df_list_label[idx])\n",
    "    plt.legend()\n",
    "    plt.xlabel('Tenure in Years')\n",
    "    plt.ylabel('Normed Counts')\n",
    "    plt.title('Distribution of Workforce Tenures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.DIVISION_CODE_SFI.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(empltbl3.DIVISION_CODE_SFI,empltbl3.COMPANY)#.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3[empltbl2.INTERN=='Y'].Tenure_months.hist(color='darkslategray',bins=80,normed=True)\n",
    "empltbl3[empltbl2.INTERN=='N'].Tenure_months.hist(color='darkturquoise',bins=80,alpha=0.5, normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at how many have missing SKEY\n",
    "* only one in the current table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(current[current.SKEY.isnull()][['Age_years','Tenure_months','COMPANY','GRADE','ANNUAL_RT','KEY']])\n",
    "ceo_key = current[current.SKEY.isnull()].KEY.values[0]\n",
    "print ceo_key\n",
    "print current[current.SKEY.isnull()][['Age_years','Tenure_months','COMPANY','GRADE','ANNUAL_RT','KEY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(empltbl3.KEY.unique()), len(empltbl3.SKEY.unique()),len(current.SKEY.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## How many are missing SKEY in retired.\n",
    "sum(empltbl3[empltbl3.status==1].SKEY.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# do survival analysis for each GRADE\n",
    "* column == 'GRADE' \n",
    "* arity = 164\n",
    "* Define a min-threshold of GRADE to look at.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.GRADE.value_counts().hist(color='forestgreen',bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## start with top 20 grades:\n",
    "empltbl3.GRADE.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use lifelines\n",
    "from lifelines import KaplanMeierFitter\n",
    "kmf0 = KaplanMeierFitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "kmf0.fit(empltbl3.Tenure_months, event_observed=empltbl3.status)\n",
    "kmf0.plot(color='darkslategray')\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure months')\n",
    "plt.title('KaplanMeier Survival: ALL employees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## define the range so all are on the same scale\n",
    "min_tenure_months= empltbl3.Tenure_months.min()\n",
    "max_tenure_months = empltbl3.Tenure_months.max()\n",
    "print min_tenure_months, max_tenure_months\n",
    "tenure_month_range = np.linspace(min_tenure_months,max_tenure_months,66)\n",
    "len(tenure_month_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.GRADE.value_counts()[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## replace nan with 'XXX'\n",
    "empltbl3.GRADE.fillna('XXX',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mg_codes = [x for x in list(empltbl3.GRADE.unique()) if  str(x).startswith('MG')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mg_codes = [x for x in list(empltbl3.GRADE.unique()) if  str(x).startswith('MG')]\n",
    "clvl_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('C')]\n",
    "ra_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('RA')]\n",
    "re_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('RE')]\n",
    "rd_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('RD')]\n",
    "pa_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('PA')]\n",
    "pb_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('PB')]\n",
    "ma_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('MA')]\n",
    "sf_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('SF')]\n",
    "rb_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('RB')]\n",
    "rc_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('RC')]\n",
    "pc_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('PC')]\n",
    "l_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('L')]\n",
    "fa_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('FA')]\n",
    "u_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('U')]\n",
    "i_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('I')]\n",
    "a_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('A')]\n",
    "b_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('B')]\n",
    "#ri_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('RI')]\n",
    "# assign missing and non to non_codes\n",
    "non_codes = ['NON','XXX']\n",
    "m_codes = ['M1N','M2N','M3N','M10']\n",
    "rx_codes = ['RF1', 'RF2', 'RF3', 'RG1', 'RG2', 'RG3', 'RG4', 'RH1', 'RH2', 'RH3', 'RH4', \n",
    "            'RI2', 'RI3', 'RJ2', 'RJ3', 'RJ4', 'RK3','RL1', 'RL2', 'RL3', 'RL4', 'RM2']\n",
    "# combine\n",
    "two_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('2')]\n",
    "t_codes = [x for x in list(empltbl3.GRADE.unique()) if str(x).startswith('T')]\n",
    "oth_codes = i_codes+two_codes+t_codes+a_codes\n",
    "oth_codes.append('ZFL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grade_groupings_list_A = [mg_codes,clvl_codes,ma_codes,pa_codes,pb_codes,sf_codes, ra_codes,rd_codes,re_codes, rb_codes, rc_codes,\n",
    "                          pc_codes,l_codes,fa_codes, u_codes,b_codes,non_codes,m_codes,rx_codes,oth_codes]\n",
    "len(grade_groupings_list_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e3_grade_function_crosstab = pd.crosstab(empltbl3.GRADE,empltbl3.JOB_FUNCTION)\n",
    "e3_grade_function_crosstab.MGT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e3_grade_function_crosstab[e3_grade_function_crosstab.MGT>0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e3_grade_function_crosstab[e3_grade_function_crosstab.PTB>0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for g in grade_groupings_list_A:\n",
    "    print sum(empltbl3.GRADE.isin(g)), g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "used_grades = list(chain.from_iterable(grade_groupings_list_A))\n",
    "sum(empltbl3.GRADE.isin(used_grades)), len(empltbl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted([x for x in empltbl3.GRADE.unique() if x.startswith('R')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3[~empltbl3.GRADE.isin(used_grades)].GRADE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.GRADE.value_counts()[40:85]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now look at each of the top 10 grades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dataFrame of these survival functions.\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12.5,5))\n",
    "#figsize(16,8)\n",
    "\n",
    "top10grades = list(empltbl3.GRADE.value_counts()[:85].index)\n",
    "kmf_grade=KaplanMeierFitter()\n",
    "\n",
    "kmf_grade.fit(empltbl3.Tenure_months, timeline=tenure_month_range, event_observed=empltbl3.status,label='ALL')\n",
    "grade_sf_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ax=fig.add_subplot(111)\n",
    "kmf_grade.plot(ax=ax,c='darkslategray')\n",
    "for grade in top10grades:\n",
    "    \n",
    "    #plt.figure(figsize=(20,10))\n",
    "    em_grade = empltbl3[empltbl3.GRADE == grade]\n",
    "    kmf_grade.fit(em_grade.Tenure_months, timeline=tenure_month_range,event_observed=em_grade.status,label=grade)\n",
    "    if grade.startswith('MG'):\n",
    "        kmf_grade.plot(ax=ax)\n",
    "    grade_sf_df = pd.concat([grade_sf_df,kmf_grade.survival_function_],axis=1)\n",
    "#kmf_gender.fit(female.Tenure_months,  timeline=tenure_month_range,event_observed=female.status)\n",
    "#kmf_gender.plot(ax=ax, c='deeppink',label='Female')\n",
    "\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grade_sf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgr = ((empltbl3.GRADE == 'MG2') |(empltbl3.GRADE == 'MG3') | (empltbl3.GRADE == 'MG4'))\n",
    "sum(mgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgr = empltbl3.GRADE.isin(mg_codes)\n",
    "sum(mgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lifelines.statistics import logrank_test\n",
    "summary, p_value, test_results = logrank_test(empltbl3[mgr].Tenure_months, empltbl3[~mgr].Tenure_months, empltbl3[mgr].status, empltbl3[~mgr].status, alpha=.99 )\n",
    "print summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12.5,5))\n",
    "\n",
    "kmf_grade=KaplanMeierFitter()\n",
    "\n",
    "kmf_grade.fit(empltbl3[mgr].Tenure_months, timeline=tenure_month_range, event_observed=empltbl3[mgr].status,label='managers')\n",
    "mgr_sf_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ax = fig.add_subplot(111)\n",
    "kmf_grade.plot(ax=ax,c='darkred')\n",
    "kmf_grade.fit(empltbl3[~mgr].Tenure_months, timeline=tenure_month_range,event_observed=empltbl3[~mgr].status,label='non-managers')\n",
    "kmf_grade.plot(ax=ax,color='darkslategray')\n",
    "mgr_sf_df = pd.concat([mgr_sf_df,kmf_grade.survival_function_],axis=1)\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIGGER QUESTION IS whether this tenure is descriptive or proscriptive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3[mgr].Tenure_months.hist(normed=True,alpha=0.3)\n",
    "empltbl3[mgr][empltbl3.status==0].Tenure_months.hist(normed=True,color='indianred',alpha=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Take the set of employees that don't leave and calculate out their survival function in the future\n",
    "* look at [1,10] years in the future for each.\n",
    "* sum over all\n",
    "* also get lower CL and upper CL\n",
    "* divide sum by count to get % remaining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgr_sf_df.head(), len(mgr_sf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgr_df = pd.DataFrame(empltbl3[mgr].Tenure_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in empltbl3[mgr][empltbl3.status==0].Tenure_months+12.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgr_sf_df.ix[:339.36].index[-1], mgr_sf_df.ix[339.36:].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "locate_closest_indices(mgr_sf_df, 339.36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def locate_closest_indices(df,index_to_find):\n",
    "    my_min = df.ix[:index_to_find].index[-1]\n",
    "    my_max = df.ix[index_to_find:].index[0]\n",
    "    #.index <= index_to_find\n",
    "    #my_max = df.index >=index_to_find\n",
    "    print index_to_find, my_min, my_max\n",
    "    return my_min,my_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lin_interpolate(df,index_to_find,ycol):\n",
    "    #x1,x2 = locate_closest_indices(df,x)\n",
    "    my_min = df.ix[:index_to_find].index[-1]\n",
    "    my_max = df.ix[index_to_find:].index[0]\n",
    "    deltax = my_max-my_min\n",
    "    #print my_min, my_max\n",
    "    y_1 = df[ycol].ix[my_min]\n",
    "    y_2 = df[ycol].ix[my_max]\n",
    "    #print y_1, y_2\n",
    "    \n",
    "    deltay=df[ycol].ix[my_max]- y_1\n",
    "    slope = deltay/deltax\n",
    "    #print slope, deltax, deltay\n",
    "    my_value = y_1+slope*(index_to_find-my_min)\n",
    "    return my_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgr_sf_df.ix[mgr_sf_df.ix[:339.36].index[-1]:mgr_sf_df.ix[339.36:].index[0]]#.plot()#.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_interpolate(mgr_sf_df,339.36,'managers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_to_find = 371.1\n",
    "\n",
    "my_min = df['A'] <= value_to_find\n",
    "Max = df['A'] >= value_to_find\n",
    "idx_Min = df.ix[Min, 'A'].idxmax()\n",
    "idx_Max = df.ix[Max, 'A'].idxmin()\n",
    "df.ix[idx_Min:idx_Max, ['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add 1 to 10 years in to future\n",
    "future_years_list = np.arange(1,11)\n",
    "future_years_list*12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plus_1yr = [lin_interpolate(mgr_sf_df,x,'managers') for x in empltbl3[mgr][empltbl3.status==0].Tenure_months+12.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(plus_1yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_mgr.Tenure_months.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "future_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## define a new data frame to hold the information\n",
    "current_mgr = empltbl3[mgr][empltbl3.status==0].Tenure_months.copy()\n",
    "#current_mgr.columns='Current_tenure'#,inplace=True)\n",
    "new_df = pd.DataFrame()\n",
    "for future_year in future_years_list:\n",
    "    cname = 'plus_'+str(future_year)+'yr'\n",
    "    survival_prob = [lin_interpolate(mgr_sf_df,x,'managers') for x in current_mgr.values+future_year*12.0]\n",
    "    a_df = pd.DataFrame(survival_prob,columns=[cname])\n",
    "    new_df = pd.concat([new_df,a_df],axis=1)\n",
    "    \n",
    "print new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df.sum()/len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hold_df = mgr_sf_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clvl_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clvl = empltbl3.GRADE.isin(clvl_codes)\n",
    "sum(clvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(empltbl3[clvl].status==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12.5,5))\n",
    "\n",
    "kmf_grade=KaplanMeierFitter()\n",
    "\n",
    "kmf_grade.fit(empltbl3[clvl].Tenure_months, timeline=tenure_month_range, event_observed=empltbl3[clvl].status,label='C-Level')\n",
    "#grade_sf_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ax = fig.add_subplot(111)\n",
    "kmf_grade.plot(ax=ax,c='darkred')\n",
    "kmf_grade.fit(empltbl3[~clvl].Tenure_months, timeline=tenure_month_range,event_observed=empltbl3[~clvl].status,label='non C-level')\n",
    "kmf_grade.plot(ax=ax,color='darkslategray')\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at different PA/RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ra = empltbl3.GRADE.isin(ra_codes)\n",
    "print sum(ra), ra_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rd = empltbl3.GRADE.isin(rd_codes)\n",
    "print sum(rd), rd_codes\n",
    "for code in rd_codes:\n",
    "    print code,sum(empltbl3.GRADE == code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12.5,5))\n",
    "\n",
    "kmf_grade=KaplanMeierFitter()\n",
    "\n",
    "kmf_grade.fit(empltbl3[ra].Tenure_months, timeline=tenure_month_range, event_observed=empltbl3[ra].status,label='RA')\n",
    "#grade_sf_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ax = fig.add_subplot(111)\n",
    "kmf_grade.plot(ax=ax,c='darkred')\n",
    "kmf_grade.fit(empltbl3[~ra].Tenure_months, timeline=tenure_month_range,event_observed=empltbl3[~ra].status,label='non RA')\n",
    "kmf_grade.plot(ax=ax,color='darkslategray')\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12.5,5))\n",
    "\n",
    "kmf_grade=KaplanMeierFitter()\n",
    "\n",
    "kmf_grade.fit(empltbl3[rd].Tenure_months, timeline=tenure_month_range, event_observed=empltbl3[rd].status,label='RD')\n",
    "#grade_sf_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ax = fig.add_subplot(111)\n",
    "kmf_grade.plot(ax=ax,c='darkred')\n",
    "kmf_grade.fit(empltbl3[~rd].Tenure_months, timeline=tenure_month_range,event_observed=empltbl3[~rd].status,label='non RD')\n",
    "kmf_grade.plot(ax=ax,color='darkslategray')\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re = empltbl3.GRADE.isin(re_codes)\n",
    "print sum(re), re_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12.5,5))\n",
    "\n",
    "kmf_grade=KaplanMeierFitter()\n",
    "\n",
    "kmf_grade.fit(empltbl3[re].Tenure_months, timeline=tenure_month_range, event_observed=empltbl3[re].status,label='RE')\n",
    "#grade_sf_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ax = fig.add_subplot(111)\n",
    "kmf_grade.plot(ax=ax,c='darkred')\n",
    "kmf_grade.fit(empltbl3[~re].Tenure_months, timeline=tenure_month_range,event_observed=empltbl3[~re].status,label='non RE')\n",
    "kmf_grade.plot(ax=ax,color='darkslategray')\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pa = empltbl3.GRADE.isin(pa_codes)\n",
    "print sum(pa), pa_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ma_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3[empltbl3.GRADE=='MG2'].JOBCODE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.JOBCODE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empltbl3[empltbl3['status'==1]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.JOB_FUNCTION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl[empl.GRADE_MA1==1].status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12.5,5))\n",
    "\n",
    "kmf_grade=KaplanMeierFitter()\n",
    "\n",
    "kmf_grade.fit(empltbl3[pa].Tenure_months, timeline=tenure_month_range, event_observed=empltbl3[pa].status,label='PA')\n",
    "#grade_sf_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ax = fig.add_subplot(111)\n",
    "kmf_grade.plot(ax=ax,c='darkred')\n",
    "kmf_grade.fit(empltbl3[~pa].Tenure_months, timeline=tenure_month_range,event_observed=empltbl3[~pa].status,label='non PA')\n",
    "kmf_grade.plot(ax=ax,color='darkslategray')\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb = empltbl3.GRADE.isin(pb_codes)\n",
    "print sum(pb), pb_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12.5,5))\n",
    "\n",
    "kmf_grade=KaplanMeierFitter()\n",
    "\n",
    "kmf_grade.fit(empltbl3[pb].Tenure_months, timeline=tenure_month_range, event_observed=empltbl3[pb].status,label='PB')\n",
    "#grade_sf_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ax = fig.add_subplot(111)\n",
    "kmf_grade.plot(ax=ax,c='darkred')\n",
    "kmf_grade.fit(empltbl3[~pb].Tenure_months, timeline=tenure_month_range,event_observed=empltbl3[~pb].status,label='non PB')\n",
    "kmf_grade.plot(ax=ax,color='darkslategray')\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf = empltbl3.GRADE.isin(sf_codes)\n",
    "print sum(sf), sf_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12.5,5))\n",
    "\n",
    "kmf_grade=KaplanMeierFitter()\n",
    "\n",
    "kmf_grade.fit(empltbl3[sf].Tenure_months, timeline=tenure_month_range, event_observed=empltbl3[sf].status,label='SF')\n",
    "#grade_sf_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ax = fig.add_subplot(111)\n",
    "kmf_grade.plot(ax=ax,c='darkred')\n",
    "kmf_grade.fit(empltbl3[~sf].Tenure_months, timeline=tenure_month_range,event_observed=empltbl3[~sf].status,label='non SF')\n",
    "kmf_grade.plot(ax=ax,color='darkslategray')\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ma = empltbl3.GRADE.isin(ma_codes)\n",
    "print sum(ma), ma_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12.5,5))\n",
    "\n",
    "kmf_grade=KaplanMeierFitter()\n",
    "\n",
    "kmf_grade.fit(empltbl3[ma].Tenure_months, timeline=tenure_month_range, event_observed=empltbl3[ma].status,label='MA')\n",
    "#grade_sf_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ax = fig.add_subplot(111)\n",
    "kmf_grade.plot(ax=ax,c='darkred')\n",
    "kmf_grade.fit(empltbl3[~ma].Tenure_months, timeline=tenure_month_range,event_observed=empltbl3[~ma].status,label='non MA')\n",
    "kmf_grade.plot(ax=ax,color='darkslategray')\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pa = empltbl3.GRADE.isin(pa_codes)\n",
    "print sum(pa), pa_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grade_sf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### More directly look at these 20 groupings:\n",
    "# create a dataFrame of these survival functions.\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12.5,5))\n",
    "#figsize(16,8)\n",
    "\n",
    "#grade_groups = #list(empltbl3.GRADE.value_counts()[:85].index)\n",
    "kmf_grade=KaplanMeierFitter()\n",
    "\n",
    "kmf_grade.fit(empltbl3.Tenure_months, timeline=tenure_month_range, event_observed=empltbl3.status,label='ALL')\n",
    "gp_grade_sf_df = pd.DataFrame(kmf_grade.survival_function_)\n",
    "ax=fig.add_subplot(111)\n",
    "kmf_grade.plot(ax=ax,c='darkslategray')\n",
    "for g in grade_groupings_list_A:\n",
    "    \n",
    "    #plt.figure(figsize=(20,10))\n",
    "    gem_grade = empltbl3.GRADE.isin(g)\n",
    "    kmf_grade.fit(empltbl3[gem_grade].Tenure_months, timeline=tenure_month_range,event_observed=empltbl3[gem_grade].status)#,label=grade)\n",
    "    #if grade.startswith('MG'):\n",
    "    kmf_grade.plot(ax=ax)\n",
    "    gp_grade_sf_df = pd.concat([gp_grade_sf_df,kmf_grade.survival_function_],axis=1)\n",
    "#kmf_gender.fit(female.Tenure_months,  timeline=tenure_month_range,event_observed=female.status)\n",
    "#kmf_gender.plot(ax=ax, c='deeppink',label='Female')\n",
    "\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')\n",
    "\n",
    "#print sum(empltbl3.GRADE.isin(g)), g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gp_grade_sf_df.columns=['ALL','MG','C','MA','PA','PB','SF','RA','RD','RE','RB','RC','PC','L','FA', 'U', 'B', 'NON','M','R*','OTHR']#,inplace=True)\n",
    "                               #mg_codes,clvl_codes,ma_codes,pa_codes,pb_codes,sf_codes, ra_codes,rd_codes,re_codes, rb_codes, rc_codes,\n",
    "                          #pc_codes,l_codes,fa_codes, u_codes,b_codes,non_codes,m_codes,rx_codes,oth_codes\n",
    "\n",
    "gp_grade_sf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gp_grade_sf_df.iloc[1].plot(kind='bar',color='steelblue')\n",
    "plt.title('Survival Propensity at 1 year')\n",
    "plt.ylabel('Survival Distribution')\n",
    "plt.xlabel('Grouped Grade code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(gp_grade_sf_df.ALL.values <=0.50)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gp_grade_sf_df[gp_grade_sf_df['ALL']<=0.50].index[0]/12.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Function to return the time when distribution falls to 50%\n",
    "def find_Npct_survival(x,npct=0.50):\n",
    "    first_index = np.where(x <=npct)[0][0]\n",
    "    #ten_years = \n",
    "    print first_index, x.iloc[first_index], x.index[first_index]#.timeline\n",
    "    #first_index-1\n",
    "    #, x.iloc[first_index-1]\n",
    "    return x.index[first_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gp_grade_sf_df['ALL'].index[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnames = []\n",
    "fiftyPCT = []\n",
    "for c in gp_grade_sf_df.columns:\n",
    "    cnames.append(c)\n",
    "    fiftyPCT.append(find_Npct_survival(gp_grade_sf_df[c])/12.)#.apply(lambda x: find_Npct_survival(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xvals= xrange(len(cnames))\n",
    "h = plt.bar(xvals,fiftyPCT,color='steelblue')\n",
    "plt.ylabel('Number of Tenure Years where SF <= 50%')\n",
    "#plt.xlim(0,21)\n",
    "plt.xlabel('Grouped Grades')\n",
    "plt.title('Job Grades impact on SF fraction.')\n",
    "\n",
    "xticks_pos = [0.65*patch.get_width() + patch.get_xy()[0] for patch in h]\n",
    "plt.xticks(xticks_pos,cnames,rotation='vertical')\n",
    "plt.grid(True)\n",
    "plt.xlim(0,21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY To look at how age effects sF\n",
    "* bin this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.Age_years.hist(bins=70,range=[15,84],color='darkorchid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.Age_years.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3.Age_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3['AgeGroup'] = pd.cut(empltbl3.Age_years,[0,24.5,34.5,44.5,54.5,64.5,100],labels=['0','1','2','3','4','5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_group_labels = ['0','1','2','3','4','5']\n",
    "fig = plt.figure(figsize=(12.5,5))\n",
    "kmf_agp = KaplanMeierFitter()\n",
    "kmf_agp.fit(empltbl3.Tenure_months, timeline=tenure_month_range, event_observed=empltbl3.status,label='ALL')\n",
    "    \n",
    "age_gp_sf_df = pd.DataFrame(kmf_agp.survival_function_)\n",
    "ax=fig.add_subplot(111)\n",
    "kmf_agp.plot(ax=ax,c='darkslategray')\n",
    "\n",
    "for ag in age_group_labels:\n",
    "    age_group = empltbl3[empltbl3.AgeGroup == ag]\n",
    "    print ag, len(age_group)\n",
    "    \n",
    "    \n",
    "        \n",
    "    kmf_agp.fit(age_group.Tenure_months, timeline=tenure_month_range,event_observed=age_group.status,label=ag)\n",
    "    \n",
    "    kmf_agp.plot(ax=ax)\n",
    "    age_gp_sf_df = pd.concat([age_gp_sf_df,kmf_grade.survival_function_],axis=1)\n",
    "\n",
    "plt.ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')\n",
    "plt.title('Survival for various age groups')\n",
    "\n",
    "#print sum(empltbl3.GRADE.isin(g)), g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_gp_sf_df.columns = ['ALL','0to25','25to35','35to45','45to55','55to65','65to100']#+=age_group_labels\n",
    "age_gp_sf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_grp_types = empltbl3.AgeGroup.unique()\n",
    "kmf= KaplanMeierFitter()\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "\n",
    "for i,agp_type in enumerate(age_grp_types):\n",
    "    ax = plt.subplot(2,3,i+1)\n",
    "    ix = empltbl3['AgeGroup'] == agp_type\n",
    "    kmf.fit( empltbl3[ix].Tenure_months, empltbl3[ix].status, label=age_gp_sf_df.columns[i+1])\n",
    "    kmf.plot(ax=ax, legend=False)\n",
    "    plt.title(age_gp_sf_df.columns[i+1])\n",
    "    plt.xlim(0,500)\n",
    "    if i==0:\n",
    "        plt.ylabel('Frac. Working after $n$ months')\n",
    "    if i == 3:\n",
    "        plt.xlabel(\"Tenure in Months\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf[sdf.Column.isin(cols_to_categorical)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this was descriptive, how to make it predictive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using `AalenAdditiveFitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lifelines import AalenAdditiveFitter\n",
    "import patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = patsy.dmatrix('Age_years + COMPANY + INTERN + SEX',empltbl4, return_type='dataframe')\n",
    "X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf = AalenAdditiveFitter(penalizer=1.0, fit_intercept=True)\n",
    "X['T'] = empltbl4['Tenure_years']\n",
    "X['E'] = empltbl4['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.fit(X,'T','E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.cumulative_hazards_.loc[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X = patsy.dmatrix('SEX + AgeGroup + INTERN + DIVISION_CODE_SFI -1', empltbl3, return_type='dataframe')\n",
    "X = patsy.dmatrix('AgeGroup + INTERN -1', empltbl3, return_type='dataframe')\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf = AalenAdditiveFitter(penalizer=1.0, fit_intercept=True)\n",
    "X['T'] = empltbl3['Tenure_years']\n",
    "X['E'] = empltbl3['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.fit(X,'T','E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.cumulative_hazards_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Estimates of cumulative $\\beta_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.plot( columns=[ 'AgeGroup[0]','AgeGroup[1]','AgeGroup[2]','INTERN[T.Y]', 'baseline' ], ix=slice(1,35) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try to predict someone's tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix = (empltbl3['AgeGroup'] == '0')\n",
    "ib = (empltbl3['AgeGroup'] == '2')\n",
    "#harper = X[ix,:][-1,:][None,:]\n",
    "#harper[0,-1] = 2003\n",
    "#print \"Harper's unique data point\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[ix].iloc[[0,2],0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[ib].iloc[20:25]#,0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test1 = X[ix].iloc[0] \n",
    "test2 = X[ix].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf.predict_survival_function(X[ix].iloc[[0,2],0:-2]).plot()\n",
    "plt.xlim(0,10)\n",
    "aaf.predict_survival_function(X[ib].iloc[[20,21],0:-2]).plot()\n",
    "plt.xlim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "aaf.predict_cumulative_hazard(test1.values).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in sdf.Column if x.startswith('JOB')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf[sdf.Column == 'GRADE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current.GRADE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a graph out of the active employees\n",
    "* use the index from the dataframe as the node number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.DiGraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize with the ceo index\n",
    "#initialize with the ceo index\n",
    "#initialize with the ceo index\n",
    "ceo_index = list(current[current.KEY==ceo_key].index)[0]\n",
    "print ceo_index,ceo_key\n",
    "G.add_node(ceo_index)\n",
    "G.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def id_dependents("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now apply some logic to these columns for keeping and not\n",
    "columns_to_fix_missing = []\n",
    "columns_to_fix_NY = []\n",
    "columns_to_omit = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_to_fix_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sdf[sdf['datatype']=='object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf[(sdf['datatype']=='object') & (sdf['x_missing']<=missing_threshold) & (sdf['x_missing'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl3[empltbl3.STATE == 'NB'][['status','LOC_STATE','LOC_CITY','JOB_FUNCTION']]#,'zip5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl[empltbl.POSTAL_SFI.isnull()].zip5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl.ACTRES1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# omit those that have more than 40% missing:\n",
    "columns_to_omit = sdf[sdf['x_missing'] > missing_threshold].Column.values\n",
    "print len(columns_to_omit)\n",
    "columns_to_omit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(empltbl['HUBIND'],empltbl['SUPV_DIFF_LOC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl.FLSA_STATUS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl.JOB_FAMILY.value_counts()[empltbl.JOB_FAMILY.value_counts()>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sort(columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_tbl = empltbl[columns_to_keep].copy()\n",
    "reduced_tbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## drop those that are not VOL or NOT in VOLINVOL column\n",
    "sum(reduced_tbl.isin({'VOLINVOL':['NOT','VOLUNTARY']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cat_col in cols_to_categorical:\n",
    "    reduced_tbl[cat_col] = reduced_tbl[cat_col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_summary_df = summarize_dataframe2(red_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_tbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_tbl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(reduced_tbl['REMOTE'],reduced_tbl['HUBIND'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(reduced_tbl['FTPTCNT1'],reduced_tbl['PTFTCNT1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_tbl.FULL_PART_TIME.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## further reduce by removing\n",
    "FULL_PART_TIME, ACTRES1, KEY, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(reduced_tbl.JOB_FAMILY.unique()), len(reduced_tbl.JOB_FUNCTION.unique()), len(reduced_tbl.GRADE.unique()),len(reduced_tbl.JOBCODE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_tbl.JOB_FUNCTION.value_counts().plot(kind='bar',color='burlywood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_tbl.GRADE.value_counts().plot(kind='bar',color='burlywood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sum(reduced_tbl.MAX_RT_ANNUAL==0)\n",
    "reduced_tbl[reduced_tbl.ANNUAL_RT!=0].ANNUAL_RT.hist(bins=40,color='darkorchid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(reduced_tbl.ANNUAL_RT==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_tbl['JOB_FUNCTION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_columns_list = ['SEX','INTERN','FULL_PART_TIME']#,'COMPANY','VOLINVOL']#'JOB_FUNCTION','COMPANY','HUBIND','VOLINVOL']\n",
    "sum(reduced_tbl[initial_columns_list].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jf_hold = reduced_tbl.JOB_FUNCTION.astype('object')\n",
    "jf_hold.fillna('XXX',inplace=True)\n",
    "reduced_tbl['JOB_FUNCTION'] = jf_hold\n",
    "reduced_tbl['JOB_FUNCTION'] = reduced_tbl['JOB_FUNCTION'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_columns_list = ['SEX','Age_years','INTERN','FULL_PART_TIME','JOB_FUNCTION','COMPANY','HUBIND','VOLINVOL']\n",
    "sum(reduced_tbl[initial_columns_list].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pull out the reduced columns\n",
    "fill_flag = True\n",
    "reduced2 = reduced_tbl[initial_columns_list].copy()\n",
    "for c in reduced2.columns:\n",
    "    nmissing = sum(reduced2[c].isnull())\n",
    "    datatype = reduced2[c].dtype\n",
    "    if nmissing > 0 and fill_flag:\n",
    "        if datatype=='category':\n",
    "            reduced2[c].fillna('XNA',inplace=True)\n",
    "    \n",
    "        \n",
    "    print c, reduced2[c].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced2 = reduced_tbl[initial_columns_list].copy()\n",
    "reduced2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_columns_list1 = list(reduced2.columns) #['SEX','INTERN','FULL_PART_TIME','JOB_FUNCTION','COMPANY','HUBIND','VOLINVOL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dummified dataframe.\n",
    "reduced_dummies = pd.get_dummies(reduced2[dummy_columns_list1])\n",
    "print reduced_dummies.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_column_list2 = list(reduced_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_col_to_drop = []\n",
    "for col in dummy_columns_list1:\n",
    "    dclist = [x for x in dummy_column_list2 if x.startswith(col)]\n",
    "    print dclist\n",
    "    dummy_col_to_drop.append(dclist[0])\n",
    "\n",
    "dummy_col_to_keep = list(set(dummy_column_list2) - set(dummy_col_to_drop))\n",
    "\n",
    "reduced3 = reduced_dummies[dummy_col_to_keep].copy()\n",
    "#add the non-categorical back in\n",
    "#reduced3[initial_columns_list[1]] = reduced2[initial_columns_list[1]]\n",
    "reduced3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add in status and time\n",
    "reduced3['Age'] = empltbl['Age_years']\n",
    "reduced3['status'] = empltbl['status']\n",
    "reduced3['Tenure'] = empltbl['Tenure_months']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aalen's Additive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lifelines import AalenAdditiveFitter\n",
    "reduced3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_tenure = AalenAdditiveFitter(penalizer=1.0,fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_tenure.fit(reduced3,'Tenure',event_col='status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_tenure.plot(columns=['FULL_PART_TIME_P','Age','SEX_M','baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_tenure_b = AalenAdditiveFitter(penalizer=1.0,fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_tenure_b.fit(reduced3,'Tenure',event_col='status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoxPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_tenure = CoxPHFitter()\n",
    "cf_tenure.fit(reduced3,'Tenure',event_col='status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_tenure.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_tenure.plot(columns=['FULL_PART_TIME_P','Age','SEX_M','baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_tenure.hazards_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_tenure.baseline_cumulative_hazard_.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cf_tenurereenure.base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduced3.index = np.arange(0,len(reduced3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k-fold\n",
    "\n",
    "from lifelines.utils import k_fold_cross_validation\n",
    "\n",
    "#regression_dataset = load_regression_dataset()\n",
    "cf = CoxPHFitter()\n",
    "scores = k_fold_cross_validation(cf, reduced3, 'Tenure', event_col='status', k=5)\n",
    "print scores\n",
    "print scores.mean()\n",
    "print scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = patsy.dmatrix('SEX + JOB_FUNCTION + Age_years + INTERN + COMPANY + VOLINVOL + HUBIND - 1', reduced2, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patsy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now use lifelines\n",
    "from lifelines import KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(14,6)\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(empltbl.Tenure_months, event_observed=empltbl.status)\n",
    "kmf.plot()\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure months')\n",
    "plt.title('KaplanMeier Survival: ALL employees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmf.survival_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### look at difference between M & F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "male = empltbl[empltbl['SEX'] =='M']\n",
    "female = empltbl[empltbl['SEX'] =='F']\n",
    "len(male),len(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "male.Tenure_months.describe(), female.Tenure_months.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_tenure_months= empltbl.Tenure_months.min()\n",
    "max_tenure_months = empltbl.Tenure_months.max()\n",
    "print min_tenure_months, max_tenure_months\n",
    "tenure_month_range = np.linspace(min_tenure_months,max_tenure_months,65)\n",
    "len(tenure_month_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "male.Tenure_months.hist(normed=True,color='dodgerblue',bins=65,label='M')\n",
    "female.Tenure_months.hist(normed=True,color='deeppink',alpha=0.5,bins=65,label='F')\n",
    "plt.xlabel('Tenure_months')\n",
    "plt.ylabel('Normed Distribution')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmf_gender = KaplanMeierFitter()\n",
    "#plt.figure(figsize=(20,10))\n",
    "kmf_gender.fit(male.Tenure_months, timeline=tenure_month_range,event_observed=male.status)\n",
    "ax = kmf_gender.plot(c='dodgerblue',label='Male')\n",
    "kmf_gender.fit(female.Tenure_months,  timeline=tenure_month_range,event_observed=female.status)\n",
    "kmf_gender.plot(ax=ax, c='deeppink',label='Female')\n",
    "ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Tenure Months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hazard Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lifelines import NelsonAalenFitter\n",
    "#plt.figure(figsize=(12.5,8))\n",
    "naf = NelsonAalenFitter()\n",
    "naf.fit(male.Tenure_months,timeline=tenure_month_range, event_observed=male.status)\n",
    "ax = naf.plot(c='dodgerblue',label='Male')\n",
    "naf.fit(female.Tenure_months,  timeline=tenure_month_range,event_observed=female.status)\n",
    "naf.plot(ax=ax, c='deeppink',label='Female')\n",
    "#ylim(0,1.05)\n",
    "plt.ylabel('Hazard Function')\n",
    "plt.xlabel('Tenure Months')\n",
    "#fit(male.Tenure_months,timeline=tenure_month_range, event_observed=male.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Repeat using age in years as timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl.Age_years.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(empltbl.Age_years > 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_age = empltbl.Age_years.min()\n",
    "max_age = empltbl.Age_years.max()\n",
    "print min_age, max_age, max_age - min_age\n",
    "delta_age= int(max_age - min_age)\n",
    "age_range = np.linspace(min_age,max_age,delta_age)\n",
    "len(age_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmf_age = KaplanMeierFitter()\n",
    "kmf_age.fit(empltbl.Age_years, timeline=age_range,event_observed=empltbl.status)\n",
    "kmf_age.plot(color='darkgoldenrod')\n",
    "plt.ylabel('Survival Distribution Function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "male.Age_years.hist(normed=True,color='dodgerblue',bins=82,alpha=0.7,label='M')\n",
    "female.Age_years.hist(normed=True,color='deeppink',alpha=0.3,bins=82,label='F')\n",
    "plt.xlabel('Age_years')\n",
    "plt.ylabel('Normed Distribution')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmf_gender_age = KaplanMeierFitter()\n",
    "#plt.figure(figsize=(20,10))\n",
    "kmf_gender_age.fit(male.Age_years, timeline=age_range,event_observed=male.status)\n",
    "ax = kmf_gender_age.plot(c='dodgerblue',label='Male')\n",
    "kmf_gender_age.fit(female.Age_years,  timeline=age_range,event_observed=female.status)\n",
    "kmf_gender_age.plot(ax=ax, c='deeppink',label='Female')\n",
    "ylim(0,1.05)\n",
    "plt.ylabel('Survival Distribution Function')\n",
    "plt.xlabel('Age (years)')\n",
    "plt.title('Gender-split KM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cox Proportional Hazard Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(empltbl.FLOORCNT1,empltbl.DEPTCNT1,color='burlywood',alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.crosstab(empltbl, index = 'JOBCNT1',columns =\n",
    "#(empltbl, \n",
    "empltbl[['JOBCNT1','LOCCNT1','DEPTCNT1','GRADECNT1','FLOORCNT1','SUPVCNT1']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c='EMPL_CLASS'\n",
    "empltbl[c].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "len(empltbl[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(empltbl.ANNUAL_RT,empltbl.SAL1,color='burlywood',alpha=0.3)\n",
    "empltbl[['ANNUAL_RT','SAL1']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(empltbl[empltbl.ANNUAL_RT>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log(empltbl.ANNUAL_RT+1).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl.SAL1.hist(bins=80)\n",
    "empltbl.SAL1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(empltbl.SAL1 == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl.RELOCATE_ALL_SFI.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl.LOCATION.value_counts().hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## encode some of the categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Per discussion with HR TEAM on April 22, 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl = empltbl4[empltbl4.sep_status<=2] # Remove the OTHER & UNKNOWN reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the list of ACTRES1 for  ReTIREMENT\n",
    "uniq_action_reasons_1 = empl.ACTRES1.unique()\n",
    "print len(uniq_action_reasons_1)\n",
    "#ret_action_reasons_1 = [x for x in uniq_action_reasons_1 if 'RETIREMENT' in x]\n",
    "#print len(ret_action_reasons_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_list = [x.split(';') for x in uniq_action_reasons_1]\n",
    "from itertools import chain\n",
    "act_reason_1_list = list(chain.from_iterable(temp_list))\n",
    "print len(act_reason_1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_reason_1_set = set(act_reason_1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(act_reason_1_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in act_reason_1_set if 'DISABI' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#possible_retire_codes = \n",
    "possible_retire_codes = [x for x in act_reason_1_set if ('RET' in x and  'RETURN' not in x) ]\n",
    "possible_retire_codes.append('DISABILITY')\n",
    "len(possible_retire_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "possible_retire_codes.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "possible_retire_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = empl.ACTRES1.ix[1]\n",
    "[a for a in t1.split(';') if a in possible_retire_codes ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "possible_retire_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl['disabled'] = empl.ACTRES1.apply(lambda x: len([a for a in x.split(';') if a == 'DISABILITY']))\n",
    "empl[empl['disabled']!=0].Age_years.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(empl.disabled==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.sep_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(empl), len(empltbl4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl[empl['retired']==1].Age_years.hist(bins=70,range=[16,85],color='darkorchid')\n",
    "empl[empl['retired']==0].Age_years.hist(bins=70,range=[16,86],color='forestgreen',alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(empl.retired==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(empl.retired,empl.sep_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl[(empl.sep_status==0) & (empl.retired==1)]['KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print empltbl[empltbl.KEY=='185980322857378'][date_columns]\n",
    "empltbl[empltbl.KEY=='185980322857378'].Age_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl[empltbl.KEY=='185980322857378'][['ACTRES1','ACTRES2','ACTRES3','ACTRES4','ACTRES5','ACTRES6','ACTRES7','ACTRES9','ACTRES10']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl[empl['retired']==1].Age_years.hist(bins=70,range=[16,85],color='darkorchid',label='retired')\n",
    "empl[(empl['retired']==0) & (empl.status==1)].Age_years.hist(bins=70,range=[16,86],color='forestgreen',alpha=0.7,label='separated')\n",
    "empl[(empl['retired']==0) & (empl.status==0)].Age_years.hist(bins=70,range=[16,86],color='darkkhaki',alpha=0.7,label='current')\n",
    "#empl[(empl['retired']==0) & (empl.status==1)].Age_years.hist(bins=70,range=[16,86],color='forestgreen',alpha=0.7)\n",
    "plt.ylabel('Number of employees')\n",
    "plt.xlabel('Age')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(empl.SAL1== 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(empl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## April 27, 2015 \n",
    "* need to categorize all data I can before loading into R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl4=pd.read_csv('employee_dataframe4.tsv',sep='\\t',index_col=0,dtype={'EMPL_CLASS':np.str,'EMPL_TYPE':np.str})\n",
    "empltbl4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf4 = summarize_dataframe2(empltbl4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf4[sdf4.datatype=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert ethnic_group to int\n",
    "empltbl4['ETHNIC_GROUP'] = empltbl4['ETHNIC_GROUP'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl4.STATE.value_counts()[empltbl4.STATE.value_counts()<50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl4.LOC_STATE.value_counts()[empltbl4.LOC_STATE.value_counts()<50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl4[empltbl4.STATE=='HH'][['status','LOC_STATE','STATE','KEY']]#in [11,29]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl[empltbl.STATE=='BC'][['KEY','LOC_STATE','STATE','status','POSTAL_SFI','ADDRESS1','ADDRESS2','TERMINATION_DT','GRADE','LOCATION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl[empltbl.KEY=='811710100533306'].values\n",
    "#empltbl[empltbl.KEY=='296979068916747'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl[empltbl.KEY=='811710100533306'][['ADDRESS1','ADDRESS2','LOCATION','POSTAL_SFI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl4.SEX.value_counts()\n",
    "empltbl4['COMP_FREQ_ANNUAL'] = 1\n",
    "empltbl4.loc[empltbl4['COMP_FREQUENCY']=='H','COMP_FREQ_ANNUAL'] = 0\n",
    "#empltbl4.drop('COMP_FREQUENCY',axis=1,inplace=True)\n",
    "\n",
    "# now deal with male,female\n",
    "empltbl4.replace({'SEX':{'M': 1,'F':0}},inplace=True)\n",
    "empltbl4[['COMP_FREQ_ANNUAL','SEX','SHIFT']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl4.COMP_FREQ_ANNUAL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl4.drop('COMP_FREQUENCY',axis=1,inplace=True)\n",
    "empltbl4.drop('STATE',axis=1,inplace=True)\n",
    "empltbl4.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign 1 to Y, 0 to N for the following columns\n",
    "columns_to_fix_NY = ['INTERN','FULLPART1','RELOCATE_ALL_SFI','HUBIND','REMOTE','REMOTE_SUPV','SUPV_DIFF_LOC','PARTFULL1']\n",
    "for acol in columns_to_fix_NY:\n",
    "    empltbl4.replace({acol :{'Y':1,'N':0}},inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_cat = ['FLSA_STATUS','FULL_PART_TIME','SHIFT','EMPL_TYPE','COMPANY','ETHNIC_GROUP','EEO1CODE','EMPL_CLASS','JOB_FUNCTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf4.sort(['arity','datatype'],ascending =True)[sdf4.arity > 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert HIRE_DT to HIRE_YEAR\n",
    "[c for c in empltbl4.columns if c.endswith('DT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empltbl4['retired'] = empltbl4.ACTRES1.apply(lambda x: identify_retired(x))\n",
    "sum(empltbl4.retired==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode the VOLINVOL column as ['INVOLUNTARY':2,'VOLUNTARY':1,'NOT':0,'\n",
    "empltbl4['sep_status'] = empltbl4['VOLINVOL'].replace({'NOT':0,'VOLUNTARY':1,'INVOLUNTARY':2,'OTHER':3,'UNKNOWN':3})\n",
    "empltbl4.sep_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl = empltbl4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl = empltbl4.copy()\n",
    "empl.drop(['VOLINVOL','ACTRES1','HIRE_DT'],axis=1,inplace=True)\n",
    "empl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "egrp, bc1 = create_factorized_df(empl,acol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgrp, bc1 = create_factorized_dfrized_df(empl,'LOC_STATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_cols_to_cat = ['LOC_STATE','GRADE','EXT_FUNC_ID_SFI','JOB_FAMILY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## remove sep_status == 3\n",
    "empl=empl[empl.sep_status<3].copy()\n",
    "empl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for acol in more_cols_to_cat[:2]:\n",
    "    print acol\n",
    "    t_df,bc1 = create_factorized_df(empl,acol)\n",
    "    # drop the original column\n",
    "    empl.drop(acol,inplace=True,axis=1)\n",
    "    # append the factorized categories\n",
    "    empl = pd.concat([empl,t_df],axis=1)\n",
    "    base_category_list.append(bc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## save this to a file\n",
    "empl.drop(more_cols_to_cat[2:],axis=1,inplace=True)\n",
    "empl.drop('KEY',axis=1,inplace=True)\n",
    "empl.to_csv('employee_dataframe5.tsv',sep='\\t',index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### create integers for times; required for CoxPH in H2O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl[['Age','Tenure']] = empl[['Age_years','Tenure_years']].applymap(lambda x: int(round(x,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl[['Age','Age_years']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.to_csv('employee_dataframe6.tsv',sep='\\t',index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdfB = summarize_dataframe2(empl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdfB.sort('arity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#empl.FUNC_ID_SFI.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_int(x):\n",
    "    try:\n",
    "        x=int(x)\n",
    "    except:\n",
    "        x=-1\n",
    "    return x\n",
    "\n",
    "empl.FUNC_ID_SFI = empl.FUNC_ID_SFI.apply(lambda x: convert_to_int(x))\n",
    "len(empl.FUNC_ID_SFI.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(empl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl.drop(['LOCATION','LEGACY_DEPT_SFI','Tenure_months'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl.to_csv('employee_dataframe5.tsv',sep='\\t',ignore_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[c for c  in enumerate(list(empl.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.loc[:2000,'status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.loc[:2000,'retired'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(empl.retired==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.loc[:4000,'retired'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = patsy.dmatrix('Age_years + COMPANY + INTERN + SEX',empltbl4, return_type='dataframe')\n",
    "#X.columns\n",
    "aaf = AalenAdditiveFitter(penalizer=1.0, fit_intercept=True)\n",
    "X['T'] = empltbl4['Tenure_years']\n",
    "X['E'] = empltbl4['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl.Age_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xft = patsy.dmatrix( 'Age_years +ANNUAL_RT+PERF1+INTERN+SEX',empl,return_type='dataframe')\n",
    "Xft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xft['T'] = empl.Tenure_years#empl.ix[:4010]['Tenure_years']\n",
    "Xft['E']=empl.retired#empl.ix[:4010]['retired']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_ret = AalenAdditiveFitter(penalizer=1.0, fit_intercept=True)\n",
    "aaf_ret.fit(Xft,'T','E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaf_ret.plot(columns=['baseline','Age_years','INTERN','SEX','ANNUAL_RT'],ix=slice(1,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "cf = CoxPHFitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "cf.fit(Xft[Xft.columns[1:]],'T','E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "few_columns1=['Age_years','ANNUAL_RT','PERF1','INTERN','SEX','Tenure_years','retired']\n",
    "reduced1 = empl.loc[:,few_columns1].copy()\n",
    "reduced1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "cf.fit(reduced1,'Tenure_years','retired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.confidence_intervals_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.hazards_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(aaf_ret.event_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lifelines.utils import k_fold_cross_validation\n",
    "xv_cf = CoxPHFitter()\n",
    "cf_scores = k_fold_cross_validation(xv_cf, reduced1,duration_col='Tenure_years',event_col='retired',k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_scores.mean(), cf_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xv_cf.hazards_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced1.ix[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(reduced1.iloc[4:5,:-2].values)\n",
    "retired_sf_avg = xv_cf.predict_survival_function(reduced1[reduced1.retired==1][reduced1.columns[:-2]].values).mean(axis=1)#.plot()#.iloc[34:35,:-2].values).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notretired_sf_avg = xv_cf.predict_survival_function(reduced1[reduced1.retired==0][reduced1.columns[:-2]].values).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xv_cf.predict_survival_function(re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retired_sf_avg.plot(label='retired')\n",
    "notretired_sf_avg.plot(label='not-retired')\n",
    "plt.xlabel('Tenure Years')\n",
    "plt.ylabel('Predicted Survival Function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced1.iloc[24:25,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf.baseline_survival_.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## examining relationships (correlations) between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl[['Tenure_years','hire_year']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.plot(kind='scatter',x='Tenure_years',y='hire_year',\n",
    "          alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.plot(kind='scatter',x='hire_year',y='Age_years',\n",
    "          alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in empl.columns if x.endswith('MOS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.plot(kind='scatter',x='CUR_LOC_MOS',y='CUR_DEPT_MOS',color='chartreuse',          alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(empl.CUR_DEPT_MOS,empl.CUR_FUNC_MOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.Tenure.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.Tenure.hist(bins=65,color='steelblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## EXPLORE more about some of these features.\n",
    "* especially ones that may be missing or zeroed out\n",
    "* SAL1, MIN_RT_ANNUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl.MIN_RT_ANNUAL.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(empl.MIN_RT_ANNUAL==0.0), sum(empl.MAX_RT_ANNUAL==0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl[empl.MIN_RT_ANNUAL==0.0]['Tenure'].hist(range=[0,64],normed=True,bins=65)\n",
    "empl[empl.MIN_RT_ANNUAL!=0.0]['Tenure'].hist(range=[0,64],normed=True,bins=65,alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl[empl.MIN_RT_ANNUAL>0].MIN_RT_ANNUAL.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl[empl.MIN_RT_ANNUAL>1].MIN_RT_ANNUAL.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl[empl.MAX_RT_ANNUAL>1].MAX_RT_ANNUAL.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print empl.TELE_MOS.describe()\n",
    "empl.plot(kind='scatter', x='TELE_MOS',y='status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[c for c in empl.columns if c.startswith('JOB_FUNCTION')]\n",
    "#pd.crosstab(empl.GRADE_MA1,empl.JOB_FUNCTION_OTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(empltbl4.GRADE,empltbl4.JOB_FUNCTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
