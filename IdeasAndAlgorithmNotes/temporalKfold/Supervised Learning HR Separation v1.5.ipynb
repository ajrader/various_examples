{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning for HR Separations\n",
    "## October 2, 2015\n",
    "<hr>\n",
    "\n",
    "### 1. Go back to the 'raw' data so I can do the transformation in a pipe-oriented way from the start\n",
    "* start with histret, histcurr, empl and bene (<font color =red> NOPE</font>)\n",
    "* actually load from employees_after2001_raw.csv\n",
    "* raw_after2001_training.ssv or raw_after2001_eval.ssv?\n",
    "#### define the source repo\n",
    "* '/home/kesj/lib/repo/'\n",
    "\n",
    "### 2. Define the correct working directories\n",
    "* '/data/discovery/hrsepara/core/' for HDFS\n",
    "* '/data/discovery/hrsepara/staging/eda' and '/home/kesj/working/hrsepara/eda/' for HDFS and LFS on phd\n",
    "\n",
    "### load from\n",
    "* em2002 = pd.read_csv('employees_after2001_raw.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coredir = '/data/discovery/hrsepara/core/'\n",
    "stgdir1 = '/data/discovery/hrsepara/staging/eda'\n",
    "stgdir1local = '/home/kesj/work/hrsepara/eda'\n",
    "stgdir2local = '/home/kesj/work/hrsepara/proc'\n",
    "repodir = '/home/kesj/lib/repo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### load the basic files\n",
    "import os,subprocess,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "import random\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try connecting to h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ip_address = '10.96.242.228'\n",
    "#nslookup_result = !nslookup {ip_address}\n",
    "#ip_name = [a.split(' = ')[1] for a in nslookup_result if 'name' in a][0][:-1]\n",
    "#ip_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_h2o_node_name(ip_address):\n",
    "    nslookup_result = !nslookup {ip_address}\n",
    "    ip_name = [a.split(' = ')[1] for a in nslookup_result if 'name' in a][0][:-1]\n",
    "    ip_name = 'sf'+ip_name\n",
    "    return(ip_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o_ip = get_h2o_node_name(ip_address)\n",
    "h2o_port = 54323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "os.environ[\"NO_PROXY\"] = h2o_ip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Version mismatch. H2O is version 3.0.1.7, but the python package is version 3.3.0.3201.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>1 minutes 1 seconds 414 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.0.1.7</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>H2O_61473</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster total memory: </td>\n",
       "<td>30.67 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>320</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>320</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>sfda74wbdn23.opr.statefarm.org</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54323</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------\n",
       "H2O cluster uptime:         1 minutes 1 seconds 414 milliseconds\n",
       "H2O cluster version:        3.0.1.7\n",
       "H2O cluster name:           H2O_61473\n",
       "H2O cluster total nodes:    8\n",
       "H2O cluster total memory:   30.67 GB\n",
       "H2O cluster total cores:    320\n",
       "H2O cluster allowed cores:  320\n",
       "H2O cluster healthy:        True\n",
       "H2O Connection ip:          sfda74wbdn23.opr.statefarm.org\n",
       "H2O Connection port:        54323\n",
       "--------------------------  ------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(ip=h2o_ip,port=h2o_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plan of attack:\n",
    "1. read in the data, split it, munge it (partially done)\n",
    "2. transform into the temporal splits and pass each to h2o to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(repodir)\n",
    "import bear.bear as br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_record_dtype_dict = {'KEY':np.str,'LOCATION':np.str,'EEO1CODE':np.str,'SKEY':np.str,'JOBCODE':np.str,'EMPL_CLASS':np.str, \n",
    "                          'SHIFT':np.str,'COMPANY':np.str,'EXT_FUNC_ID_SFI':np.str,'FUNC_ID_SFI':np.str,\n",
    "                          'DIVISION_CODE_SFI':np.str,'JOB_FAMILY':np.str,'JOB_FUNCTION':np.str,'ACTRES1':np.str,\n",
    "                          'ACTRES2':np.str,'ACTRES3':np.str,'ACTRES4':np.str,'ACTRES5':np.str,'ACTRES6':np.str,\n",
    "                          'ACTRES7':np.str,'ACTRES8':np.str,'ACTRES9':np.str,'ACTRES10':np.str,'BOX1':np.str,\n",
    "                          'BOX2':np.str,'BOX3':np.str,'BOX4':np.str,'BOX5':np.str,'BOX6':np.str,'BOX7':np.str,\n",
    "                          'BOX8':np.str,'BOX9':np.str,'BOX10':np.str,'RATE1':np.str,'RATE2':np.str,'RATE3':np.str,\n",
    "                          'RATE4':np.str,'RATE5':np.str,'RATE6':np.str,'RATE7':np.str,'RATE8':np.str,'RATE9':np.str,\n",
    "                          'RATE10':np.str,'VOLINVOL':np.str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAG_REDO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if FLAG_REDO:\n",
    "    os.chdir(stgdir1local)\n",
    "    # August 28, 2015\n",
    "# Begin here by reading in the file\n",
    "    em2002 = pd.read_csv('employees_after2001_raw.csv',dtype=hist_record_dtype_dict)\n",
    "    em2002.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a few additional target columns\n",
    "* retired\n",
    "* separated\n",
    "* invol_sep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the list of ACTRES1 for  ReTIREMENT\n",
    "uniq_action_reasons_1 = em2002.ACTRES1.unique()\n",
    "print len(uniq_action_reasons_1)\n",
    "temp_list = [str(x).split(';') for x in uniq_action_reasons_1]\n",
    "from itertools import chain\n",
    "act_reason_1_list = list(chain.from_iterable(temp_list))\n",
    "print len(act_reason_1_list)\n",
    "act_reason_1_set = set(act_reason_1_list)\n",
    "print len(act_reason_1_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "possible_retire_codes = [x for x in act_reason_1_set if ('RET' in x and  'RETURN' not in x) ]\n",
    "possible_retire_codes.append('DISABILITY')\n",
    "len(possible_retire_codes)\n",
    "possible_retire_codes.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_retired(x,ret_codes =possible_retire_codes):\n",
    "    try:\n",
    "        matched = [a for a in x.split(';') if a in ret_codes]\n",
    "        if len(matched):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except AttributeError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002['retired'] = em2002.ACTRES1.apply(lambda x: identify_retired(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create a column for former (i.e. separated but NOT retired)\n",
    "em2002['former']= 0\n",
    "my_rows = em2002[(em2002.status==1) & (em2002.retired==0)].index\n",
    "print \"Out of {0} rows, {1} are separated and not retired.\".format(len(em2002),len(my_rows))\n",
    "#sum(empl_df['terminated']))#, len(my_rows)\n",
    "#em2002.iloc[my_rows,'former']=1\n",
    "em2002.loc[my_rows,'former']=1#.ix[my_rows]=1\n",
    "print sum(em2002.former)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(em2002.status, em2002.retired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(em2002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  There is one case where the person is 'retired' but has status of 0 is wrong -- I'm removing this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(em2002[~((em2002.status == 0)& (em2002.retired == 1))])\n",
    "em2002 = em2002[~((em2002.status == 0)& (em2002.retired == 1))]\n",
    "print len(em2002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up this data set a bit more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Starting with subset of {0} employees.\".format(len(em2002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cols =em2002.columns.tolist()\n",
    "columns_to_omit = [a for a in em2002.columns if a.startswith('ACTRES')]\n",
    "columns_to_omit.append('ADDRESS1')\n",
    "columns_to_omit.append('ADDRESS2')\n",
    "columns_to_omit.append('MAR_STATUS_DT')\n",
    "columns_to_omit.append('KEY')\n",
    "columns_to_omit.append('SKEY')\n",
    "columns_to_omit.append('STATE') # these values are noisier than LOC_STATE\n",
    "columns_to_omit.append('LOC_CITY')\n",
    "columns_to_omit.append('zip5')\n",
    "columns_to_omit.append('PER_ORG')\n",
    "columns_to_omit.append('POSTAL_SFI')\n",
    "columns_to_omit.append('VOLINVOL')\n",
    "columns_to_omit.append('MAR_STA_SNAME_SFI')\n",
    "print len(columns_to_omit)\n",
    "print len(all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cols2 = list(set(all_cols)-set(columns_to_omit))\n",
    "len(all_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(stgdir2local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if FLAG_REDO:\n",
    "    em2002[all_cols2].to_csv('after2001_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jump to HERE October 2, 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERF10</th>\n",
       "      <th>FLSA_STATUS</th>\n",
       "      <th>BIRTHDATE</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>CUR_LOC_MOS</th>\n",
       "      <th>JOB_FAMILY</th>\n",
       "      <th>MERIT3</th>\n",
       "      <th>former</th>\n",
       "      <th>RELOCATE_ALL_SFI</th>\n",
       "      <th>FULLPART10</th>\n",
       "      <th>...</th>\n",
       "      <th>SAL9</th>\n",
       "      <th>REMOTE_SUPV</th>\n",
       "      <th>DIVISION_CODE_SFI</th>\n",
       "      <th>SUPVCNT5</th>\n",
       "      <th>DEPTCNT5</th>\n",
       "      <th>status</th>\n",
       "      <th>DEPTCNT3</th>\n",
       "      <th>DEPTCNT1</th>\n",
       "      <th>ADDRCNT10</th>\n",
       "      <th>CUR_FUNC_MOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>12AUG1923</td>\n",
       "      <td>MA3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>02MAY1925</td>\n",
       "      <td>MA1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>06MAY1925</td>\n",
       "      <td>MA1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>21OCT1916</td>\n",
       "      <td>C5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>03MAY1925</td>\n",
       "      <td>M10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERF10 FLSA_STATUS  BIRTHDATE GRADE  CUR_LOC_MOS JOB_FAMILY  MERIT3  \\\n",
       "0       0           Z  12AUG1923   MA3            0        NaN       0   \n",
       "1       0           Z  02MAY1925   MA1            0        NaN       0   \n",
       "2       0           Z  06MAY1925   MA1            0        NaN       0   \n",
       "3       0           N  21OCT1916    C5            0        NaN       0   \n",
       "4       0           Z  03MAY1925   M10            0        NaN       0   \n",
       "\n",
       "   former RELOCATE_ALL_SFI FULLPART10      ...       SAL9  REMOTE_SUPV  \\\n",
       "0       0                N          N      ...          0            N   \n",
       "1       0                N          N      ...          0            N   \n",
       "2       0                N          N      ...          0            N   \n",
       "3       0                N          N      ...          0            N   \n",
       "4       0                N          Y      ...          0            N   \n",
       "\n",
       "   DIVISION_CODE_SFI  SUPVCNT5 DEPTCNT5  status  DEPTCNT3  DEPTCNT1  \\\n",
       "0                  6         0        0       1         0         0   \n",
       "1                  6         0        0       1         0         0   \n",
       "2                  6         0        0       1         0         0   \n",
       "3                  6         0        0       1         0         0   \n",
       "4                  9         0        0       1         0         0   \n",
       "\n",
       "   ADDRCNT10  CUR_FUNC_MOS  \n",
       "0          0             0  \n",
       "1          0             0  \n",
       "2          0             0  \n",
       "3          0             0  \n",
       "4          0             0  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em2 = pd.read_csv('after2001_v1.csv',dtype={'EMPL_CLASS':np.str,'LOCATION':np.str,'EEO1CODE':np.str,'SHIFT':np.str})\n",
    "em2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#em2[em2.columns[130]].head()#,53,81,130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic processing steps\n",
    "1. define set of columns to keep for analysis\n",
    "    * remove historical ones & Rate\n",
    "2. convert dates to timestamps and calculate the age/tenure/hire-age\n",
    "3. convert indicators\n",
    "4. convert BOX1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cols = em2.columns.tolist()\n",
    "print \"starting with {0} columns.\".format(len(all_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## look at historical columns and drop them\n",
    "historical_cols = []\n",
    "for i in xrange(2,11):\n",
    "    #print str(i)\n",
    "    hcols = [a for a in all_cols if a.endswith(str(i))]\n",
    "    historical_cols+=hcols\n",
    "print \"{0} historical columns will be omited\".format(len(historical_cols) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cols2 = list(set(all_cols)-set(historical_cols))\n",
    "all_cols2.remove('RATE1') # drop RATE1, it is collinear with BOX1\n",
    "print len(all_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mos_cols = [x for x in all_cols2 if x.endswith(\"MOS\")]\n",
    "print len(mos_cols), mos_cols\n",
    "date_cols = [x for x in em2.columns if x.endswith('DT')]\n",
    "date_cols.append('BIRTHDATE')\n",
    "date_cols.append('Tenure_tdelta')\n",
    "date_cols.append('Age_tdelta')\n",
    "print len(date_cols), date_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert BOX1 to a number\n",
    "em2['BOX1'].replace({'L':1,'S':2,'H':3},inplace=True)\n",
    "em2['BOX1'].fillna(0,inplace=True)\n",
    "em2.BOX1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert ages and tenures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_years(timestamp1,timestamp2,days_in_year =365.25):\n",
    "    number_of_years = (timestamp2 - timestamp1).days/days_in_year\n",
    "    return number_of_years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  calculate Age_years and Tenure_years\n",
    "em2[['hire_tstmp','birth_tstmp','term_tstmp']] = em2[['HIRE_DT','BIRTHDATE','TERMINATION_DT']].applymap(lambda x: pd.to_datetime(datetime.strptime(x,'%d%b%Y')))\n",
    "em2['Age_years']=em2[['birth_tstmp','term_tstmp']].apply(lambda x: calculate_years(x[0],x[1]),axis=1)\n",
    "em2['Tenure_years']=em2[['hire_tstmp','term_tstmp']].apply(lambda x: calculate_years(x[0],x[1]),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hire_age_tdelta = em2['hire_tstmp']-em2['birth_tstmp']\n",
    "# convert to days, months, or years\n",
    "em2['hire_age'] = hire_age_tdelta/np.timedelta64(1,'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mos_cols = [x for x in em2002.columns if x.endswith('MOS')]\n",
    "\n",
    "tstmp_cols = [x for x in em2.columns if x.endswith('tstmp')]\n",
    "print len(tstmp_cols), tstmp_cols\n",
    "\n",
    "useful_time_cols = []\n",
    "useful_time_cols.append('Tenure_years')\n",
    "useful_time_cols.append('Age_years')\n",
    "useful_time_cols.append('hire_age')\n",
    "print len(useful_time_cols), useful_time_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cols3 = list(set(all_cols2)-set(mos_cols)-set(date_cols))\n",
    "all_cols3 = list(set(all_cols3).union(set(tstmp_cols)))\n",
    "all_cols3+=useful_time_cols# redoing keeping tstmp columns\n",
    "print \"now there are {0} total columns to consider.\".format(len(all_cols3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[a for a in all_cols3 if a.endswith('tstmp')]\n",
    "[a for a in all_cols3 if a.endswith('age')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean up the indicator columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "br.get_columns_with_all_nulls(em2[all_cols3]) # good no columns are fully empty\n",
    "cat_cols = br.get_categorical(em2[all_cols3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## fill in missing for HAVE_DEP\n",
    "em2['HAVE_DEP'].fillna('N',inplace=True)\n",
    "em2.HAVE_DEP.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em2['HAVE_INS'].fillna('N',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2.HAVE_DEP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indicator_cols = []\n",
    "cat_cols2 = []\n",
    "for c in cat_cols:\n",
    "    nobs = len(em2[c].unique())\n",
    "    if nobs == 2:\n",
    "        indicator_cols.append(c)\n",
    "    else:\n",
    "        print c, nobs\n",
    "        cat_cols2.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert these indicator columns to binary reps (0/1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(c,em2[c].unique().tolist()) for c in indicator_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indicator_dict = {'INTERN': {'N':0,'Y':1},\n",
    "                  'REMOTE': {'N':0,'Y':1}, 'FULLPART1': {'N':0,'Y':1},\n",
    "                 'RELOCATE_ALL_SFI' : {'N':0,'Y':1},\n",
    "                'HUBIND':{'N':0,'Y':1},'SUPV_DIFF_LOC':{'N':0,'Y':1},\n",
    "     'HAVE_DEP': {'N':0,'Y':1},'HAVE_INS':{'N':0,'Y':1},'PARTFULL1':{'N':0,'Y':1},\n",
    "    'REMOTE_SUPV':{'N':0,'Y':1}, 'COMP_FREQUENCY': {'A':1,'H':0}, \n",
    "                  'SEX': {'M':0,'F':1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in indicator_cols:\n",
    "    em2[col].replace(indicator_dict[col],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## save file\n",
    "em2[all_cols3].to_csv('after2001_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT STARTING POINT OCT 6, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up missing & dummy encode/etc the categorical --> use a pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_columns = br.get_columns_with_nulls(em2[all_cols3])\n",
    "print len(missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_cat_cols = br.get_columns_with_nulls(em2[cat_cols2])\n",
    "missing_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mthl_tenure_range = np.linspace(0,65,781)\n",
    "def calculate_survival_functions_b(df,y, time_col, col_name,num_cutoff = 40,timerange =mthl_tenure_range):\n",
    "    \n",
    "    \"\"\" Function to generically return a dataframe of survival function, grouped by some categorical column\n",
    "    inputs:\n",
    "        df --> database to derive survival functions from\n",
    "        time_col --> the temporal column to use for SF modeling (Kaplan Meier fitter applied)\n",
    "        event_col --> the truncated column to use for SF modeling\n",
    "        col_name --> the column to group up and determine KMF sf for\n",
    "        num_cutoff --> number of groups to consider\n",
    "        timerange --> min and max range\n",
    "    outputs:\n",
    "        survivalfunc_df --> a data frame that contains survival function.\n",
    "\n",
    "    other options:\n",
    "        *frac_cutoff --> the fraction of unique elements that will be kept as separate groups\n",
    "        *min_size_cutoff --> min size to use for the cutoff.\n",
    "        * these last two are not implemented\n",
    "    \"\"\"\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    kmf=KaplanMeierFitter()\n",
    "    # create example for all cases -- serves as background\n",
    "    # create a time range\n",
    "    \n",
    "    kmf.fit(df[time_col],timeline=timerange,event_observed=y,label='all')\n",
    "    survivalfunc_df = pd.DataFrame(kmf.survival_function_)\n",
    "    # groupify the dataframe\n",
    "    grp_value_counts = df[col_name].value_counts()\n",
    "    #if frac_cutoff == None:\n",
    "    #    #by default take 15 %\n",
    "    #    frac_cutoff = .15 \n",
    "    #top_n_groups = int(frac_cutoff *len(grp_value_counts))\n",
    "    #if min_size_cutoff == None:\n",
    "        # by default \n",
    "    # Take the top num_cutoff groups\n",
    "    #my_grps = grp_value_counts.ix[:num_cutoff].index.tolist() \n",
    "    my_grps = grp_value_counts.iloc[:num_cutoff].index.tolist() \n",
    "    \n",
    "    # make a list of elements in each of these groups\n",
    "    grp_dict = {}\n",
    "    for grp in my_grps: \n",
    "        grp_dict[grp] = df[df[col_name] == grp].index.tolist()\n",
    "    # loop through grps and create kmf survival function\n",
    "    for i,jgrp in enumerate(my_grps):\n",
    "        j_idx = grp_dict[jgrp]\n",
    "        #print i, jgrp, len(j_idx)\n",
    "        kmf.fit(df[time_col].ix[j_idx],timeline=mthl_tenure_range,event_observed=y.ix[j_idx],label=str(jgrp))\n",
    "        survivalfunc_df = pd.concat([survivalfunc_df,kmf.survival_function_],axis=1)\n",
    "    \n",
    "    \n",
    "    return survivalfunc_df\n",
    "\n",
    "def return_first_time_survival(sfdf,thresh=0.5):\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # assign all value to the default\n",
    "    default_value = sfdf[sfdf['all']<=thresh].index[0]\n",
    "    median_survival_dict = defaultdict(lambda: default_value)\n",
    "    for c in sfdf.columns[1:]:\n",
    "        #print c\n",
    "        try:\n",
    "            my_sf_date = sfdf[sfdf[c]<=thresh].index[0]\n",
    "        except IndexError: # because never reached that threshold value\n",
    "            my_sf_date = sfdf.index[-1]\n",
    "        except KeyError: # because of type of the key\n",
    "            my_sf_date = sfdf[sfdf[int(c)]<=thresh].index[0]\n",
    "\n",
    "        median_survival_dict[c]=my_sf_date\n",
    "        \n",
    "    return median_survival_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SurvivalEncodeColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_fix=[],rows_to_scan='all',method='median',max_number_groups=40, my_thresh=0.5):\n",
    "        self.method = method\n",
    "        self.columns_to_fix = columns_to_fix\n",
    "        self.rows_to_scan = rows_to_scan\n",
    "        self.max_num_groups = max_number_groups\n",
    "        self.thresh = my_thresh\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.survive_columns = {} # dictionary to map old columns to new\n",
    "        self.survive_values = {}\n",
    "        self.column_cutoff = {}\n",
    "        \n",
    "        \n",
    "        for col in self.columns_to_fix:\n",
    "            #(assumes these have previously been label encoded so the values should be ints)\"\n",
    "            ncol=str(col)+\"_le\"\n",
    "            num_cutoff = self.max_num_groups\n",
    "            survive_col = 'surv_'+ncol.lower()\n",
    "            nuniq = len(X[ncol].unique())\n",
    "            if nuniq < num_cutoff:\n",
    "                num_cutoff = nuniq\n",
    "                \n",
    "            self.column_cutoff[col]=num_cutoff\n",
    "            \n",
    "            #frac_accounted_for = X[col].value_counts().iloc[:num_cutoff].sum()/float(len(X))\n",
    "            #print i,col,newcol, nuniq, num_cutoff,num_cutoff/float(nuniq),frac_accounted_for\n",
    "            # I want to make this fraction close to 80%?\n",
    "            sf_df = calculate_survival_functions_b(X,y,'Tenure_years', ncol,num_cutoff)\n",
    "            self.survive_columns[col]=survive_col\n",
    "            ## create the dictionary\n",
    "            self.survive_values[col]=return_first_time_survival(sf_df,thresh=self.thresh)\n",
    "    \n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        X_temp = X.copy()\n",
    "        original_cols = list(X_temp.columns)\n",
    "        for col in self.columns_to_fix:\n",
    "            ncol=str(col)+\"_le\" # assumes labelencoded\n",
    "            new_col = self.survive_columns[col]\n",
    "            col_dict = self.survive_values[col]\n",
    "            X_temp[new_col] = X_temp[ncol].apply(lambda x: col_dict[str(x)])\n",
    "            original_cols.remove(ncol)\n",
    "            original_cols.append(new_col)\n",
    "        \n",
    "        X_temp = X_temp[original_cols]\n",
    "        return X_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cols3.remove('LOCATION')\n",
    "all_cols3.remove('LEGACY_DEPT_SFI')\n",
    "all_cols3.remove('TOT_MO_SERVICE_SFI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_cols_to_omit =list(set(all_cols)-set(all_cols3))\n",
    "len(my_cols_to_omit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[a for a in all_cols3 if a.endswith('SFI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_cols2 = list(set(all_cols3).intersection(set(cat_cols2)))\n",
    "[(c,len(em2[c].unique())) for c in cat_cols2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_label_encode_cols = ['JOB_FAMILY', 'GRADE', 'JOB_FUNCTION',\n",
    " 'FLOR_SFI', 'FUNC_ID_SFI', 'EXT_FUNC_ID_SFI',\n",
    " 'JOBCODE', 'LOC_TYPE_DESCR_SFI',\n",
    " 'LOC_STATE']\n",
    "cat_cols_to_dummy_encode = ['EMPL_CLASS','EEO1CODE','EMPL_TYPE','FULL_PART_TIME','ETHNIC_GROUP','DIVISION_CODE_SFI','COMPANY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_minfix_cols = ['SAL1','MIN_RT_ANNUAL','MERIT1','PERF1']\n",
    "my_maxfix_cols = ['MAX_RT_ANNUAL']\n",
    "missing_zero_cols = ['BOX1','FUNC_CNT','EXTFUNC_CNT','TOTAL_RPT_CNT','DIRECT_RPT_CNT']\n",
    "mode_impute_cols = ['MERIT1','PERF1','ADDRCNT1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([(\"null\",br.RemoveAllNull()),\n",
    "                 (\"drop\",br.DropColumns(columns_to_drop =my_cols_to_omit)),\n",
    "                 (\"label_encode\",br.LabelEncodeColumn(my_label_encode_cols)),\n",
    "                 \n",
    "                 #(\"dummy_encode\", br.DummyEncodeColumn(cat_cols_to_dummy_encode)),\n",
    "                 (\"survival_encode\",SurvivalEncodeColumn(my_label_encode_cols[:5],method='median')),\n",
    "                 (\"dummy_encode\",br.ConvertCategorical(categorical_columns=cat_cols_to_dummy_encode,method='dummy')),\n",
    "                 (\"fixout_min\",br.FixNumericOutlier(columns_to_fix=my_minfix_cols,criteria_coef=('percentile',2),\n",
    "                                                   method='lower',fill_with='nearest_value')),\n",
    "                 (\"fixout_max\",br.FixNumericOutlier(columns_to_fix=['MAX_ANNUAL_RT'],criteria_coef=('percentile',2),\n",
    "                                                   method='both',fill_with='nearest_value')),\n",
    "                 (\"fill_missingzero\",br.FillMissingValue(columns_to_fix=missing_zero_cols,fill_value=0)),\n",
    "                 (\"imp_mode\",br.ImputeData(columns_to_impute=mode_impute_cols,rows_to_scan=0.8))\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pull out a build set to make the pipeline from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Starting with subest of {0} employees.\".format(len(em2))\n",
    "eval_fraction = 0.20\n",
    "em2build, em2eval = train_test_split(em2,test_size=eval_fraction)\n",
    "print \"Evaluation set has {0} employees; training set has {1} employees.\".format(len(em2eval),len(em2build))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = em2build['former']\n",
    "build = pipe2.fit_transform(em2build,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation = pipe2.fit(em2build,y).transform(em2eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_columns = build.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build.to_csv('trans_train.csv',index=False)\n",
    "evaluation.to_csv('trans_eval.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(list_of_columns)\n",
    "[a for a in list_of_columns if a in ['former','status','retired']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_for_modeling = [a for a in list_of_columns if a not in ['former','status','retired']]\n",
    "len(columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "br.perfect_collinearity_test(build[columns_for_modeling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redundant_cols = ['hire_age','FULLPART1','COMPANY','ETHNIC_GROUP',\n",
    "                  'EMPL_TYPE','DIVISION_CODE_SFI','ADDRCNT1_d','PERF1_d','MERIT_d',\n",
    "                  'EMPL_TYPE_E','FULL_PART_TIME_X','COMPANY_1','ETHNIC_GROUP_1.0','DIVISION_CODE_SFI_4',\n",
    "                 'EMPL_CLASS_1','EEO1CODE_6']\n",
    "columns_for_modeling2 = list(set(columns_for_modeling)-set(redundant_cols)-set(tstmp_cols))\n",
    "br.perfect_collinearity_test(build[columns_for_modeling2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(columns_for_modeling2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now build the time-kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the date range\n",
    "full_date_range = [str(a)+'-01-01' for a in np.arange(2002,2016)]\n",
    "print len(full_date_range)\n",
    "#full_date_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize temporal kfolds:\n",
    "1. split the training dataset into windows corresponding to the difference in time\n",
    "2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def create_temporal_kfolds(dates_df,date_range,time_delta):\n",
    "    \"\"\"\n",
    "    inputs: date_range\n",
    "            time_delta (in years)\n",
    "            dataframe_dates --> assumes 'hire_tstmp' and 'term_tstmp'\n",
    "    outputs:\n",
    "            kf is a list of list of list: \n",
    "            [indices from original df that are 'in' a fold, indices from original df that are 'out' of a fold]\n",
    "            each row in this corresponds to the temporal-kfold\n",
    "            filtered_pairs is a list of start and end times\n",
    "    \"\"\"\n",
    "    min_date = pd.to_datetime(date_range[0])\n",
    "    max_date = pd.to_datetime(date_range[-1])\n",
    "    my_index = dates_df[(dates_df.term_tstmp>=min_date)].index\n",
    "    # calculate number of kfolds\n",
    "    date_span_years = np.int(np.round((max_date-min_date).days/365.24,0))\n",
    "    nfolds = date_span_years - time_delta\n",
    "    print date_span_years, time_delta, nfolds, len(my_index)\n",
    "    all_pairs = list(itertools.combinations(date_range,2))\n",
    "    # now filter if difference in time  == time_delta\n",
    "    filtered_pairs = []\n",
    "    for i0,i1 in all_pairs:\n",
    "        if int(i1[:4])-int(i0[:4]) == time_delta:\n",
    "            filtered_pairs.append([i0,i1])\n",
    "            #print i0,i1\n",
    "    print len(filtered_pairs)\n",
    "    # now process each of these filtered pairs\n",
    "    kf = []\n",
    "    for j0,j1 in filtered_pairs: # omit the last one because it has no corresponding partner/endtime\n",
    "        start_date = pd.to_datetime(j0)\n",
    "        end_date = pd.to_datetime(j1)\n",
    "        #print j0,j1#,len(k)\n",
    "        \n",
    "        \n",
    "        kfold_idx = dates_df[(dates_df.term_tstmp >= start_date) & (dates_df.hire_tstmp<start_date)].index.tolist()\n",
    "        after_idx = dates_df[(dates_df.hire_tstmp>=end_date)].index.tolist()\n",
    "        before_idx = list(set(my_index)-set(kfold_idx)-set(after_idx))\n",
    "        #temporal_kfold(dates_df[dates_df.term_tstmp>=min_date],start_date,end_date)\n",
    "        #print \"\\t\",len(kfold_idx), len(after_idx),len(before_idx)\n",
    "        \n",
    "        # combined out of fold\n",
    "        not_kfold_idx = list(set(after_idx).union(set(before_idx)))\n",
    "        \n",
    "        print j0,j1,len(kfold_idx),len(not_kfold_idx)\n",
    "        kf.append([kfold_idx,not_kfold_idx])\n",
    "    \n",
    "    return kf,filtered_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_years2(paired_times,indices,dates_df,cols_to_alter = ['Age_years','Tenure_years']):\n",
    "    # calc the Age at beginnning of time period\n",
    "    ## now calculate age at hire\n",
    "    reset_age_tdelta = pd.to_datetime(paired_times[0])-dates_df['birth_tstmp']#)/np.timedelta64(1,'D')\n",
    "    reset_tenure_tdelta = pd.to_datetime(paired_times[0])-dates_df['hire_tstmp']#)/np.timedelta64(1,'D')\n",
    "    # convert to days, months or years\n",
    "    reset_age = reset_age_tdelta/np.timedelta64(1,'Y')\n",
    "    reset_tenure = reset_tenure_tdelta/np.timedelta64(1,'Y')\n",
    "    # look at terminated or not\n",
    "    #empl_df['terminated']= 0\n",
    "    # push these as a data frame so I can merge\n",
    "    adj_times = pd.DataFrame()\n",
    "    adj_times['adj_age']=reset_age\n",
    "    adj_times['adj_tenure']=reset_tenure      \n",
    "    return adj_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_target_within_x_years(df,paired_dates,tfold,n_years,target_col):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        df -- data frame\n",
    "        paired_dates (2nd output from create_temporal_kfolds)\n",
    "        tfold (1st output from create_temporal_kfolds)\n",
    "        targe_col --> desired target\n",
    "        \n",
    "    plan is to adjust the target, Age and tenure to match time frame of temporal kfold\n",
    "    outputs:\n",
    "    \"\"\"\n",
    "    print len(tfold)#, paired_dates\n",
    "\n",
    "    df_dict = {}\n",
    "    for i,tf in enumerate(tfold):\n",
    "        start_date = paired_dates[i][0]\n",
    "        end_date = paired_dates[i][1]\n",
    "        #print start_date,end_date,n_years\n",
    "        #altered_fold_df = pd.DataFrame(columns=['fold_mbr','adj_age','adj_tenure','adj_term'])\n",
    "        # if in the fold reset the age to start of fold; define new window of termination\n",
    "        in_fold_idx = tfold[i][0] # the index of the in_fold_observations \n",
    "        # note that \"sex\" is just used to create a value that then gets dummied out\n",
    "        cols_to_copy = ['SEX','Age_years','Tenure_years']\n",
    "        cols_to_copy.append(target_col)\n",
    "        \n",
    "        altered_fold_df = df[cols_to_copy].copy()\n",
    "        # adjust these\n",
    "        altered_fold_df.columns=['fold_mbr','adj_age','adj_tenure','adj_tgt']\n",
    "        altered_fold_df.fold_mbr = 0\n",
    "        \n",
    "        #ra,rt = reset_years(paired_dates[i],in_fold_idx,dates_df)\n",
    "        adj_df =reset_years2(paired_dates[i],in_fold_idx,df)\n",
    "        #altered_fold_df.ix[in_fold_idx]['adj_age']=ra\n",
    "        #altered_fold_df.ix[in_fold_idx]['adj_tenure']=rt\n",
    "        altered_fold_df.loc[in_fold_idx,['adj_age','adj_tenure']]=adj_df.ix[in_fold_idx] # assign to the altered values\n",
    "        new_tgt = (df.ix[in_fold_idx]['term_tstmp']<= end_date).as_matrix().astype(np.int)\n",
    "        #(em2mod.ix[kf[0][0]]['term_tstmp']<= fp[0][1]).as_matrix().astype(np.int)\n",
    "        # deal with last time-fold specially\n",
    "        if i == len(tfold)-1:\n",
    "            new_tgt = (df.ix[in_fold_idx]['term_tstmp']< end_date).as_matrix().astype(np.int)\n",
    "        #print \"\\t\", len(new_term),sum(new_term)\n",
    "        altered_fold_df.loc[in_fold_idx,'adj_tgt']=new_tgt\n",
    "        altered_fold_df.loc[in_fold_idx,'fold_mbr']=1\n",
    "        df_dict[i]=altered_fold_df\n",
    "    # now append this to a larger panel\n",
    "    tfold_panel = pd.Panel.from_dict(data =df_dict)\n",
    "    return tfold_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_tfolds(df, n_years, cols_to_model, tgt_value='former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = tstmp_cols, date_range=full_date_range):\n",
    "    \"\"\" Function to create the temporal kfolds\n",
    "    parameters:\n",
    "        df       - a pandas data frame (that has been preprocessed)\n",
    "        n_years  - size of the temporal window (in years)\n",
    "        cols_to_model - list of columns to use in the modeling procedure \n",
    "        tgt_value  - column name to use as the target variable\n",
    "        time_cols  - list of columns that are time senitive and must be adjusted\n",
    "        tstmp_cols - list of columns that contain timestamps for things like hiring, termination and birth\n",
    "        date_range - list comprising the inclusive annual starting dates from beginning to end of range.\n",
    "    output:\n",
    "        tfolds  - a list containing the indices of in and out of fold members for each of the tfolds created\n",
    "        tfold_panel - a pandas Panel (3D data frame) containing the membership in different folds, the adjusted targets,\n",
    "            the adjusted timesenitive data, and the columns to use for modeling.\n",
    "    \"\"\"    \n",
    "    # step 1 create the temporal_folds\n",
    "    if not [a for a in tstmp_cols if a in df.columns] == tstmp_cols:\n",
    "        print \"The list of required timestamp columns do not exist in the input dataframe.\"\n",
    "        print tstmp_cols\n",
    "        exit\n",
    "    tfolds, paired_dates = create_temporal_kfolds(df[tstmp_cols],date_range, n_years) \n",
    "    #defines the time-windows and assigns observations to folds\n",
    "    \n",
    "    # create the time-shifted tfolds and push into a pandas Panel (3D data frame)\n",
    "    tfold_panel=transform_df_to_tfold(df,tfolds,paired_dates,n_years,cols_to_model, tgt_value,tstmp_cols,time_cols)\n",
    "    return tfold_panel, tfolds\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_df_to_tfold(df,tfold,paired_dates,n_years,cols_to_keep,target_col,tstmp_cols,time_cols):\n",
    "    \"\"\"\n",
    "    Function to adjust the input data frame so that time_sensitive columns and target column\n",
    "    conform to the bounds of that temporal kfold (tfold). Specifically adjust the target, Age and tenure \n",
    "    to match time frame of temporal kfold\n",
    "    \n",
    "    Parameters:\n",
    "        df -- a pandas data frame\n",
    "        paired_dates (2nd output from create_temporal_kfolds)\n",
    "        tfolds (1st output from create_temporal_kfolds)\n",
    "        target_col --> desired target\n",
    "        cols_to_keep --> the list of columns within df that get expressed in df.\n",
    "        time_cols\n",
    "        \n",
    "    plan is to \n",
    "    outputs:\n",
    "        tfold_panel\n",
    "    \"\"\"\n",
    "    #print len(tfold)#, paired_dates\n",
    "    #print df.columns ,len(df.columns), len(cols_to_keep)\n",
    "    #return\n",
    "    # do some sanity checks\n",
    "    # 1. make sure cols_to_keep, target and tstmp_cols columns are in df.columns\n",
    "    input_column_list = df.columns.tolist()\n",
    "    n_total_columns = len(input_column_list)\n",
    "    #if (n_total_columns != len(cols_to_keep)+len(target_col)+len(tstmp_cols)):\n",
    "        # now look at each piece\n",
    "    targetlist = []\n",
    "    targetlist.append(target_col)\n",
    "    if not check_if_subset(targetlist,input_column_list):\n",
    "            #target_col in df.columns:\n",
    "            #print \"{0} target column not present in input set\".format(target_col)\n",
    "        return\n",
    "    if not check_if_subset(tstmp_cols,input_column_list):\n",
    "        return\n",
    "            #[a for a in tstmp_cols if a in input_column_list] == tstmp_cols: # requires\n",
    "            #print \"There are missing timestamp columns. Recheck the list {0}\".format(tstmp_cols)\n",
    "    #        return\n",
    "    if not check_if_subset(time_cols,input_column_list):\n",
    "            #[a for a in time_cols if a in input_column_list] == time_cols: # requires\n",
    "            #print \"There are missing timestamp columns. Recheck the list {0}\".format(tstmp_cols)\n",
    "        return    \n",
    "    if not check_if_subset(cols_to_keep,input_column_list):\n",
    "        return\n",
    "    \n",
    "    ## now set up the columns for manipulation\n",
    "    cols_to_copy = cols_to_keep\n",
    "    if not check_if_subset(time_cols,cols_to_keep):\n",
    "        cols_to_copy+=time_cols\n",
    "        print len(cols_to_copy)\n",
    "    \n",
    "    \n",
    "    df_dict = {}\n",
    "    \n",
    "    # identify which element of tstmp_cols corresponds to term_tstmp\n",
    "    term_id = tstmp_cols.index('term_tstmp')\n",
    "    birth_id = tstmp_cols.index('birth_tstmp')\n",
    "    hire_id = tstmp_cols.index('hire_tstmp')\n",
    "    #print term_id, tstmp_cols[term_id]\n",
    "    \n",
    "    for i,tf in enumerate(tfold):\n",
    "        start_date = paired_dates[i][0]\n",
    "        end_date = paired_dates[i][1]\n",
    "        \n",
    "        in_fold_idx = tfold[i][0] # the index of the in_fold_observations \n",
    "       \n",
    "        altered_fold_df = df[cols_to_copy].copy()\n",
    "        altered_fold_df['fold_mbr']=0 # create a new column to identify membership in that fold.\n",
    "        altered_fold_df.loc[in_fold_idx,'fold_mbr']=1 # assign the in_fold_indices to that fold membership\n",
    "        ####\n",
    "        # adjust the age and tenure for those in the fold\n",
    "        reset_age_tdelta = pd.to_datetime(start_date)-df.ix[in_fold_idx][tstmp_cols[birth_id]]\n",
    "        reset_age = reset_age_tdelta/np.timedelta64(1,'Y')\n",
    "        reset_tenure_tdelta = pd.to_datetime(start_date)-df.ix[in_fold_idx][tstmp_cols[hire_id]]\n",
    "        reset_tenure = reset_tenure_tdelta/np.timedelta64(1,'Y')\n",
    "        altered_fold_df.loc[in_fold_idx,'Age_years']=reset_age\n",
    "        altered_fold_df.loc[in_fold_idx,'Tenure_years']=reset_tenure\n",
    "        old_tgt = df.ix[tfold[i][1]][target_col]\n",
    "        new_tgt = (df.ix[in_fold_idx][tstmp_cols[term_id]]<= end_date).as_matrix().astype(np.int)\n",
    "        # deal with last time-fold specially\n",
    "        if i == len(tfold)-1:\n",
    "            new_tgt = (df.ix[in_fold_idx][tstmp_cols[term_id]]< end_date).as_matrix().astype(np.int)\n",
    "            \n",
    "        altered_fold_df.loc[in_fold_idx,target_col]=new_tgt\n",
    "        old_tgt = df.ix[tfold[i][1]][target_col]\n",
    "        altered_fold_df.loc[tfold[i][1],target_col] = old_tgt\n",
    "        #ra,rt = reset_years(paired_dates[i],in_fold_idx,dates_df)\n",
    "        \"\"\"adj_df =reset_years2(paired_dates[i],in_fold_idx,df)\n",
    "        #altered_fold_df.ix[in_fold_idx]['adj_age']=ra\n",
    "        #altered_fold_df.ix[in_fold_idx]['adj_tenure']=rt\n",
    "        altered_fold_df.loc[in_fold_idx,time_cols]=adj_df.ix[in_fold_idx] # assign to the altered values\n",
    "        \n",
    "        #(em2mod.ix[kf[0][0]]['term_tstmp']<= fp[0][1]).as_matrix().astype(np.int)\n",
    "        \n",
    "        #print \"\\t\", len(new_term),sum(new_term)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        df_dict[i]=altered_fold_df\n",
    "    # now append this to a larger panel\n",
    "    tfold_panel = pd.Panel.from_dict(data =df_dict)\n",
    "    return tfold_panel\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_tKfold_CV2(modeltype, in_panel, tkfolds, cols_to_use, tgt_column = 'former', ntrees=100):\n",
    "    \"\"\" Calculate the rmse for each cross-validated temporalFold\n",
    "    \n",
    "    Parameters:\n",
    "        model - a scikit learn model name\n",
    "        in_panel  - a pandas Panel with the observed input data adjusted \n",
    "        tgt_column -- the target variable\n",
    "        cols_to_use -- the input variables to be used in modeling\n",
    "        tkfolds -- teh temporal timefolds (list of dimension 2)\n",
    "    outputs:\n",
    "        models --> the list of fit models\n",
    "        RMSE --> the rmse error\n",
    "        \n",
    "    \"\"\"\n",
    "    RMSE = []\n",
    "    roc_auc = []\n",
    "    models = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for fold_id, indices in enumerate(tkfolds):\n",
    "        training = indices[0]\n",
    "        testing = indices[1]\n",
    "        #print fold_id, len(training),len(testing)\n",
    "        X_train, X_test = in_panel[fold_id][cols_to_use].ix[training].as_matrix(), in_panel[fold_id][cols_to_use].ix[testing].as_matrix()\n",
    "        y_train, y_test = in_panel[fold_id][tgt_column].ix[training].as_matrix(), in_panel[fold_id][tgt_column].ix[testing].as_matrix()\n",
    "        if modeltype == 'rfc':\n",
    "            model = ensemble.RandomForestClassifier(n_estimators=ntrees, max_features='auto', oob_score=True)\n",
    "        elif modeltype=='bgc':\n",
    "            model=ensemble.GradientBoostingClassifier(n_estimators=ntrees,max_features='auto')\n",
    "        else:\n",
    "            model=tree.DecisionTreeClassifier()\n",
    "            \n",
    "        # Train the model\n",
    "        model.fit(X_train,y_train)\n",
    "        # use the model to predict output\n",
    "        y_fitted = model.predict(X_test)\n",
    "        RMSE.append(np.sqrt(metrics.mean_squared_error(y_test,y_fitted)))\n",
    "        roc_auc.append(metrics.roc_auc_score(y_test,y_fitted))\n",
    "        models.append(model)\n",
    "    # leave the model fit to the entire dataset\n",
    "    #model.fit(in_x,in_y)\n",
    "    \n",
    "    return RMSE,roc_auc,models\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_if_subset(list1,list2): #compare_column_lists(list1,list2):\n",
    "    if set(list1).issubset(set(list2)):\n",
    "        return 1\n",
    "    else:\n",
    "        print \"{0} is not contained in {1}. Recheck your lists.\".format(list1,list2)\n",
    "        return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reintroduce the tstmp columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build[tstmp_cols]=em2build[tstmp_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel4, tfold4 = setup_tfolds(build, 4, columns_for_modeling2, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols=tstmp_cols, date_range=full_date_range)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Now transform this panel into an h2o Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(panel4), len(tfold4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one off \n",
    "* for each mdl in len(panel4):\n",
    "    * train = panel4[mdl].ix[tfold4[mdl][0]]\n",
    "    * test = panel4[mdl].ix[tfold4[mdl][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_train_df = panel4[0].ix[tfold4[0][0]]\n",
    "my_test_df =  panel4[0].ix[tfold4[0][1]]\n",
    "#train4_0 = h2o.H2OFrame(panel4[0][columns_for_modeling2].ix[tfold4[0][0]])\n",
    "#y4_0 = h2o.H2OFrame(python_obj=panel4[0]['former'].ix[tfold4[0][0]])\n",
    "my_train_df.shape, my_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_train_df[].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o_cols = my_train_df.columns.tolist()\n",
    "h2o_cols.remove('fold_mbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir tmp\n",
    "os.chdir('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_train_df[h2o_cols].to_csv('my_train.csv',index=False)\n",
    "my_test_df[h2o_cols].to_csv('my_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dictionary does not preserve the colum order/data\n",
    "#train4_0 = h2o.H2OFrame(python_obj = my_train_df[h2o_cols].to_dict())\n",
    "#test4_0 = h2o.H2OFrame(python_obj = my_test_df[h2o_cols].to_dict())\n",
    "train4_0 = h2o.H2OFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -put *.csv /user/kesj/ajH2O_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train4_0 = h2o.import_file(path = 'hdfs://nameservice1/user/kesj/ajH2O_3/my_train.csv')\n",
    "test4_0 = h2o.import_file(path = 'hdfs://nameservice1/user/kesj/ajH2O_3/my_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o_gbm_mdl_0 = h2o.gbm(y = \"former\", x = columns_for_modeling2, training_frame = train4_0, validation_frame = test4_0, ntrees = 500 , max_depth = 4, learn_rate=0.1,distribution=\"AUTO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o_gbm_mdl_0.deepfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_0_vi = pd.DataFrame(data =h2o_gbm_mdl_0.varimp(return_list=True),columns=['variable','relative_importance','scaled_importance','percentage'])\n",
    "gbm_0_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_0_vi.percentage.cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict on the hold out set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_tstmps = ['birth_tstmp','hire_tstmp','term_tstmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adjust_eval_by_x_years(df,year_val,modeling_columns,tstmp_cols=default_tstmps,target_col='former'):\n",
    "    # construct\n",
    "  \n",
    "    ## set up method to assess the eval set\n",
    "    print \"There are {0} elements in the evaluation set\".format(len(df))\n",
    "   \n",
    "    print \"original target variable value counts:\", df[target_col].value_counts()\n",
    "    # restructure to deal with time_frame retirement (target variable)\n",
    "    yr_cut_val = year_val+0.5\n",
    "    # index of those that actually accomplish target within timeframe (allow 0.5 additional years)\n",
    "    eval_within_time_target_index = df[(df[target_col]==1) & (df.Tenure_years <= yr_cut_val)].index\n",
    "    # exclude indices that are active and have tenure less than this time\n",
    "    eval_excluded_index = df[(df[target_col]==0) & (df.Tenure_years  <= yr_cut_val)].index\n",
    "    \n",
    "    # the rest become my not-terminated set\n",
    "    eval_active_index = set(df.index) - set(eval_within_time_target_index) - set(eval_excluded_index)\n",
    "    print len(eval_excluded_index),len(eval_within_time_target_index), len(eval_active_index)\n",
    "    eval_idx_to_use =df.ix[set(df.index)-set(eval_excluded_index)].index\n",
    "    #len(eval_idx_to_use)\n",
    "    # reset the target to 0 for active\n",
    "    eval_new_target = df[target_col].copy()\n",
    "    eval_new_target.ix[eval_active_index] = 0\n",
    "    print \"new target variable value counts: \"\n",
    "    print eval_new_target.ix[eval_idx_to_use].value_counts()\n",
    "    print \"_____\"\n",
    "    y_eval = eval_new_target.ix[eval_idx_to_use].as_matrix().astype(np.int) # true values\n",
    "    eval_adj_tenure = df.ix[eval_idx_to_use].Tenure_years.apply(lambda x: x-year_val if (x>float(year_val)) else 0).values\n",
    "    print len(eval_adj_tenure), len(y_eval)\n",
    "    # now adjust age by length of time; use hire_age if not in set to use.\n",
    "    eval_adj_age = df.ix[eval_idx_to_use].Age_years.apply(lambda x: x-year_val)\n",
    "    hire_age = (df.ix[eval_within_time_target_index]['birth_tstmp']-df.ix[eval_within_time_target_index]['hire_tstmp'])/np.timedelta64(1,'Y')#.days/days_in_year\n",
    "    eval_adj_age.ix[eval_within_time_target_index] = hire_age #df.ix[eval_within_time_target_index]['birth_tstmp'#df_dates['hire_age']\n",
    "    \n",
    "    # construct the evaluation X matrix\n",
    "    print \"input matrix has {0} features\".format(len(modeling_columns))\n",
    "    Xeval = np.zeros((len(eval_idx_to_use),len(modeling_columns)))\n",
    "    # drop 'Age_years' and Tenure_years from the list\n",
    "    cols_to_use = []\n",
    "    cols_to_use+=modeling_columns\n",
    "    cols_to_use.remove('Age_years')\n",
    "    cols_to_use.remove('Tenure_years')#.copy()\n",
    "    \"\"\"\n",
    "    Xeval[:,:-2] = df.ix[eval_idx_to_use][cols_to_use].as_matrix().astype(np.float)\n",
    "    # now put the adjusted tenure and ages into this matrix\n",
    "    Xeval[:,-2] = eval_adj_age.values\n",
    "    Xeval[:,-1]=eval_adj_tenure\n",
    "    #print len(modeling_columns),np.shape(Xeval)\n",
    "    \"\"\"\n",
    "    # this version matches the changed ording of columns\n",
    "    Xeval[:,0]=eval_adj_age.values\n",
    "    Xeval[:,1]=eval_adj_tenure\n",
    "    Xeval[:,2:] = df.ix[eval_idx_to_use][cols_to_use].as_matrix().astype(np.float)\n",
    "    return Xeval, y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluation[tstmp_cols]=em2eval[tstmp_cols] # append the tstmp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4eval, y4eval =adjust_eval_by_x_years(evaluation,4,columns_for_modeling2)#,tstmp_cols=default_tstmps,target_col='former')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_dict = {}\n",
    "for idx,feature in enumerate(columns_for_modeling2):\n",
    "    print idx, feature\n",
    "    eval_dict[feature]=list(X4eval[:,idx])\n",
    "    \n",
    "eval_dict['former']=list(y4eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval4_frame = h2o.H2OFrame(python_obj=eval_dict)\n",
    "\n",
    "#h2o_gbm_mdl_0.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval4_frame.as_data_frame().to_csv('eval_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "['former' in eval4_frame.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred4_0 = h2o_gbm_mdl_0.predict(eval4_frame).as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred4_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(pred4_0.predict.values,y4eval,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred4_0.predict.apply(lambda x: np.int(x+0.6)).sum(), sum(y4eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.vstack([pred4_0.predict.values, pred4_0.predict.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y4eval,np.vstack([pred4_0.predict.values, pred4_0.predict.values]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o.save_model(h2o_gbm_mdl_0,path='hdfs://nameservice1/user/kesj/ajH2O_3/p4_0/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let me retry with an actual ENUM for the predictor/response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train4_0['former'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train4_0['former'] =train4_0['former'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o_gbm_mdl_b0 = h2o.gbm(y = \"former\", x = columns_for_modeling2, training_frame = train4_0, validation_frame = test4_0, ntrees = 500 , max_depth = 4, learn_rate=0.1,distribution=\"bernoulli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#h2o_gbm_mdl_b0\n",
    "pred4_b0 = h2o_gbm_mdl_b0.predict(eval4_frame).as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pred4_b0.predict.sum()\n",
    "pred4_b0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o.save_model(h2o_gbm_mdl_b0,path='hdfs://nameservice1/user/kesj/ajH2O_3/p4_b0/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def plot_conf_matrix(y_true,y_pred,normed=True,**kwargs):\n",
    "    my_c = metrics.confusion_matrix(y_true,y_pred)\n",
    "    \n",
    "    print metrics.matthews_corrcoef(y_true,y_pred)\n",
    "    if normed:\n",
    "        cm_normalized = my_c.astype('float') / my_c.sum(axis=1)[:, np.newaxis]\n",
    "        my_c = cm_normalized\n",
    "        plt.title('Normalized RF Classifier Confusion Matrix')\n",
    "    else:\n",
    "        plt.title('Random Forest Classifier Confusion Matrix')\n",
    "        \n",
    "    sns.heatmap(my_c, annot=True,  fmt='',cmap='Blues')\n",
    "    plt.ylabel('True')\n",
    "    #plt.yticks\n",
    "    plt.xlabel('Assigned')\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_roc_curve(target_test, target_predicted_proba):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "    \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y4eval,pred4_b0.predict.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(target_test, target_predicted_proba):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "    \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_pred = pred4_b0['p0'].copy()\n",
    "tmp_pred.ix[pred4_b0[pred4_b0.predict==0].index] = pred4_b0.ix[pred4_b0[pred4_b0.predict==0].index]['p1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred4_b0[pred4_b0.predict==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(pred4_b0.p0.values,tmp_pred.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tmp_pred.values\n",
    "plot_roc_curve(y4eval,np.vstack([1-tmp_pred.values, tmp_pred.values]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y4eval, pred4_b0[['p0','p1']].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y4eval, pred4_b0[['p0','p1']].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o_gbm_mdl_b0.varimp(return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eport the POJO to a local directory space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dest_dir = '/home/kesj/work/hrsepara/proc/h2o/gbm_4yr_sep_b0/'\n",
    "os.chdir(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!curl http://sfda74wbdn03.opr.statefarm.org:54321/3/h2o-genmodel.jar > h2o-genmodel.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!curl http://sfda74wbdn03.opr.statefarm.org:54321/3/Models.java/GBM_model_python_1444141461056_19 > GBM_model_python_1444141461056_19.java\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!javac -cp h2o-genmodel.jar -J-Xmx2g -J-XX:MaxPermSize=128m GBM_model_python_1444141461056_19.java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write a function to apply this each fold in a panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse4,roc_auc4,gbc_mdl4 = apply_tKfold_CV2('gbc',panel4, tfold4,  cols_to_use = columns_for_modeling3, tgt_column='former',ntrees=500)#['columns_for_modeling'],em2mod['former'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#h2o.H2ODisplay(python_obj= list(\n",
    "panel4[0].ix[tfold4[0][0]].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP HERE 10/01/2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"For retirement:\"\n",
    "print \"training set:\\t\",\n",
    "print em2.retired.value_counts()/len(em2)\n",
    "print \"evaluation set:\\t\",\n",
    "print em2eval.retired.value_counts()/len(em2eval)\n",
    "print \"For Separation\"\n",
    "print \"training set:\\t\",\n",
    "print em2.former.value_counts()/len(em2)\n",
    "print \"evaluation set:\\t\",\n",
    "print em2eval.former.value_counts()/len(em2eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE a Test-train split from this dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_indices = list(range(em2002.KEY.nunique()))\n",
    "print len(list_of_indices )\n",
    "random.seed(823321)\n",
    "#new_indices = [x for x in random.shuffle(list_of_indices)\n",
    "random.shuffle(list_of_indices)#, len(list_of_indices))\n",
    "em2002.index = list_of_indices # note that random.shuffle does this shuffling inplace\n",
    "em2002.sort_index(inplace=True)\n",
    "em2002.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what are the columns included?\n",
    "* examine building a model/models with minimal_input_col_list:\n",
    "    - minimal_input_col_list = ['KEY','HIRE_DT','BIRTHDATE','SAL1','HAVE_INS','HAVE_DEP','EMPL_TYPE','SEX', 'MAX_RT_ANNUAL','MIN_RT_ANNUAL','PERF1','MERIT1','BOX1','INTERN','HUBIND']\n",
    "* calculate Age_years & Tenure_years for each --> FeatureUnion\n",
    "\n",
    "## October -- making this bigger\n",
    "* go back to version 1.1 to see if I can construct the pipeline again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now deal with the columns used for modeling here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " = ['Age_years','Tenure_years','SAL1','MERIT1','PERF1','BOX1','SEX','HAVE_INS','HAVE_DEP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# repeat the split\n",
    "# break into evaluation and build sets\n",
    "print \"Starting with subest of {0} employees.\".format(len(em2002))\n",
    "eval_fraction = 0.20\n",
    "em2, em2eval = cross_validation.train_test_split(em2002,test_size=eval_fraction)\n",
    "print \"Evaluation set has {0} employees; training set has {1} employees.\".format(len(em2eval),len(em2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em2_tgt_retired = em2.retired\n",
    "em2_tgt_former = em2.former\n",
    "eval_tgt_retired = em2eval.retired\n",
    "eval_tgt_former = em2eval.former"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in an __ad hoc__ way convert these columns based upon our previous 'rules'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_required_cols = ['hire_tstmp','term_tstmp','birth_tstmp','former','retired']\n",
    "cols_for_model_prep = []\n",
    "cols_for_model_prep+=other_required_cols\n",
    "cols_for_model_prep+=columns_for_modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace the Y with 1 and N with 0, M with 1 and F with 0\n",
    "def apply_preprocess_small(df,cols_to_use =[]):\n",
    "    empl=df[cols_to_use].copy()\n",
    "    #all_cols = empl.columns.tolist()\n",
    "    empl['SEX'].replace({'M':1,'F':0},inplace=True)\n",
    "    empl[['HAVE_INS','HAVE_DEP']]=empl[['HAVE_INS','HAVE_DEP']].replace({'Y':1,'N':0}).copy()\n",
    "    empl['BOX1']=empl['BOX1'].replace({'H':3,'S':2,'L':1}).copy()\n",
    "    \n",
    "    # now deal with ints\n",
    "    \n",
    "    # fix the dollar amounts\n",
    "    min_sal1 = 17621.76 #(based upon training set I have: 5 %tile cut off)\n",
    "    min_min_rt_ann = 17900. # same as above\n",
    "    min_max_rt_ann = 33155.70\n",
    "\n",
    "    max_max_rt_ann = 133068.91\n",
    "    min_merit1 = 0.0\n",
    "    min_perf1 = 0.0\n",
    "    fix_min_outlier_col_dict = {'SAL1': min_sal1, 'MERIT1': min_merit1, 'PERF1': min_perf1}\n",
    "    fix_max_outlier_col_dict = {'MAX_RT_ANNUAL': max_max_rt_ann}\n",
    "\n",
    "    # replae these values\n",
    "    for key,value in fix_min_outlier_col_dict.iteritems():\n",
    "        idx_to_replace = empl[empl[key]<value].index\n",
    "        empl.loc[idx_to_replace,key]=value\n",
    "    \n",
    "    # now fill in missing with zero\n",
    "    empl.fillna(0,inplace=True)\n",
    "        \n",
    "        \n",
    "    return empl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2[cols_for_model_prep].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## so I want to use columns_for_modeling:\n",
    "['Age_years',\n",
    " 'Tenure_years',\n",
    " 'SAL1',\n",
    " 'MERIT1',\n",
    " 'PERF1',\n",
    " 'BOX1',\n",
    " 'SEX',\n",
    " 'HAVE_INS',\n",
    " 'HAVE_DEP']\n",
    "for my model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf,fp = create_temporal_kfolds(em2mod,full_date_range,5)\n",
    "len(kf),len(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(kf[0][0]), len(kf[0][1]), fp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "start_date = fp[i][0]\n",
    "end_date = fp[i][1]\n",
    "in_fold_idx=kf[i][0]\n",
    "target_col= 'former'\n",
    "cols_to_copy = ['SEX','Age_years','Tenure_years']\n",
    "cols_to_copy.append(target_col)\n",
    "cols_to_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "altered_fold_df = em2mod[cols_to_copy].copy()\n",
    "        # adjust these\n",
    "altered_fold_df.columns=['fold_mbr','adj_age','adj_tenure','adj_tgt']\n",
    "altered_fold_df.fold_mbr = 0\n",
    "adj_df =reset_years2(fp[i],in_fold_idx,em2mod)\n",
    "altered_fold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "altered_fold_df.loc[in_fold_idx,['adj_age','adj_tenure']]= adj_df.ix[in_fold_idx]\n",
    "altered_fold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mypanel5 = define_target_within_x_years(em2mod,fp,kf,5,'former')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mypanel5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mypanel5[0].ix[kf[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_for_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print columns_for_modeling[2:]\n",
    "X5fold = np.zeros((len(em2mod),len(columns_for_modeling),len(kf)))\n",
    "y5fold = []\n",
    "for i in xrange(0,len(kf)):\n",
    "    X5fold[:,:-2,i]=em2mod[columns_for_modeling[2:]].as_matrix().astype(np.float)\n",
    "    X5fold[:,-2:,i]=mypanel5[i][['adj_age','adj_tenure']]\n",
    "    my_y=mypanel5[i][['adj_tgt']].as_matrix().astype(np.int)\n",
    "    y5fold.append(my_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evalmod = apply_preprocess_small(em2eval,cols_for_model_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## now apply each model to my eval set\n",
    "def evaluate_models(model_list,Xeval):\n",
    "    eval_pred_class = np.zeros((len(Xeval),len(model_list)))\n",
    "    eval_pred_proba = np.zeros((len(Xeval),2,len(model_list)))\n",
    "\n",
    "    for i,mdl in enumerate(model_list):\n",
    "        eval_proba = mdl.predict_proba(Xeval)\n",
    "        eval_pred_class[:,i]=mdl.predict(Xeval)\n",
    "        eval_pred_proba[:,:,i]=eval_proba\n",
    "    #print np.shape(eval_prediction_proba3)\n",
    "    return eval_pred_class, eval_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reworking this\n",
    "1. preprocess the test data \n",
    "    0. transform all to numbers and fill in missing (```apply_preprocess_small```)\n",
    "    1. define the time_range\n",
    "    2. define the time fields (both timestamps and temporally dependent columns)\n",
    "        1. default_tstmps\n",
    "        2. _years columns: Age_years & Tenure_years\n",
    "    3. define the columns to use (for modeling)\n",
    "2. setup_tfold_models\n",
    "    * create_temporal_kfolds\n",
    "    * define_target_within_x_years\n",
    "    * \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contrary_case = []\n",
    "contrary_case += default_tstmps \n",
    "contrary_case.append('jobchg_tstmp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if [a for a in default_tstmps if a in em2mod.columns] == default_tstmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not [a for a in contrary_case if a in em2mod.columns] == contrary_case:\n",
    "    print \"some columns in contrary_case are missing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pan1 = transform_df_to_tfold(em2mod,kf,fp,5,columns_for_modeling,'former',default_tstmps,['Age_years','Tenure_years'])\n",
    "                      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pan1.items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[sum(pan1[a].former.isnull()) for a in xrange(0,len(pan1.items.tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pan1[8].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pan1[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(pan1[0].former.isnull()), len(kf[0][1]), len(kf[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10/01/15\n",
    "try gradient boosted classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble, tree, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse5,roc_auc5,rfmdl5 = apply_tKfold_CV2('gbc',pan1, kf,  cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopped here for LABOR DAY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel4, tfold4 = setup_tfolds(em2mod, 4, columns_for_modeling, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for training, testing in tfold4: #len(tfold4[0][1]), len(tfold4[0][0])\n",
    "    print len(training),len(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build a method/function to apply a model to the temporal_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#metrics.mean_squared_error\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_tKfold_CV(model, in_panel, tkfolds, cols_to_use, tgt_column = 'former' ):\n",
    "    \"\"\" Calculate the rmse for each cross-validated temporalFold\n",
    "    \n",
    "    Parameters:\n",
    "        model - a scikit learn model\n",
    "        in_panel  - a pandas Panel with the observed input data adjusted \n",
    "        in_y - a pandas Series with the observed outcome\n",
    "        k - number of cross validation folds (test set will be 1/k of the data)\n",
    "    \"\"\"\n",
    "    RMSE = []\n",
    "    for fold_id, indices in enumerate(tkfolds):\n",
    "        training = indices[0]\n",
    "        testing = indices[1]\n",
    "        print fold_id, len(training),len(testing)\n",
    "        X_train, X_test = in_panel[fold_id][cols_to_use].ix[training].as_matrix(), in_panel[fold_id][cols_to_use].ix[testing].as_matrix()\n",
    "        y_train, y_test = in_panel[fold_id][tgt_column].ix[training].as_matrix(), in_panel[fold_id][tgt_column].ix[testing].as_matrix()\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train,y_train)\n",
    "        # use the model to predict output\n",
    "        y_fitted = model.predict(X_test)\n",
    "        RMSE.append(np.sqrt(metrics.mean_squared_error(y_test,y_fitted)))\n",
    "    # leave the model fit to the entire dataset\n",
    "    #model.fit(in_x,in_y)\n",
    "    \n",
    "    return RMSE\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_tKfold_CV2(modeltype, in_panel, tkfolds, cols_to_use, tgt_column = 'former', ntrees=100):\n",
    "    \"\"\" Calculate the rmse for each cross-validated temporalFold\n",
    "    \n",
    "    Parameters:\n",
    "        model - a scikit learn model name\n",
    "        in_panel  - a pandas Panel with the observed input data adjusted \n",
    "        tgt_column -- the target variable\n",
    "        cols_to_use -- the input variables to be used in modeling\n",
    "        tkfolds -- teh temporal timefolds (list of dimension 2)\n",
    "    outputs:\n",
    "        models --> the list of fit models\n",
    "        RMSE --> the rmse error\n",
    "        \n",
    "    \"\"\"\n",
    "    RMSE = []\n",
    "    roc_auc = []\n",
    "    models = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for fold_id, indices in enumerate(tkfolds):\n",
    "        training = indices[0]\n",
    "        testing = indices[1]\n",
    "        #print fold_id, len(training),len(testing)\n",
    "        X_train, X_test = in_panel[fold_id][cols_to_use].ix[training].as_matrix(), in_panel[fold_id][cols_to_use].ix[testing].as_matrix()\n",
    "        y_train, y_test = in_panel[fold_id][tgt_column].ix[training].as_matrix(), in_panel[fold_id][tgt_column].ix[testing].as_matrix()\n",
    "        if modeltype == 'rfc':\n",
    "            model = ensemble.RandomForestClassifier(n_estimators=ntrees, max_features='auto', oob_score=True)\n",
    "        elif modeltype=='bgc':\n",
    "            model=ensemble.GradientBoostingClassifier(n_estimators=ntrees,max_features='auto')\n",
    "        else:\n",
    "            model=tree.DecisionTreeClassifier()\n",
    "            \n",
    "        # Train the model\n",
    "        model.fit(X_train,y_train)\n",
    "        # use the model to predict output\n",
    "        y_fitted = model.predict(X_test)\n",
    "        RMSE.append(np.sqrt(metrics.mean_squared_error(y_test,y_fitted)))\n",
    "        roc_auc.append(metrics.roc_auc_score(y_test,y_fitted))\n",
    "        models.append(model)\n",
    "    # leave the model fit to the entire dataset\n",
    "    #model.fit(in_x,in_y)\n",
    "    \n",
    "    return RMSE,roc_auc,models\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now setup protocol for generating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random_forest = ensemble.RandomForestClassifier(n_estimators=100, max_features='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse4,roc_auc4,rfmdl4 = apply_tKfold_CV2('rfc',panel4, tfold4, cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in xrange(0,len(panel4)):\n",
    "    print a, panel4[a][panel4[a].former==1].former.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply to the hold-out (EVAL) set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(roc_auc4).boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(a,rfmdl4[a].oob_score_) for a in xrange(0,len(rfmdl4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list= pan1[0].columns\n",
    "feature_list = columns_for_modeling\n",
    "feature_list\n",
    "fi_5df = create_fi_df(rfmdl5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_4df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fval_cols = [a for a in fi_4df.columns if 'value' in a]\n",
    "fi_4df[fval_cols].T.boxplot()\n",
    "plt.title('Feature Importances for 4year former')\n",
    "plt.ylabel('Feature Importances in Tfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4eval, y4eval = adjust_eval_by_x_years(evalmod,4,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4evalb, y4evalb = adjust_eval_by_x_years(evalmod,4,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beval_pred4class, beval_pred4proba = evaluate_models(rfmdl4,X4evalb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y4eval,map(eval_pred4class.mean(),np.int))\n",
    "plot_roc_curve(y4evalb,beval_pred4proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beval_pred4class.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beval_pred4class.min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y4evalb,map(np.int,beval_pred4class.mean(axis=1)+0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y4eval,map(eval_pred4class.mean(),np.int))\n",
    "plot_roc_curve(y4eval,eval_pred4proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y4eval,map(np.int,eval_pred4class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalmod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y5eval),len(evalmod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(evalmod[evalmod.Tenure_years <=5.0+.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel5[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X5eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalmod.former.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y5eval.sum()\n",
    "y5eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X5eval, y5eval = adjust_eval_by_x_years(evalmod,5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## try for 5year\n",
    "panel5, tfold5 = setup_tfolds(em2mod, 5, columns_for_modeling, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "rmse5,roc_auc5,rfmdl5 = apply_tKfold_CV2('gbc',panel5, tfold5, cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)\n",
    "X5eval, y5eval = adjust_eval_by_x_years(evalmod,5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Repeat for more trees\n",
    "rmse5b,roc_auc5b,rfmdl5b = apply_tKfold_CV2('gbc',panel5, tfold5, cols_to_use = columns_for_modeling, tgt_column='former',ntrees=500)#['columns_for_modeling'],em2mod['former'],)\n",
    "X5evalb,y5evalb = adjust_eval_by_x_years(evalmod,5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_scores5b = pd.DataFrame()\n",
    "cv_scores5b['rmse'] = rmse5b#pd.DataFrame(rmse5)#.boxplot()\n",
    "cv_scores5b['roc_auc']=roc_auc5b\n",
    "#pd.DataFrame(roc_auc5).boxplot()\n",
    "cv_scores5b.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_scores5 = pd.DataFrame()\n",
    "cv_scores5['rmse'] = rmse5#pd.DataFrame(rmse5)#.boxplot()\n",
    "cv_scores5['roc_auc']=roc_auc5\n",
    "#pd.DataFrame(roc_auc5).boxplot()\n",
    "cv_scores5.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse5, rmse5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ev5df = pd.DataFrame()\n",
    "ev5df['avg'] = eval_pred5class.mean(axis=1)\n",
    "#ev5df.head()\n",
    "ev5df['min'] = eval_pred5class.min(axis=1)\n",
    "ev5df['max']= eval_pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred5class, eval_pred5proba = evaluate_models(rfmdl5,X5eval)\n",
    "plot_conf_matrix(y5eval,map(np.int,eval_pred5class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y5eval,eval_pred5proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred5classb, eval_pred5probab = evaluate_models(rfmdl5b,X5eval)\n",
    "plot_conf_matrix(y5eval,map(np.int,eval_pred5classb.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(map(np.int,eval_pred5classb.mean(axis=1))), len(eval_pred5classb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y5eval,eval_pred5probab[:,:,:].mean(axis=2))\n",
    "plot_roc_curve(y5eval,eval_pred5proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_5df = create_fi_df(rfmdl5,columns_for_modeling)\n",
    "val_cols = [a for a in fi_5df.columns if 'value' in a]\n",
    "fi_5df[val_cols].T.boxplot()\n",
    "plt.title('Feature Importances for 5year former')\n",
    "plt.ylabel('Feature Importances in Tfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir 'gbc_5sep_pkl'\n",
    "%cd '/home/kesj/work/hrsepara/eda/gbc_5sep_pkl/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rfmdl5,open('gbc5.pkl','wb'))\n",
    "#len(flist_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try loading the previously pickled models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd '/home/kesj/work/hrsepara/eda/jl_5yr_100auto/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stored_mdl = jl.load('frf100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Seval_pred5class,Seval_pred5proba = evaluate_models(stored_mdl,X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y5eval,Seval_pred5proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat for 3 years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel3, tfold3 = setup_tfolds(em2mod, 3, columns_for_modeling, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "rmse3,roc_auc3,rfmdl3 = apply_tKfold_CV2('gbc',panel3, tfold3, cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)\n",
    "X3eval, y3eval = adjust_eval_by_x_years(evalmod,3,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred3class, eval_pred3proba = evaluate_models(rfmdl3,X3eval)\n",
    "plot_conf_matrix(y3eval,map(np.int,eval_pred3class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y3eval,eval_pred3proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(eval_pred3proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(0,len(panel3)):\n",
    "    #fpr,tpr,treshholds = roc_\n",
    "    plot_roc_curve(y3eval,eval_pred3proba[:,:,i])\n",
    "plot_roc_curve(y3eval,eval_pred3proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y3eval,eval_pred3proba[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel2, tfold2 = setup_tfolds(em2mod, 2, columns_for_modeling, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "rmse2,roc_auc2,rfmdl2 = apply_tKfold_CV2('rfc',panel2, tfold2, cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)\n",
    "X2eval, y2eval = adjust_eval_by_x_years(evalmod,2,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred2class, eval_pred2proba = evaluate_models(rfmdl2,X2eval)\n",
    "plot_conf_matrix(y2eval,map(np.int,eval_pred2class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel1, tfold1 = setup_tfolds(em2mod, 1, columns_for_modeling, tgt_value = 'former',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "rmse1,roc_auc1,rfmdl1 = apply_tKfold_CV2('rfc',panel1, tfold1, cols_to_use = columns_for_modeling, tgt_column='former')#['columns_for_modeling'],em2mod['former'],)\n",
    "X1eval, y1eval = adjust_eval_by_x_years(evalmod,1,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred1class, eval_pred1proba = evaluate_models(rfmdl1,X1eval)\n",
    "plot_conf_matrix(y1eval,map(np.int,eval_pred1class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(0,len(panel1)):\n",
    "    #fpr,tpr,treshholds = roc_\n",
    "    plot_roc_curve(y1eval,eval_pred1proba[:,:,i])\n",
    "plot_roc_curve(y1eval,eval_pred1proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel2[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try for 'retired'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "today = pd.to_datetime('2015-01-01')\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "evalmod[(evalmod['retired']==1) & (today - evalmod['term_tstmp']<= 1.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adjust_eval_by_x_yearsR(df,year_val,modeling_columns,endtime,tstmp_cols=default_tstmps,target_col='retired'):\n",
    "    # construct\n",
    "  \n",
    "    ## set up method to assess the eval set\n",
    "    print \"There are {0} elements in the evaluation set\".format(len(df))\n",
    "   \n",
    "    print \"original target variable value counts:\", df[target_col].value_counts()\n",
    "    # restructure to deal with time_frame retirement (target variable)\n",
    "    yr_cut_val = year_val+0.5\n",
    "    # index of those that actually accomplish target within timeframe (allow 0.5 additional years)\n",
    "    eval_within_time_target_index = df[(df[target_col]==1) & (endtime - df['term_tstmp'] <= yr_cut_val)].index\n",
    "    # exclude indices that are active and have tenure less than this time\n",
    "    eval_excluded_index = df[(df[target_col]==0) & (df.Tenure_years  <= yr_cut_val)].index\n",
    "    \n",
    "    # the rest become my not-terminated set\n",
    "    eval_active_index = set(df.index) - set(eval_within_time_target_index) - set(eval_excluded_index)\n",
    "    print len(eval_excluded_index),len(eval_within_time_target_index), len(eval_active_index)\n",
    "    eval_idx_to_use =df.ix[set(df.index)-set(eval_excluded_index)].index\n",
    "    #len(eval_idx_to_use)\n",
    "    # reset the target to 0 for active\n",
    "    eval_new_target = df[target_col].copy()\n",
    "    eval_new_target.ix[eval_active_index] = 0\n",
    "    print \"new target variable value counts: \"\n",
    "    print eval_new_target.ix[eval_idx_to_use].value_counts()\n",
    "    print \"_____\"\n",
    "    y_eval = eval_new_target.ix[eval_idx_to_use].as_matrix().astype(np.int) # true values\n",
    "    eval_adj_tenure = df.ix[eval_idx_to_use].Tenure_years.apply(lambda x: x-year_val if (x>float(year_val)) else 0).values\n",
    "    print len(eval_adj_tenure), len(y_eval)\n",
    "    # now adjust age by length of time; use hire_age if not in set to use.\n",
    "    eval_adj_age = df.ix[eval_idx_to_use].Age_years.apply(lambda x: x-year_val)\n",
    "    hire_age = (df.ix[eval_within_time_target_index]['birth_tstmp']-df.ix[eval_within_time_target_index]['hire_tstmp'])/np.timedelta64(1,'Y')#.days/days_in_year\n",
    "    eval_adj_age.ix[eval_within_time_target_index] = hire_age #df.ix[eval_within_time_target_index]['birth_tstmp'#df_dates['hire_age']\n",
    "    \n",
    "    # construct the evaluation X matrix\n",
    "    print \"input matrix has {0} features\".format(len(modeling_columns))\n",
    "    Xeval = np.zeros((len(eval_idx_to_use),len(modeling_columns)))\n",
    "    # drop 'Age_years' and Tenure_years from the list\n",
    "    cols_to_use = []\n",
    "    cols_to_use+=modeling_columns\n",
    "    cols_to_use.remove('Age_years')\n",
    "    cols_to_use.remove('Tenure_years')#.copy()\n",
    "    \"\"\"\n",
    "    Xeval[:,:-2] = df.ix[eval_idx_to_use][cols_to_use].as_matrix().astype(np.float)\n",
    "    # now put the adjusted tenure and ages into this matrix\n",
    "    Xeval[:,-2] = eval_adj_age.values\n",
    "    Xeval[:,-1]=eval_adj_tenure\n",
    "    #print len(modeling_columns),np.shape(Xeval)\n",
    "    \"\"\"\n",
    "    # this version matches the changed ording of columns\n",
    "    Xeval[:,0]=eval_adj_age.values\n",
    "    Xeval[:,1]=eval_adj_tenure\n",
    "    Xeval[:,2:] = df.ix[eval_idx_to_use][cols_to_use].as_matrix().astype(np.float)\n",
    "    return Xeval, y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RX2eval, Ry2eval = adjust_eval_by_x_yearsR(evalmod,2,columns_for_modeling, today,target_col = 'retired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel2, Rtfold2 = setup_tfolds(em2mod, 2, columns_for_modeling, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "Rrmse2,Rroc_auc2,Rrfmdl2 = apply_tKfold_CV2('rfc',Rpanel2, Rtfold2, cols_to_use = columns_for_modeling, tgt_column='retired')#['columns_for_modeling'],em2mod['former'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Reval_pred2class,Reval_pred2proba = evaluate_models(Rrfmdl2,RX2eval)\n",
    "plot_roc_curve(Ry2eval,Reval_pred2proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel5, Rtfold5 = setup_tfolds(em2mod, 5, columns_for_modeling, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "Rrmse5,Rroc_auc5,Rrfmdl5 = apply_tKfold_CV2('rfc',Rpanel5, Rtfold5, cols_to_use = columns_for_modeling, tgt_column='retired')#['columns_for_modeling'],em2mod['former'],)\n",
    "RX5eval, Ry5eval = adjust_eval_by_x_yearsR(evalmod,5,columns_for_modeling, today,target_col = 'retired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Reval_pred5class,Reval_pred5proba = evaluate_models(Rrfmdl5,RX5eval)\n",
    "plot_roc_curve(Ry5eval,Reval_pred5proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel4, Rtfold4 = setup_tfolds(em2mod,4, columns_for_modeling, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "Rrmse4,Rroc_auc4,Rrfmdl4 = apply_tKfold_CV2('rfc',Rpanel4, Rtfold5, cols_to_use = columns_for_modeling, tgt_column='retired')#['columns_for_modeling'],em2mod['former'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RX4eval, Ry4eval = adjust_eval_by_x_yearsR(evalmod,4,columns_for_modeling, today,target_col = 'retired')\n",
    "Reval_pred4class,Reval_pred4proba = evaluate_models(Rrfmdl4,RX4eval)\n",
    "plot_roc_curve(Ry4eval,Reval_pred4proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel3, Rtfold3 = setup_tfolds(em2mod, 3, columns_for_modeling, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "Rrmse3,Rroc_auc3,Rrfmdl3 = apply_tKfold_CV2('rfc',Rpanel3, Rtfold3, cols_to_use = columns_for_modeling, tgt_column='retired')#['columns_for_modeling'],em2mod['former'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RX3eval, Ry3eval = adjust_eval_by_x_yearsR(evalmod,3,columns_for_modeling,today, target_col = 'retired')\n",
    "Reval_pred3class,Reval_pred3proba = evaluate_models(Rrfmdl3,RX3eval)\n",
    "plot_roc_curve(Ry3eval,Reval_pred3proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rpanel1, Rtfold1 = setup_tfolds(em2mod, 1, columns_for_modeling, tgt_value = 'retired',\n",
    "                 time_cols=['Age_years','Tenure_years'], tstmp_cols = default_tstmps, date_range=full_date_range)\n",
    "Rrmse1,Rroc_auc1,Rrfmdl1 = apply_tKfold_CV2('rfc',Rpanel5, Rtfold5, cols_to_use = columns_for_modeling, tgt_column='retired')#['columns_for_modeling'],em2mod['former'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalmod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RX1eval[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(evalmod[(evalmod['retired']==1) & (today - evalmod['term_tstmp'] <= 5.5*365.25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5.5*365.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum((today - evalmod['term_tstmp']) <= 5.5*365.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RX1eval, Ry1eval = adjust_eval_by_x_yearsR(evalmod,1,columns_for_modeling, today, target_col = 'retired')\n",
    "Reval_pred1class,Reval_pred1proba = evaluate_models(Rrfmdl1,RX1eval)\n",
    "plot_roc_curve(Ry1eval,Reval_pred1proba[:,:,:].mean(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir save_models_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd 'save_models_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sep\n",
    "!mkdir ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## define the base directories\n",
    "case_dir = ['sep/','ret/']\n",
    "## define the model cases\n",
    "nyrs = map(str,np.arange(1,6))\n",
    "base='rfmdl'\n",
    "model_listing = []\n",
    "pkl_file_dict = {}\n",
    "#dump_file_listing= []\n",
    "for case in case_dir:\n",
    "    #!cd {case_dir}\n",
    "    for yr in nyrs:\n",
    "        #dir_name = case+yr+'/'\n",
    "        #!mkdir {yr}\n",
    "        #!cd {yr}\n",
    "        model_name = base+yr\n",
    "        file_name = 'rf'\n",
    "        if case == 'ret/':\n",
    "            model_name = 'R'+model_name\n",
    "            file_name = 'R'+file_name\n",
    "        file_name+=yr\n",
    "        file_name+='.pkl'\n",
    "        \n",
    "        print dir_name, model_name, file_name\n",
    "        model_listing.append(model_name)\n",
    "        pkl_file_dict[model_name]=file_name\n",
    "        #file_list = jl.dump(model_name,file_name)\n",
    "        #dump_file_listing.append(file_list)\n",
    "        #!cd ../\n",
    "    #!cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store_dir = '/home/kesj/work/hrsepara/save_models_1/'\n",
    "dump_file_listing = []\n",
    "for mdl in model_listing:\n",
    "    if mdl.startswith('R'):\n",
    "        base_dir = store_dir + 'ret'\n",
    "        #!cd {base_dir}#/home/kesj/work/hrsepara/save_models_1/ret        \n",
    "    else:\n",
    "        base_dir = store_dir + 'sep'\n",
    "    \n",
    "    os.chdir(base_dir)#!cd {base_dir}\n",
    "    yr = mdl[-1]\n",
    "    #os.makedirs(yr)#!mkdir {yr}\n",
    "    #os.chdir(yr)#!cd {yr}\n",
    "    print yr,mdl\n",
    "    #file_list =jl.dump(mdl,pkl_file_dict[mdl])\n",
    "    #dump_file_listing.append(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/sep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.mkdir('1')\n",
    "os.chdir('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump_file_listing = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flist = jl.dump(rfmdl1,'rf1.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/sep')\n",
    "os.mkdir('2')\n",
    "os.chdir('2')\n",
    "flist = jl.dump(rfmdl2,'rf2.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/sep')\n",
    "os.mkdir('3')\n",
    "os.chdir('3')\n",
    "flist = jl.dump(rfmdl3,'rf3.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/sep')\n",
    "os.mkdir('4')\n",
    "os.chdir('4')\n",
    "flist = jl.dump(rfmdl4,'rf4.pkl')\n",
    "dump_file_listing.append(flist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/sep')\n",
    "os.mkdir('5')\n",
    "os.chdir('5')\n",
    "flist = jl.dump(rfmdl5,'rf5.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=5\n",
    "for yr in nyrs:\n",
    "    os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')\n",
    "    os.mkdir(yr)\n",
    "    os.chdir(yr)\n",
    "    flist = jl.dump(,'rf5.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.mkdir('1')\n",
    "os.chdir('1')\n",
    "flist = jl.dump(Rrfmdl1,'Rrf1.pkl')\n",
    "dump_file_listing.append(flist)\n",
    "\n",
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')\n",
    "os.mkdir('2')\n",
    "os.chdir('2')\n",
    "flist = jl.dump(Rrfmdl2,'Rrf2.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')\n",
    "os.mkdir('3')\n",
    "os.chdir('3')\n",
    "flist = jl.dump(Rrfmdl3,'Rrf3.pkl')\n",
    "dump_file_listing.append(flist)\n",
    "\n",
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')\n",
    "os.mkdir('4')\n",
    "os.chdir('4')\n",
    "flist = jl.dump(Rrfmdl4,'Rrf4.pkl')\n",
    "dump_file_listing.append(flist)\n",
    "\n",
    "os.chdir('/home/kesj/work/hrsepara/save_models_1/ret')\n",
    "os.mkdir('5')\n",
    "os.chdir('5')\n",
    "flist = jl.dump(Rrfmdl5,'Rrf5.pkl')\n",
    "dump_file_listing.append(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panel4[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside:\n",
    "* KFold within sklearn does the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_folds = cross_validation.KFold(n=len(em2mod),n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for std_tr,std_test in std_folds:\n",
    "    print len(std_tr), len(std_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now build t_fold models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tfold5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "five_rf_mdl_100A = []\n",
    "for i in xrange(0,len(kf)):\n",
    "    train_y = y5fold[i].flatten()[kf[i][0]]\n",
    "    train_X = X5fold[kf[i][0],:,i]\n",
    "    rfmdl = ensemble.RandomForestClassifier(n_estimators=100,max_features='auto',n_jobs=1)\n",
    "    rfmdl.fit(train_X,train_y)\n",
    "#baseline_singleRFC = ensemble.RandomForestClassifier(n_jobs=50,n_estimators=500,max_features=None)\n",
    "#baseline_singleRFC.fit(X,y_term)\n",
    "#baseline_singleRFC_importances= baseline_singleRFC.feature_importances_\n",
    "    five_rf_mdl_100A.append(rfmdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "five_rf_mdl_100A[0].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X5eval, y5eval = adjust_eval_by_x_years(evalmod,5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_pred5class,eval_pred5proba = evaluate_models(five_rf_mdl_100A,X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5eval,map(np.int,eval_pred5class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y3eval,eval_prediction_proba3[:,])\n",
    "plot_roc_curve(y5eval,eval_pred5proba[:,:,:].mean(axis=2))\n",
    "plt.ylim([0,1.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### function to help explore the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to push feature_importances for a set of RF models into a dataframe\n",
    "def create_fi_df(mdl_list,feature_names):\n",
    "    list_feature_importances = []\n",
    "    col_list = []\n",
    "    for i,mdl in enumerate(mdl_list):\n",
    "        list_feature_importances.append(plotFI(mdl,feature_names,show_plot=False))\n",
    "        col_list.append('fold'+str(i)+'_value')\n",
    "        col_list.append('fold'+str(i)+'_std')\n",
    "\n",
    "    fi_df = pd.concat(list_feature_importances,axis=1)\n",
    "    # create column headings\n",
    "    fi_df.columns = col_list\n",
    "    # create the average of the values\n",
    "    value_cols = [x for x in col_list if x.endswith('value')]\n",
    "    \n",
    "    fi_df['avg_val']=fi_df[value_cols].mean(axis=1)\n",
    "    fi_df['avg_variance']=fi_df[value_cols].std(axis=1)\n",
    "#t2_eval_fi_df[['avg_val','avg_std']].sort('avg_val',ascending=False)\n",
    "    return fi_df\n",
    "\n",
    "def plotFI(forest,featureNames=[],show_plot=True):#,autoscale=True,headroom=0.05):\n",
    "    \"\"\"\n",
    "    forest is the model to be graphed.\n",
    "    featureNames is the list of features to be displayed\n",
    "    \n",
    "    \"\"\"\n",
    "    #if autoscale:\n",
    "    #    x_scale = forest.feature_importances_.max()+ headroom\n",
    "    #else:\n",
    "    #    x_scale = 1\n",
    "    \n",
    "    featureImportances=forest.feature_importances_\n",
    "    # sort the importances from biggest to least\n",
    "    indices = np.argsort(featureImportances)[::-1]\n",
    "    estimators = forest.estimators_\n",
    "    # calculate the variance over the forest \n",
    "    \n",
    "    std = np.std([tree.feature_importances_ for tree in estimators],axis=0)\n",
    "    # print summary statement\n",
    "    nfeatures = len(featureImportances)\n",
    "    print(\"Number of Features: %d\" % (nfeatures))\n",
    "    print(\"Number of Trees: %d\" %(len(estimators)))\n",
    "    \n",
    "    #print featureNames\n",
    "    if len(featureNames)==0:\n",
    "        featureNames = map(str,indices)\n",
    "    \n",
    "    fN2 = [featureNames[a] for a in indices]\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(len(indices)):\n",
    "        print(\"%d. feature %d=%s (%f)\" % (f + 1, indices[f], featureNames[indices[f]],featureImportances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    # define a cutoff in terms of feature_importance\n",
    "    if nfeatures <= 30:\n",
    "        kfeatures = nfeatures # keep all if smaller than 30\n",
    "    else:\n",
    "        kfeatures = 30\n",
    "        \n",
    "    kindices = indices[:kfeatures]\n",
    "    if show_plot:\n",
    "        plt.title(\"Feature importances\")\n",
    "        plt.barh(range(len(kindices)), featureImportances[kindices],\n",
    "           color=\"steelblue\", xerr=std[kindices], align=\"center\",ecolor='k')#,lw=2)\n",
    "    \n",
    "        plt.yticks(range(len(kindices)),fN2)\n",
    "        #grid(True)\n",
    "    \n",
    "    c1 = 'value'\n",
    "    c2 = 'std'\n",
    "    tdata = np.vstack([featureImportances[indices],std[indices]])\n",
    "    df = pd.DataFrame(data = tdata.T,index=fN2,columns=[c1,c2])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list = [a for a in columns_for_modeling if 'years' not in a]\n",
    "feature_list += columns_for_modeling[:2]\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[e for e in tree0.estimators_]\n",
    "np.shape(tree0.indices_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_5df = create_fi_df(five_rf_mdl_100A,feature_list)\n",
    "#tree0 = rfmdl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_5df.plot(kind='bar',y='avg_val')#,std='avg_var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi_5df.plot(kind='bar',y='avg_variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##save this model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd '/home/kesj/work/hrsepara/eda/jl_5yr_100auto/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import joblib as jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../\n",
    "!du -h 'jl_5yr_100auto'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## work through evaluating based upon a set of existing models\n",
    "* I want to save all the separations to a data frame and then save it to disk\n",
    "* likewise with the retirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#os.chdir('../../')\n",
    "\n",
    "os.chdir(stgdir1local)\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_BASE_PATH='../save_models_1/'\n",
    "pred_cases = ['sep/','ret/']\n",
    "pred_years = map(np.str,np.arange(1,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep_proba_df = []\n",
    "ret_proba_df = []\n",
    "import joblib as jl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_models_simple(model_list,X,mode='mean',offset=0):\n",
    "    \"\"\" Function to apply a set of models to a given input and generate the predicted value(s)\n",
    "    :param model_list --> input list of models\n",
    "    :param X --> input array to apply models to\n",
    "    :param mode --> what sort of output to return; default is mean\n",
    "    intermediates\n",
    "        eval_pred_class --> array of classification prediction for each model\n",
    "        eval_pred_proba --> array of predicted probabilities for each model\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    eval_pred_class = np.zeros((len(X),len(model_list)))\n",
    "    eval_pred_proba = np.zeros((len(X),2,len(model_list)))\n",
    "\n",
    "    for i,mdl in enumerate(model_list):\n",
    "        eval_proba = mdl.predict_proba(X)\n",
    "        eval_pred_class[:,i]=mdl.predict(X)\n",
    "        eval_pred_proba[:,:,i]=eval_proba\n",
    "    if mode == 'mean':\n",
    "        # average the probabilities (for class=1) and return the mean predicted probability\n",
    "        prediction = np.mean(eval_pred_proba[:,1,:],axis=1)\n",
    "        #eval_pred_proba[:,1,:].mean(axis=2)\n",
    "\n",
    "    elif mode == 'class': # return the desired class prediction\n",
    "        prediction = map(np.int,eval_pred_class.mean(axis=1))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#del X\n",
    "np.shape(X5eval)\n",
    "X = X5eval[30:80,:]\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_proba_df = []\n",
    "for idx,pyr in enumerate(pred_years):\n",
    "    pkl_name ='rf'+pyr+'.pkl'#5.pkl'\n",
    "    path_name =MODEL_BASE_PATH+pred_cases[0]+pyr+'/'\n",
    "    print path_name, pkl_name\n",
    "    #path_name = MODEL_BASE_PATH+pred_cases[0]+\"5/\"#pred_years[0]+'/'\n",
    "        # load a model, evaluate it and return the 'average' probability for each person\n",
    "        #abs_mdl_name = os.path.abspath(path_name+pkl_name)\n",
    "    mdl_name = path_name+pkl_name\n",
    "    stored_mdl = jl.load(mdl_name)\n",
    "    stored_prediction = evaluate_models_simple(stored_mdl,X)#stored_pred,stored_pred_proba = evaluate_models(stored_mdl,X)\n",
    "\n",
    "    df = pd.DataFrame(stored_prediction.T)\n",
    "    df.columns=['sep'+pyr+'yr']\n",
    "    #df.#print stored_prediction\n",
    "    sep_proba_df.append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sep_proba_df)\n",
    "#sep_df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_df = pd.concat([a for a in sep_proba_df],axis=1)\n",
    "sep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sep_df.T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.rename(columns=['sep'+pyr+'yr'],inplace=True)\n",
    "df.columns=['sep'+pyr+'yr']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sep_proba_df = sep_proba_df[1:]\n",
    "pd.concat([a for a in sep_proba_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some miscellaneous, experimental visualizations of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(np.mean(eval_pred5proba[:,1,:],axis=1))\n",
    "ev5df = pd.DataFrame(eval_pred5proba[:,1,:])\n",
    "ev5df.head()\n",
    "#ev5df['avg'] = eval_pred5proba[:,0,:].mean(axis=2)\n",
    "#ev5df['avg'] = eval_pred5proba[:,0,:].min(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nshow = 21\n",
    "ev5df.head(nshow).T.boxplot(vert=False)\n",
    "plt.xlabel('predicted probability of separation')\n",
    "plt.ylabel('employee')\n",
    "plt.title('5 year window')\n",
    "#plt.plot(x=y5eval[:30],y=np.arange(0,30),color='darkgoldenrod',marker='*')\n",
    "for x,y in np.vstack([y5eval[:nshow],np.arange(0,nshow)]).T:\n",
    "    plt.plot(x,y,'D',color='darkgoldenrod')\n",
    "for x,yhat in np.vstack([map(np.int,eval_pred5class.mean(axis=1))[:nshow],np.arange(0,nshow)]).T:\n",
    "    plt.plot(x,yhat,'o',color='darkorchid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_class = ev5df.head(nshow).mean(axis=1) #map(np.int,ev5df.head(nshow).mean(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_class = p_class.apply(lambda x: round(x,0))\n",
    "#p_class['color']= 'red'\n",
    "p_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cname = ['red']*21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.violinplot(ev5df.head(nshow).T,vert=False)\n",
    "plt.xlabel('Probability of separation')\n",
    "plt.ylabel('employee')\n",
    "plt.xlim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create a scoring measure for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_kfold_cross_validation(model, all_X, all_y, k=5):\n",
    "    \"\"\"Calculate root mean squared error for each cross-validation fold.\n",
    "    \n",
    "    Parameters:\n",
    "        model - a scikit learn model\n",
    "        all_X - a pandas DataFrame with the observed input data\n",
    "        all_y - a pandas Series with the observed outcome\n",
    "        k - number of cross validation folds (test set will be 1/k of the data)\n",
    "    \n",
    "    Return value:\n",
    "        An array of length 'k' with the root mean squared error\n",
    "        for each fold.\n",
    "    \"\"\"\n",
    "    # 'folds' is a generator that will yield pairs of arrays (train, test)\n",
    "    # selecting row numbers for training/testing\n",
    "    folds = cross_validation.KFold(n=len(all_y), n_folds=k)\n",
    "    RMSE = []    # root mean squared errors\n",
    "    # Loop over the cross-validation folds\n",
    "    for training, testing in folds:\n",
    "        # Get the training and test splits\n",
    "        training = all_X.index[training]\n",
    "        testing = all_X.index[testing]\n",
    "        X_train, X_test = all_X.ix[training], all_X.ix[testing]\n",
    "        y_train, y_test = all_y.ix[training], all_y.ix[testing]\n",
    "    \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # Use the model to predict output\n",
    "        y_fitted = model.predict(X_test)\n",
    "        RMSE.append(np.sqrt(mean_squared_error(y_test, y_fitted)))\n",
    "    # Leave the model fit to the entire dataset\n",
    "    model.fit(all_X, all_y)\n",
    "    # And return the array of root mean squared errors\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first try to generalize the temporalKfold as a class\n",
    "* base this upon the KFold(_BaseKfold): class in scikitlearn\n",
    "* returns an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import _BaseKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class windowKFold(_BaseKFold):\n",
    "    \"\"\"windowed or temporal K-Folds cross validation iterator.\n",
    "    Provides train/test indices to split data in train test sets. Split\n",
    "    dataset into k consecutive folds (without shuffling).\n",
    "    Each fold is then used a validation set once while the k - 1 remaining\n",
    "    fold form the training set.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Total number of elements.\n",
    "    n_folds : int, default=3\n",
    "        Number of folds. Must be at least 2.\n",
    "    shuffle : boolean, optional\n",
    "        Whether to shuffle the data before splitting into batches.\n",
    "    random_state : None, int or RandomState\n",
    "        Pseudo-random number generator state used for random\n",
    "        sampling. If None, use default numpy RNG for shuffling\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn import cross_validation\n",
    "    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "    >>> y = np.array([1, 2, 3, 4])\n",
    "    >>> kf = cross_validation.KFold(4, n_folds=2)\n",
    "    >>> len(kf)\n",
    "    2\n",
    "    >>> print(kf)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    sklearn.cross_validation.KFold(n=4, n_folds=2, shuffle=False,\n",
    "                                   random_state=None)\n",
    "    >>> for train_index, test_index in kf:\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [2 3] TEST: [0 1]\n",
    "    TRAIN: [0 1] TEST: [2 3]\n",
    "    Notes\n",
    "    -----\n",
    "    The first n % n_folds folds have size n // n_folds + 1, other folds have\n",
    "    size n // n_folds.\n",
    "    See also\n",
    "    --------\n",
    "    StratifiedKFold: take label information into account to avoid building\n",
    "    folds with imbalanced class distributions (for binary or multiclass\n",
    "    classification tasks).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, n_folds=3, indices=None, shuffle=False,\n",
    "                 random_state=None):\n",
    "        super(KFold, self).__init__(n, n_folds, indices, shuffle, random_state)\n",
    "        self.idxs = np.arange(n)\n",
    "        if shuffle:\n",
    "            rng = check_random_state(self.random_state)\n",
    "            rng.shuffle(self.idxs)\n",
    "\n",
    "    def _iter_test_indices(self):\n",
    "        n = self.n\n",
    "        n_folds = self.n_folds\n",
    "        fold_sizes = (n // n_folds) * np.ones(n_folds, dtype=np.int)\n",
    "        fold_sizes[:n % n_folds] += 1\n",
    "        current = 0\n",
    "        for fold_size in fold_sizes:\n",
    "            start, stop = current, current + fold_size\n",
    "            yield self.idxs[start:stop]\n",
    "            current = stop\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '%s.%s(n=%i, n_folds=%i, shuffle=%s, random_state=%s)' % (\n",
    "            self.__class__.__module__,\n",
    "            self.__class__.__name__,\n",
    "            self.n,\n",
    "            self.n_folds,\n",
    "            self.shuffle,\n",
    "            self.random_state,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Size of the input set:\", input_data.shape)\n",
    "\n",
    "models = dict(\n",
    "    logistic = linear_model.LogisticRegression(),\n",
    "    gbc = ensemble.GradientBoostingClassifier(max_depth=5),\n",
    "    ridge = linear_model.RidgeClassifier(),\n",
    "    tree = tree.DecisionTreeClassifier(max_depth=5),\n",
    "    #svc = svm.LinearSVC(),\n",
    "    naive_bayes = naive_bayes.MultinomialNB(),  # Can only use if all inputs are positive\n",
    "    random_forest = ensemble.RandomForestClassifier(n_estimators=10, max_depth=5)\n",
    ")\n",
    "\n",
    "win = (spread > 0).astype(int)\n",
    "rmses = {}\n",
    "for name, model in models.items():\n",
    "    rmses[name] = perform_kfold_cross_validation(model, input_data, win, k=3)\n",
    "    \n",
    "pd.DataFrame(rmses).boxplot(vert=False, return_type='axes')\n",
    "plt.gcf().set_size_inches(9, 5)\n",
    "plt.xlabel(\"Error in prediction\"); plt.ylabel(\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try building a model with deeper splits? or more trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(X5fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_for_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jl.dump(five_rf_mdl_100A,'frf100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../\n",
    "%cd '/home/kesj/work/hrsepara/eda/jl_5yr_100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5.4 * 1000/250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "five_rf_mdl = []\n",
    "for i in xrange(0,len(tfold5)):\n",
    "    train_y = y5fold[i].flatten()#[tfold5[i][0]]\n",
    "    #train_X = #X5fold[tfold5[i][0],:,i]\n",
    "    train_X = X5fold[:,:,i]\n",
    "    rfmdl = ensemble.RandomForestClassifier(n_jobs=50,n_estimators=500,max_features=None)\n",
    "    rfmdl.fit(train_X,train_y)\n",
    "#baseline_singleRFC = ensemble.RandomForestClassifier(n_jobs=50,n_estimators=500,max_features=None)\n",
    "#baseline_singleRFC.fit(X,y_term)\n",
    "#baseline_singleRFC_importances= baseline_singleRFC.feature_importances_\n",
    "    five_rf_mdl.append(rfmdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(evalmod['hire_tstmp']-evalmod['birth_tstmp'])/np.timedelta64(1,'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pred_5class, eval_pred_proba5 = evaluate_models(five_rf_mdl,X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_pred5class_100A, eval_pred5proba = evaluate_models(five_rf_mdl_100A,X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(eval_pred_5class), len(y5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5eval,map(int,eval_pred_5class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5eval,map(int,eval_pred5class_100A.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y3eval,eval_prediction_proba3[:,])\n",
    "plot_roc_curve(y5eval,eval_pred5proba[:,:,:].mean(axis=2))\n",
    "plt.ylim([0,1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5eval,map(int,eval_pred_5class.mean(axis=1)+0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(five_rf_mdl,'five_rf_mdljl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd five_rf_mdljl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frf= joblib.load('five_rf_mdljl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Beval_pred_5class, Beval_pred_proba5 = evaluate_models(frf,X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y3eval,eval_prediction_proba3[:,])\n",
    "plot_roc_curve(y5eval,Beval_pred_proba5[:,:,:].mean(axis=2))\n",
    "plt.ylim([0,1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Beval_pred5class0, Beval_pred5proba0 = evaluate_models(frf[0],X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Beval_pred_proba5[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y3eval,eval_prediction_proba3[:,])\n",
    "plot_roc_curve(y5eval,Beval_pred_proba5[:,:,4])\n",
    "plt.ylim([0,1.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try again with joblib directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib as jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../\n",
    "!mkdir jl_5yr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jldir = '/home/kesj/work/hrsepara/eda/jl_5yr/' \n",
    "os.chdir(jldir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat for 3 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfold3,tfold3_times,panel3term,X3fold,y3fold = setup_tfold_models(em2mod,3,columns_for_modeling)\n",
    "print len(tfold3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "three_rf_mdl_100 = []\n",
    "for i in xrange(0,len(tfold3)):\n",
    "    train_y = y3fold[i].flatten()\n",
    "    train_X = X3fold[:,:,i]\n",
    "    rfmdl = ensemble.RandomForestClassifier(n_estimators=100,max_features='auto',n_jobs=1)\n",
    "    rfmdl.fit(train_X,train_y)\n",
    "#baseline_singleRFC = ensemble.RandomForestClassifier(n_jobs=50,n_estimators=500,max_features=None)\n",
    "#baseline_singleRFC.fit(X,y_term)\n",
    "#baseline_singleRFC_importances= baseline_singleRFC.feature_importances_\n",
    "    three_rf_mdl_100.append(rfmdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dump the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd '../'\n",
    "!mkdir 'jl_3yr_100'\n",
    "%cd '/home/kesj/work/hrsepara/eda/jl_3yr_100'\n",
    "three_100_list = jl.dump(three_rf_mdl_100,'trf100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(three_100_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3eval, y3eval = adjust_eval_by_x_years(evalmod,3,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_pred3class,eval_pred3proba = evaluate_models(three_rf_mdl_100,X3eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y3eval,eval_pred3proba[:,:,:].mean(axis=2))\n",
    "plt.ylim([0,1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_conf_matrix(y3eval,eval_)\n",
    "plot_conf_matrix(y3eval,map(int,eval_pred3class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# omit those that have more than 25% missing:\n",
    "missing_threshold = 0.25\n",
    "columns_to_omit = list(sdf[sdf['x_missing'] > missing_threshold].Column.values)\n",
    "print len(columns_to_omit)\n",
    "print columns_to_omit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a simple DataFrame of employee dates using Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let me return to removing columns I don't want\n",
    "* keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "columns_to_remove = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"DF_Converter\", br.DataFrameConverter(columns=X.columns)),\n",
    "                     (\"Cat_Converter\", br.ConvertCategorical(categorical_columns=categorical_columns)),\n",
    "                     (\"Impute\", br.ImputeData()),\n",
    "                     (\"clf\", RandomForestClassifier(n_jobs=50))])\n",
    "pipeline.fit(X, y)\n",
    "pipeline.predict_proba(X_2014_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add/replace some relevant columns to this dataframe\n",
    "* POSTAL_SFI --> zip5 \n",
    "* unempl_rate by joining on unemployment\n",
    "* Age_hire\n",
    "* terminated \n",
    "* sep_status\n",
    "\n",
    "use a parallel dataframe for dates/timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnSelector(TransformerMixin):\n",
    "    \"\"\" Selects column(s) from a pandas DataFrame\n",
    "    \"\"\"\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols\n",
    "    def tranform(self, X, y=None):\n",
    "        return X[:,self.cols]\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Per discussion with HR COE team decide to truncate data after a particular date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions Follow\n",
    "* Most taken from ```bear.py```\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note make sure you have run kinit before the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now assign these values to the arrays\n",
    "emB['med_surv'] = emB['JOBCODE'].apply(lambda x: med_survival[x] )\n",
    "emB_eval['med_surv'] = emB_eval['JOBCODE'].apply(lambda x: med_survival[x] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeling_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(modeling_cols)\n",
    "sm_mod_cols = [a for a in modeling_cols]\n",
    "job_function_cols = [b for b in modeling_cols if b.startswith('JOB_FUNCTION')]\n",
    "job_function_cols\n",
    "#for a in ['JOBCODE','grade_code','loc_descr','job_fcode','']\n",
    "sm_mod_cols.remove('JOBCODE')\n",
    "sm_mod_cols+=['med_surv']\n",
    "print len(sm_mod_cols), len(modeling_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xp = emB[sm_mod_cols].as_matrix().astype(np.float)\n",
    "print np.shape(Xp)\n",
    "#y_tenure = emB.Tenure_years.as_matrix().astype(np.float)\n",
    "Xeval_p = emB_eval[sm_mod_cols].as_matrix().astype(np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "RFRforest2 = ensemble.RandomForestRegressor(n_jobs=50,n_estimators=500,max_features=None)\n",
    "RFRforest2.fit(Xp,y_tenure)\n",
    "#importances= forest.feature_importances_\n",
    "## apply to the eval subset from emB\n",
    "pred_tenure_eval_2 = RFRforest2.predict(Xeval_p)\n",
    "np.shape(pred_tenure_eval_2)#, np.shape(y_tenure_class.ix[eval_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_feature_importances(RFRforest2,sm_mod_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.scatter(y_tenure_class.ix[eval_index],pred_tenure_eval,color='chartreuse',alpha=0.3)\n",
    "sns.regplot(emB_eval.Tenure_years, pred_tenure_eval_2,color='darkorchid')\n",
    "#plt.scatter(emB_eval.Tenure_years,pred_tenure_eval,color='darkslategray',alpha=0.3)\n",
    "plt.xlabel('True Tenure Length')\n",
    "plt.ylabel('Predicted Tenure Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
