{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#HR Separation. \n",
    "Checking the annual retirement and separation rates given a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coredir = '/data/discovery/hrsepara/core/'\n",
    "stgdir1 = '/data/discovery/hrsepara/staging/eda'\n",
    "stgdir1local = '/home/kesj/work/hrsepara/eda'\n",
    "stgdir2local = '/home/hrsepara/work'\n",
    "repodir = '/home/kesj/lib/repo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/2.3.0/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/opt/anaconda/2.3.0/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "### load the basic files\n",
    "import os,subprocess,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "import random\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of attack:\n",
    "1. read the data (after 2001)\n",
    "2. obtain the set of current employees\n",
    "3. Run through a model to get prediction(s) for retirement and separation\n",
    "    * based upon the given model, preprocess it appropriately: for the server model use the minimal set of features and processing of the web_app code.\n",
    "    * for the survival model ...\n",
    "4. calc the total separation and retirements for each year and derive the rate of separation/retirement.\n",
    "    * how do I determine the confidence intervals for these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134266, 69)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.chdir(stgdir1local)\n",
    "#em2002 = pd.read_csv('employees_after2001_raw.csv',dtype={'EMPL_CLASS':np.str,'LOCATION':np.str,'EEO1CODE':np.str,'SHIFT':np.str,'VOLINVOL':np.str})\n",
    "#em2002.shape\n",
    "##em2 = pd.read_csv('after2001_v1.csv')\n",
    "##em2.head()\n",
    "os.chdir('/home/hrsepara/work/data/')\n",
    "em2002 = pd.read_csv('after2001_v3.csv',dtype={'EMPL_CLASS':np.str,'EEO1CODE':np.str,'KEY':np.str})\n",
    "em2002.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'status' in em2002.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>retired</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49674</td>\n",
       "      <td>15117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "retired      0      1\n",
       "status               \n",
       "0        69475      0\n",
       "1        49674  15117"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(em2002.status, em2002.retired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save this dataframe\n",
    "#os.chdir(stgdir2local)\n",
    "#em2002.to_csv('after2001_keyed.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first define the current employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current = em2002[em2002.status==0].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69475, 69)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now look to apply the HRserver model (reduced column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cols_to_keep = ['KEY','HIRE_DT','BIRTHDATE','SAL1','MERIT1','PERF1','BOX1','SEX','HAVE_INS','HAVE_DEP']\n",
    "#columns_for_modeling = ['Age_years','Tenure_years','SAL1','MERIT1','PERF1','BOX1','SEX','HAVE_INS','HAVE_DEP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#employee_df = current[columns_for_modeling].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#employee_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# March 4, 2016\n",
    "## Look at applying my current best models to the set of current employees:\n",
    "* retirement_sf2.pkl \n",
    "* separation_cf4.pkl\n",
    "### Load these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/proc')\n",
    "retirement_mdl_file = 'retirement_sf2.pkl'\n",
    "separation_mdl_file = 'separation_cf4.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=34767, number of events=11905\n",
      "\n",
      "                coef  exp(coef)  se(coef)          z          p  lower 0.95  upper 0.95     \n",
      "Age_years  3.388e-01  1.403e+00 1.010e-02  3.354e+01 1.192e-246   3.190e-01   3.586e-01  ***\n",
      "SAL1      -2.439e-01  7.836e-01 1.313e-02 -1.858e+01  4.794e-77  -2.697e-01  -2.182e-01  ***\n",
      "MERIT1    -2.373e-01  7.888e-01 1.416e-02 -1.675e+01  5.614e-63  -2.650e-01  -2.095e-01  ***\n",
      "PERF1     -1.240e-01  8.834e-01 1.373e-02 -9.032e+00  1.686e-19  -1.509e-01  -9.708e-02  ***\n",
      "BOX1      -1.031e-02  9.897e-01 1.254e-02 -8.222e-01  4.110e-01  -3.488e-02   1.427e-02     \n",
      "SEX        1.697e-01  1.185e+00 1.129e-02  1.503e+01  4.522e-51   1.475e-01   1.918e-01  ***\n",
      "HAVE_INS  -1.610e-01  8.513e-01 1.126e-02 -1.430e+01  2.206e-46  -1.830e-01  -1.389e-01  ***\n",
      "HAVE_DEP   4.226e-03  1.004e+00 1.099e-02  3.844e-01  7.007e-01  -1.732e-02   2.578e-02     \n",
      "---\n",
      "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n",
      "\n",
      "Concordance = 0.723\n"
     ]
    }
   ],
   "source": [
    "ret_mdl = pickle.load(open(retirement_mdl_file))\n",
    "ret_mdl.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=76368, number of events=31927\n",
      "\n",
      "                       coef  exp(coef)  se(coef)          z          p  lower 0.95  upper 0.95     \n",
      "Age_years        -9.386e-01  3.912e-01 1.023e-02 -9.175e+01  0.000e+00  -9.587e-01  -9.185e-01  ***\n",
      "SAL1             -1.115e+00  3.278e-01 1.479e-02 -7.539e+01  0.000e+00  -1.144e+00  -1.086e+00  ***\n",
      "MERIT1            2.742e-01  1.315e+00 6.343e-03  4.323e+01  0.000e+00   2.618e-01   2.866e-01  ***\n",
      "PERF1            -1.016e-01  9.034e-01 1.240e-02 -8.195e+00  2.514e-16  -1.259e-01  -7.730e-02  ***\n",
      "BOX1             -4.839e-01  6.164e-01 6.824e-03 -7.090e+01  0.000e+00  -4.972e-01  -4.705e-01  ***\n",
      "SEX               1.643e-01  1.179e+00 6.098e-03  2.695e+01 5.826e-160   1.524e-01   1.763e-01  ***\n",
      "HAVE_INS         -3.066e-01  7.359e-01 9.072e-03 -3.380e+01 1.975e-250  -3.244e-01  -2.888e-01  ***\n",
      "HAVE_DEP         -2.326e-01  7.925e-01 1.147e-02 -2.027e+01  2.258e-91  -2.550e-01  -2.101e-01  ***\n",
      "DEPTCNT1         -3.471e-01  7.068e-01 9.569e-03 -3.627e+01 4.495e-288  -3.658e-01  -3.283e-01  ***\n",
      "EXTFUNC_CNT       9.591e-02  1.101e+00 5.597e-03  1.713e+01  8.204e-66   8.494e-02   1.069e-01  ***\n",
      "FUNC_CNT         -1.504e-01  8.603e-01 8.158e-03 -1.844e+01  6.098e-76  -1.664e-01  -1.344e-01  ***\n",
      "REMOTE           -1.546e-01  8.567e-01 1.116e-02 -1.386e+01  1.179e-43  -1.765e-01  -1.328e-01  ***\n",
      "DIRECT_RPT_CNT    1.569e-01  1.170e+00 3.968e-03  3.955e+01  0.000e+00   1.491e-01   1.647e-01  ***\n",
      "HUBIND           -8.338e-02  9.200e-01 6.762e-03 -1.233e+01  6.280e-35  -9.663e-02  -7.012e-02  ***\n",
      "REH_CNT          -2.330e-01  7.921e-01 6.523e-03 -3.572e+01 1.758e-279  -2.458e-01  -2.202e-01  ***\n",
      "JOB_FUNCTION_PSA -7.550e-02  9.273e-01 6.798e-03 -1.111e+01  1.179e-28  -8.883e-02  -6.217e-02  ***\n",
      "---\n",
      "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n",
      "\n",
      "Concordance = 0.887\n"
     ]
    }
   ],
   "source": [
    "sep_mdl = pickle.load(open(separation_mdl_file))\n",
    "sep_mdl.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### begin with Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_surv_model_columns(surv_mdl):\n",
    "    #event_col = surv_mdl.event_observed.name\n",
    "    time_col = surv_mdl.durations.name\n",
    "    model_cols = surv_mdl.hazards_.columns.tolist()\n",
    "    cols_to_keep = [a for a in model_cols]\n",
    "    cols_to_keep.append(event_col)\n",
    "    cols_to_keep.append(time_col)\n",
    "    return cols_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age_years', 'SAL1', 'MERIT1', 'PERF1', 'BOX1', 'SEX', 'HAVE_INS', 'HAVE_DEP', 'DEPTCNT1', 'EXTFUNC_CNT', 'FUNC_CNT', 'REMOTE', 'DIRECT_RPT_CNT', 'HUBIND', 'REH_CNT', 'JOB_FUNCTION_PSA', 'status', 'Tenure_years']\n"
     ]
    }
   ],
   "source": [
    "sep_cols_to_keep = get_surv_model_columns(sep_mdl)\n",
    "print(sep_cols_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define columns that are NOT in the input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JOB_FUNCTION_PSA']\n"
     ]
    }
   ],
   "source": [
    "cols_to_construct = list(set(sep_cols_to_keep)-set(current.columns.tolist()))\n",
    "print(cols_to_construct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'JOB_FUNCTION'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pieces = cols_to_construct[0].split('_')\n",
    "print(len(pieces))\n",
    "dummy_cat = pieces[-1]\n",
    "main_cat = \"_\".join(piece for piece in pieces[:-1])\n",
    "main_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## transform the input to this format\n",
    "current[cols_to_construct[0]]=current[main_cat].apply(lambda x: 1 if x==dummy_cat else 0)\n",
    "#current[main_cat][current[main_cat]==dummy_cat]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "employee_df = current[sep_cols_to_keep].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat for retirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_cols_to_keep = get_surv_model_columns(ret_mdl)\n",
    "ret_cols_to_construct = list(set(ret_cols_to_keep)-set(current.columns.tolist()))\n",
    "ret_cols_to_construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret_empl = current[ret_cols_to_keep].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin applying the models to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age_years           False\n",
       "SAL1                False\n",
       "MERIT1              False\n",
       "PERF1               False\n",
       "BOX1                False\n",
       "SEX                 False\n",
       "HAVE_INS            False\n",
       "HAVE_DEP            False\n",
       "DEPTCNT1            False\n",
       "EXTFUNC_CNT         False\n",
       "FUNC_CNT            False\n",
       "REMOTE              False\n",
       "DIRECT_RPT_CNT      False\n",
       "HUBIND              False\n",
       "REH_CNT             False\n",
       "JOB_FUNCTION_PSA    False\n",
       "status              False\n",
       "Tenure_years        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_df.isnull().any() # nothing is missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAL1</th>\n",
       "      <th>PERF1</th>\n",
       "      <th>MERIT1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69475.000000</td>\n",
       "      <td>69475.000000</td>\n",
       "      <td>69475.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63044.836594</td>\n",
       "      <td>2193.765437</td>\n",
       "      <td>1824.702200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31289.533827</td>\n",
       "      <td>1898.840218</td>\n",
       "      <td>2362.811163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9094.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-45000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38642.465000</td>\n",
       "      <td>877.500000</td>\n",
       "      <td>904.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>57323.480000</td>\n",
       "      <td>1928.370000</td>\n",
       "      <td>1630.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>81215.420000</td>\n",
       "      <td>3213.000000</td>\n",
       "      <td>2514.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>725000.000000</td>\n",
       "      <td>56751.140000</td>\n",
       "      <td>35000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SAL1         PERF1        MERIT1\n",
       "count   69475.000000  69475.000000  69475.000000\n",
       "mean    63044.836594   2193.765437   1824.702200\n",
       "std     31289.533827   1898.840218   2362.811163\n",
       "min      9094.800000      0.000000 -45000.000000\n",
       "25%     38642.465000    877.500000    904.230000\n",
       "50%     57323.480000   1928.370000   1630.710000\n",
       "75%     81215.420000   3213.000000   2514.330000\n",
       "max    725000.000000  56751.140000  35000.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_df[['SAL1','PERF1','MERIT1']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix the dollar amounts\n",
    "min_sal1 = 17621.76 #(based upon training set I have: 5 %tile cut off)\n",
    "min_min_rt_ann = 17900. # same as above\n",
    "min_max_rt_ann = 33155.70\n",
    "\n",
    "max_max_rt_ann = 133068.91\n",
    "min_merit1 = 0.0\n",
    "min_perf1 = 0.0\n",
    "fix_min_outlier_col_dict = {'SAL1': min_sal1, 'MERIT1': min_merit1, 'PERF1': min_perf1}\n",
    "#fix_max_outlier_col_dict = {'MAX_RT_ANNUAL': max_max_rt_ann}\n",
    "\n",
    "# replace these values\n",
    "for key,value in fix_min_outlier_col_dict.iteritems():        \n",
    "    idx_to_replace = employee_df[employee_df[key]<value].index\n",
    "    employee_df.loc[idx_to_replace,key]=value\n",
    "\n",
    "    # dummy empl_type categories\n",
    "    #empl_type_dummy_cat = ['EMPL_TYPE_E', 'EMPL_TYPE_H', 'EMPL_TYPE_N', 'EMPL_TYPE_S', 'EMPL_TYPE_X', 'EMPL_TYPE_nan']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAL1</th>\n",
       "      <th>PERF1</th>\n",
       "      <th>MERIT1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69475.000000</td>\n",
       "      <td>69475.000000</td>\n",
       "      <td>69475.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63098.086224</td>\n",
       "      <td>2193.765437</td>\n",
       "      <td>1918.218172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31209.347146</td>\n",
       "      <td>1898.840218</td>\n",
       "      <td>1790.079567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17621.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38642.465000</td>\n",
       "      <td>877.500000</td>\n",
       "      <td>904.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>57323.480000</td>\n",
       "      <td>1928.370000</td>\n",
       "      <td>1630.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>81215.420000</td>\n",
       "      <td>3213.000000</td>\n",
       "      <td>2514.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>725000.000000</td>\n",
       "      <td>56751.140000</td>\n",
       "      <td>35000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SAL1         PERF1        MERIT1\n",
       "count   69475.000000  69475.000000  69475.000000\n",
       "mean    63098.086224   2193.765437   1918.218172\n",
       "std     31209.347146   1898.840218   1790.079567\n",
       "min     17621.760000      0.000000      0.000000\n",
       "25%     38642.465000    877.500000    904.230000\n",
       "50%     57323.480000   1928.370000   1630.710000\n",
       "75%     81215.420000   3213.000000   2514.330000\n",
       "max    725000.000000  56751.140000  35000.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_df[['SAL1','PERF1','MERIT1']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oh no these versions of the fitter don't have my utilities associated with them...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Forecast forward in 1 year intervals\n",
    "def identify_forecast_timepoints(mdl, X, time_range):\n",
    "    \"\"\"\n",
    "        :param X: a (n,d) covariate numpy array or DataFrame. If a numpy array, it is coerced into a DataFrame\n",
    "        :param time_range: a list of times to calculate the survival for.\n",
    "        :return: time_point_df a DataFrame of selected future times to create survival forecasts for.\n",
    "\n",
    "        Construct a data frame that has the current time_col for each observation incremented by the values in the\n",
    "        desired list (time_range)\n",
    "    \"\"\"\n",
    "    time_col = mdl.durations.name\n",
    "    column_names = ['time_point_'+np.str(tp) for tp in time_range]\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        my_index = X.index.tolist()\n",
    "    else:\n",
    "        my_index = np.arange(0, len(X))\n",
    "        X = pd.DataFrame(X, columns=mdl.hazards_.columns)\n",
    "\n",
    "    time_point_df = pd.DataFrame(columns=column_names, index=my_index)\n",
    "    for idx in my_index:\n",
    "        my_times = np.array([X.loc[idx, time_col]+tp for tp in time_range])\n",
    "        time_point_df.ix[idx] = my_times\n",
    "\n",
    "    return time_point_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "def return_desired_cumulative_hazards(t,mdl):\n",
    "    \"\"\"\n",
    "    t: an event time that is used as the base line to forecast forward in time\n",
    "    \"\"\"\n",
    "    maxtimepoint = mdl.baseline_hazard_.index.max() #Now taken care of in the forecast\n",
    "    if t > maxtimepoint:\n",
    "        t = maxtimepoint # just set to the max value.\n",
    "    try:\n",
    "        # spec_hazard = self.baseline_hazard_.ix[t].values\n",
    "        c_haz = mdl.baseline_cumulative_hazard_.ix[t].values[0]\n",
    "\n",
    "    except KeyError:\n",
    "        # get the first after this point\n",
    "        t_post = mdl.baseline_hazard_.ix[t:].index[0]\n",
    "        # get the last before this point\n",
    "        t_prior = mdl.baseline_hazard_.ix[:t].index[-1]\n",
    "        # x = [t_prior, t_post]\n",
    "        y = [mdl.baseline_cumulative_hazard_.ix[t_prior].values[0],\n",
    "             mdl.baseline_cumulative_hazard_.ix[t_post].values[0]]\n",
    "        # print(x, y)\n",
    "        chaz_interp = interpolate.interp1d([t_prior, t_post], y)\n",
    "        c_haz = chaz_interp(t)\n",
    "\n",
    "    return c_haz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sep_timepoints = identify_forecast_timepoints(sep_mdl,employee_df,[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def line(x, a, b):\n",
    "    return a*x+b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forecast_survival_function(mdl, df, time_range=[0,1,2,3,4,5], calc_ci=True, extrapolate=False):\n",
    "    \"\"\"\n",
    "        :param self:\n",
    "        :param df:\n",
    "\n",
    "        :param time_range:\n",
    "        :param calc_ci: flag to return the confidence intervals\n",
    "        :return:\n",
    "    \"\"\"\n",
    "\n",
    "    #time_col = self.durations.name\n",
    "    col_names = ['t_'+np.str(tp) for tp in time_range]\n",
    "    # calculate the predicted hazard\n",
    "    my_partial_hazard = mdl.predict_partial_hazard(df)\n",
    "    # assign the specific timepoints and calculate the cumulative hazards at these points\n",
    "    forecast_times = identify_forecast_timepoints(mdl,df, time_range)\n",
    "    max_time = mdl.baseline_hazard_.index.max()\n",
    "    if extrapolate:\n",
    "        # do a linear extrapolation of the cumulative hazards and use this to get values beyond the known range\n",
    "        p_haz, p_haz_cov = curve_fit(line, mdl.baseline_cumulative_hazard_.index,\n",
    "                                 mdl.baseline_cumulative_hazard_.values.ravel())\n",
    "            # force the points to match\n",
    "        offset = mdl.baseline_cumulative_hazard_.values[-1][0] - line(mdl.baseline_cumulative_hazard_.index[-1],\n",
    "                                                                           p_haz[0] ,p_haz[1])\n",
    "            # apply to timepoints\n",
    "        specific_cumulative_hazards = forecast_times.applymap(lambda x: return_desired_cumulative_hazards(mdl,x)\n",
    "            if x <= max_time else offset+line(x,popt[0],popt[1]))\n",
    "    else:  # this is the default case\n",
    "            # replace those that exceed the max-time observed with the max observed time\n",
    "        forecast_times[forecast_times > max_time] = max_time\n",
    "        specific_cumulative_hazards = forecast_times.applymap(lambda x: return_desired_cumulative_hazards(x,mdl))\n",
    "\n",
    "        # predict the survival function at these forecasted times\n",
    "        pred_survival_fcn = pd.DataFrame(np.exp(-np.multiply(specific_cumulative_hazards.values,\n",
    "                                                             my_partial_hazard.values)), index=df.index)\n",
    "\n",
    "    if calc_ci:\n",
    "        # calculate the predicted hazard\n",
    "        partial_hazard_ci = mdl.predict_partial_hazard_ci(df)\n",
    "        pred_lower_survival_ci = pd.DataFrame(np.exp(-np.multiply(specific_cumulative_hazards.values.T,\n",
    "                                                                  partial_hazard_ci.values[:, 1])),\n",
    "                                              columns=df.index).T\n",
    "        pred_upper_survival_ci = pd.DataFrame(np.exp(-np.multiply(specific_cumulative_hazards.values.T,\n",
    "                                                                  partial_hazard_ci.values[:, 0])),\n",
    "                                              columns=df.index).T\n",
    "\n",
    "        surv_prediction = pd.Panel(data={'surv': pred_survival_fcn, 'lbci': pred_lower_survival_ci,\n",
    "                                         'ubci': pred_upper_survival_ci})\n",
    "    else:\n",
    "        surv_prediction = pd.Panel(data={'surv': pred_survival_fcn})\n",
    "                                   #, 'lbci': pred_survival_fcn,\n",
    "                                   #      'ubci': pred_survival_fcn})\n",
    "    surv_prediction.minor_axis = col_names\n",
    "\n",
    "    return surv_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets break this down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 11s, sys: 473 ms, total: 25min 12s\n",
      "Wall time: 25min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tdp = identify_forecast_timepoints(sep_mdl, employee_df, time_range =[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 17.2 µs\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#sep_forecast = forecast_survival_function(sep_mdl, employee_df, time_range=[0,1,2,3,4,5], calc_ci=True, extrapolate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_partial_hazard = sep_mdl.predict_partial_hazard(employee_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.0408906411\n"
     ]
    }
   ],
   "source": [
    "max_time = sep_mdl.baseline_hazard_.index.max()\n",
    "print(max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdp2 = tdp.copy()\n",
    "tdp2[tdp2>max_time]=max_time # just set to the max value (no extrapolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spec_cum_haz = tdp2.applymap(lambda x: return_desired_cumulative_hazards(x,sep_mdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep_pred_survival_function = pd.DataFrame(np.exp(-np.multiply(spec_cum_haz.values,\n",
    "                                                             my_partial_hazard.values)), index=employee_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_proba = 1-sep_pred_survival_function\n",
    "sep_proba['KEY']= current.KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sep_prob0</th>\n",
       "      <th>sep_prob1</th>\n",
       "      <th>sep_prob2</th>\n",
       "      <th>sep_prob3</th>\n",
       "      <th>sep_prob4</th>\n",
       "      <th>sep_prob5</th>\n",
       "      <th>KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64791</th>\n",
       "      <td>0.416907</td>\n",
       "      <td>0.433157</td>\n",
       "      <td>0.456523</td>\n",
       "      <td>0.469564</td>\n",
       "      <td>0.495995</td>\n",
       "      <td>0.516903</td>\n",
       "      <td>929965184037557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64792</th>\n",
       "      <td>0.411617</td>\n",
       "      <td>0.430857</td>\n",
       "      <td>0.450175</td>\n",
       "      <td>0.466659</td>\n",
       "      <td>0.492508</td>\n",
       "      <td>0.505002</td>\n",
       "      <td>2396741883083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64793</th>\n",
       "      <td>0.092980</td>\n",
       "      <td>0.098332</td>\n",
       "      <td>0.104625</td>\n",
       "      <td>0.109815</td>\n",
       "      <td>0.115951</td>\n",
       "      <td>0.122274</td>\n",
       "      <td>872454415016088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64794</th>\n",
       "      <td>0.126733</td>\n",
       "      <td>0.136192</td>\n",
       "      <td>0.147030</td>\n",
       "      <td>0.159128</td>\n",
       "      <td>0.173263</td>\n",
       "      <td>0.188095</td>\n",
       "      <td>247046588569436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64795</th>\n",
       "      <td>0.130791</td>\n",
       "      <td>0.142563</td>\n",
       "      <td>0.153719</td>\n",
       "      <td>0.163980</td>\n",
       "      <td>0.173378</td>\n",
       "      <td>0.181629</td>\n",
       "      <td>797202090638318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sep_prob0  sep_prob1  sep_prob2  sep_prob3  sep_prob4  sep_prob5  \\\n",
       "64791   0.416907   0.433157   0.456523   0.469564   0.495995   0.516903   \n",
       "64792   0.411617   0.430857   0.450175   0.466659   0.492508   0.505002   \n",
       "64793   0.092980   0.098332   0.104625   0.109815   0.115951   0.122274   \n",
       "64794   0.126733   0.136192   0.147030   0.159128   0.173263   0.188095   \n",
       "64795   0.130791   0.142563   0.153719   0.163980   0.173378   0.181629   \n",
       "\n",
       "                   KEY  \n",
       "64791  929965184037557  \n",
       "64792    2396741883083  \n",
       "64793  872454415016088  \n",
       "64794  247046588569436  \n",
       "64795  797202090638318  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_proba.columns = ['sep_prob0','sep_prob1','sep_prob2','sep_prob3','sep_prob4','sep_prob5','KEY']\n",
    "sep_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>sep_prob0</th>\n",
       "      <th>sep_prob1</th>\n",
       "      <th>sep_prob2</th>\n",
       "      <th>sep_prob3</th>\n",
       "      <th>sep_prob4</th>\n",
       "      <th>sep_prob5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64791</th>\n",
       "      <td>929965184037557</td>\n",
       "      <td>0.416907</td>\n",
       "      <td>0.433157</td>\n",
       "      <td>0.456523</td>\n",
       "      <td>0.469564</td>\n",
       "      <td>0.495995</td>\n",
       "      <td>0.516903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64792</th>\n",
       "      <td>2396741883083</td>\n",
       "      <td>0.411617</td>\n",
       "      <td>0.430857</td>\n",
       "      <td>0.450175</td>\n",
       "      <td>0.466659</td>\n",
       "      <td>0.492508</td>\n",
       "      <td>0.505002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64793</th>\n",
       "      <td>872454415016088</td>\n",
       "      <td>0.092980</td>\n",
       "      <td>0.098332</td>\n",
       "      <td>0.104625</td>\n",
       "      <td>0.109815</td>\n",
       "      <td>0.115951</td>\n",
       "      <td>0.122274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64794</th>\n",
       "      <td>247046588569436</td>\n",
       "      <td>0.126733</td>\n",
       "      <td>0.136192</td>\n",
       "      <td>0.147030</td>\n",
       "      <td>0.159128</td>\n",
       "      <td>0.173263</td>\n",
       "      <td>0.188095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64795</th>\n",
       "      <td>797202090638318</td>\n",
       "      <td>0.130791</td>\n",
       "      <td>0.142563</td>\n",
       "      <td>0.153719</td>\n",
       "      <td>0.163980</td>\n",
       "      <td>0.173378</td>\n",
       "      <td>0.181629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   KEY  sep_prob0  sep_prob1  sep_prob2  sep_prob3  sep_prob4  \\\n",
       "64791  929965184037557   0.416907   0.433157   0.456523   0.469564   0.495995   \n",
       "64792    2396741883083   0.411617   0.430857   0.450175   0.466659   0.492508   \n",
       "64793  872454415016088   0.092980   0.098332   0.104625   0.109815   0.115951   \n",
       "64794  247046588569436   0.126733   0.136192   0.147030   0.159128   0.173263   \n",
       "64795  797202090638318   0.130791   0.142563   0.153719   0.163980   0.173378   \n",
       "\n",
       "       sep_prob5  \n",
       "64791   0.516903  \n",
       "64792   0.505002  \n",
       "64793   0.122274  \n",
       "64794   0.188095  \n",
       "64795   0.181629  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_proba = sep_proba[['KEY','sep_prob0','sep_prob1','sep_prob2','sep_prob3','sep_prob4','sep_prob5']]\n",
    "sep_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep_proba.to_csv('current_sep_prob.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2534"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sep_proba.sep_prob0>=0.5).astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/kesj/work/hrsepara/proc'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for retirement I need to predict prob = 0 if age <50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load my version of lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll_repo_dir = '/home/kesj/lib/repo/lifelines'\n",
    "os.chdir(ll_repo_dir)\n",
    "import lifelines as ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep_mdl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the current date\n",
    "import datetime\n",
    "today_timestamp = pd.to_datetime(datetime.datetime.today())\n",
    "print today_timestamp\n",
    "# replace with Jan 01-15\n",
    "today_timestamp =pd.to_datetime(datetime.datetime.strptime('01JAN2015','%d%b%Y'))\n",
    "print today_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_years(timestamp1,timestamp2,days_in_year =365.25):\n",
    "    number_of_years = (timestamp2 - timestamp1).days/days_in_year\n",
    "    return number_of_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create timestamps for columns that are timestamps\n",
    "\n",
    "employee_df[['hire_tstmp','birth_tstmp']] = employee_df[['HIRE_DT','BIRTHDATE']].applymap(lambda x: pd.to_datetime(datetime.datetime.strptime(x,'%d%b%Y')))\n",
    "employee_df[['Age_years','Tenure_years']] = employee_df[['birth_tstmp','hire_tstmp']].applymap(lambda x: calculate_years(x,today_timestamp))\n",
    "\n",
    "# now deal with the the rest of the columns (map using the above  )\n",
    "columns_for_modeling = ['Age_years','Tenure_years','SAL1','MERIT1','PERF1','BOX1','SEX','HAVE_INS','HAVE_DEP',]\n",
    "    #'EMPL_TYPE']\n",
    "# replace Y with 1 and N with 0\n",
    "# replace M with 1 and F with 0 (in SEX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl=employee_df[columns_for_modeling].copy()\n",
    "empl.fillna({'HAVE_INS':'N','HAVE_DEP':'N','BOX1':0,'MERIT1':0.0,'PERF1':0.0,'SAL1':0.0},inplace=True)\n",
    "empl.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## replace specific elements based upon dictionary\n",
    "replace_dict = {'HAVE_INS': {'Y':1,'N':0}, 'HAVE_DEP': {'Y':1,'N':0}, 'BOX1':{'H':3,'S':2,'L':1},'SEX':{'M':1,'F':0}}\n",
    "for key,value in replace_dict.iteritems():\n",
    "    empl[key].replace(value,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = employee_df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the application of a series of time-based model\n",
    "def apply_time_models(X,MODEL_BASE_PATH,pcase,pred_years):\n",
    "    proba_df = []\n",
    "\n",
    "\n",
    "    import joblib as jl\n",
    "    import pandas as pd\n",
    "\n",
    "    for idx,pyr in enumerate(pred_years):\n",
    "        pkl_name ='rf'+pyr+'.pkl'#5.pkl'\n",
    "        if pcase == 'ret/':\n",
    "            pkl_name = 'R'+pkl_name\n",
    "\n",
    "        path_name =MODEL_BASE_PATH+pcase+pyr+'/'\n",
    "        print path_name, pkl_name\n",
    "\n",
    "        # load a model, evaluate it and return the 'average' probability for each person\n",
    "        #abs_mdl_name = os.path.abspath(path_name+pkl_name)\n",
    "        mdl_name = path_name+pkl_name\n",
    "        stored_mdl = jl.load(mdl_name)\n",
    "        stored_prediction = evaluate_models(stored_mdl,X)#stored_pred,stored_pred_proba = evaluate_models(stored_mdl,X)\n",
    "\n",
    "        df = pd.DataFrame(stored_prediction.T)\n",
    "        df.columns=[pcase[:-1]+pyr+'yr']\n",
    "\n",
    "        proba_df.append(df)\n",
    "\n",
    "    pred_df = pd.concat([a for a in proba_df], axis=1)\n",
    "    return pred_df\n",
    "\n",
    "# define a function to apply a set of models to a given prediction\n",
    "## now apply each model to my eval set\n",
    "def evaluate_models(model_list,X,mode='mean',offset=0):\n",
    "    \"\"\" Function to apply a set of models to a given input and generate the predicted value(s)\n",
    "    :param model_list --> input list of models\n",
    "    :param X --> input array to apply models to\n",
    "    :param mode --> what sort of output to return; default is mean\n",
    "    intermediates\n",
    "        eval_pred_class --> array of classification prediction for each model\n",
    "        eval_pred_proba --> array of predicted probabilities for each model\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    eval_pred_class = np.zeros((len(X),len(model_list)))\n",
    "    eval_pred_proba = np.zeros((len(X),2,len(model_list)))\n",
    "\n",
    "    for i,mdl in enumerate(model_list):\n",
    "        eval_proba = mdl.predict_proba(X)\n",
    "        eval_pred_class[:,i]=mdl.predict(X)\n",
    "        eval_pred_proba[:,:,i]=eval_proba\n",
    "    if mode == 'mean':\n",
    "        # average the probabilities (for class=1) and return the mean predicted probability\n",
    "        prediction = np.mean(eval_pred_proba[:,1,:],axis=1)\n",
    "        #eval_pred_proba[:,1,:].mean(axis=2)\n",
    "\n",
    "    elif mode == 'class': # return the desired class prediction\n",
    "        prediction = map(np.int,eval_pred_class.mean(axis=1))\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "MODEL_BASE_PATH = '/home/hrsepara/work/model/'\n",
    "#MODEL_BASE_PATH = 'C:\\\\Users\\\\kesj\\\\code\\\\hrsep1\\\\model_1\\\\'\n",
    "pred_cases = ['sep/','ret/']\n",
    "pred_years = map(np.str,np.arange(1,6))\n",
    "\n",
    "sep_proba_df = apply_time_models(X,MODEL_BASE_PATH,pred_cases[0],pred_years)\n",
    "ret_proba_df = apply_time_models(X,MODEL_BASE_PATH,pred_cases[1],pred_years)\n",
    "#sep_proba_df.index=employee_df.KEY\n",
    "#ret_proba_df.index=employee_df.KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sep_proba_df), len(ret_proba_df), len(employee_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feb 9, 2016 Assess these predictions\n",
    "* for separation:\n",
    "    1. calculate total number of separations in next 5 years\n",
    "    2. calculate total number for each of the specific jobGrADE, etc. listed in previous email.\n",
    "    \n",
    "* for retirement:\n",
    "    1. calculate total number of retirements (restrict to those overX)\n",
    "    2. compare to sf model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEPARATION ASSESSMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a dictionary for some of these 'interesting' jobs\n",
    "#### December 31, 2015\n",
    "\n",
    "* The extended Functions (EXT_FUNC_ID_SFI) Jeff Briks is interested in are:\n",
    "    * CCC Sales (00892)\n",
    "    * CCC Service (00071)\n",
    "    * Life Health Response Center (00816)\n",
    "    * Enterprise Auto Express (00909)\n",
    "    * Enterprise ILR (00910)\n",
    "    * State Farm Bank (00517)\n",
    "    * SFPP (00835)\n",
    "* The jobs (JOBCODES) he is interested in are these:\n",
    "    * CCC Service Rep (6200)\n",
    "    * CCC Sales Rep (1876)\n",
    "    * Life Customer Service Asst (2638, 2639, & 2641)\n",
    "    * Claim Associate-Express (0983 & 0984)\n",
    "    * Claim Associate-ILR (1009)\n",
    "    * Claim Team Manager – ILR (0986)\n",
    "    * Bank Customer Service Rep (0851, 852, & 0853)\n",
    "    * SFPP Account Rep (4105)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#interesting_extended_functions = [892,71, 816, 909,910,517,835]\n",
    "extFuncDict ={}\n",
    "extFuncDict[892]='CCC Sales'\n",
    "extFuncDict[71]='CCC Service'\n",
    "extFuncDict[816]='Life Health Response Center'\n",
    "#(00816)\n",
    "extFuncDict[909]='Enterprise Auto Express'\n",
    "extFuncDict[910]='Enterprise ILR' \n",
    "extFuncDict[517]='State Farm Bank'\n",
    "extFuncDict[835]='SFPP'\n",
    "interesting_extended_functions = extFuncDict.keys()\n",
    "extFuncDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobCodeDict = {}\n",
    "jobCodeDict[6200]= 'CCC Service Rep'\n",
    "jobCodeDict[1876]= 'CCC Sales Rep'\n",
    "jobCodeDict[1009]='CLaim Associate-ILR'\n",
    "jobCodeDict[986]='CLaim Team Manager-ILR'\n",
    "jobCodeDict[983]='Claim Associate-Express'\n",
    "jobCodeDict[984]='Claim Associate-Express'\n",
    "jobCodeDict[2638]='Life Customer Service Asst'\n",
    "jobCodeDict[2639]='Life Customer Service Asst'\n",
    "jobCodeDict[2641]='Life Customer Service Asst'\n",
    "jobCodeDict[4105]= 'SFPP Account Rep'\n",
    "jobCodeDict[851]= 'Bank Customer Service Rep'\n",
    "jobCodeDict[852]= 'Bank Customer Service Rep'\n",
    "jobCodeDict[853]= 'Bank Customer Service Rep'\n",
    "interesting_jobcodes =  jobCodeDict.keys()\n",
    "jobCodeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(sep_proba_df)\n",
    "sep_proba_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(current) \n",
    "ctemp = current[['KEY','Age_years','Tenure_years','JOBCODE','EXT_FUNC_ID_SFI']].copy()\n",
    "ctemp.index =np.arange(0,len(ctemp))\n",
    "ctemp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep_df = pd.concat([ctemp,sep_proba_df],axis=1)\n",
    "print len(sep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Counts of Separation:\n",
    "* Method 1: sum : `sep_proba_df.sum() ` \n",
    "* Method 2: over threshhold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map(np.int, sep_proba_df.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "sep_proba_df.applymap(lambda x: 1 if x>thresh else 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess the model validity using the testing set (from 10/6/15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2eval = pd.read_csv('/home/kesj/work/hrsepara/proc/trans_train.csv')\n",
    "[col for col in em2eval.columns.tolist() if col.endswith('DT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[col for col in em2eval.columns.tolist() if col.endswith('tstmp')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### okay re-form the split to get the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print em2002.shape\n",
    "from sklearn.cross_validation import train_test_split\n",
    "print \"Starting with subest of {0} employees.\".format(len(em2002))\n",
    "eval_fraction = 0.20\n",
    "em2build, em2eval = train_test_split(em2002,test_size=eval_fraction,random_state=83221)\n",
    "print \"Evaluation set has {0} employees; training set has {1} employees.\".format(len(em2eval),len(em2build))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try to evaluate the mdls on em2eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2eval_df = em2eval[columns_for_modeling].copy()\n",
    "em2eval_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix the dollar amounts\n",
    "min_sal1 = 17621.76 #(based upon training set I have: 5 %tile cut off)\n",
    "min_min_rt_ann = 17900. # same as above\n",
    "min_max_rt_ann = 33155.70\n",
    "\n",
    "max_max_rt_ann = 133068.91\n",
    "min_merit1 = 0.0\n",
    "min_perf1 = 0.0\n",
    "fix_min_outlier_col_dict = {'SAL1': min_sal1, 'MERIT1': min_merit1, 'PERF1': min_perf1}\n",
    "fix_max_outlier_col_dict = {'MAX_RT_ANNUAL': max_max_rt_ann}\n",
    "\n",
    "# replace these values\n",
    "for key,value in fix_min_outlier_col_dict.iteritems():        \n",
    "    idx_to_replace = em2eval_df[em2eval_df[key]<value].index\n",
    "    em2eval_df.loc[idx_to_replace,key]=value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sum(em2eval_df.SAL1 != em2eval.SAL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em2eval_df['birth_tstmp']= em2eval['birth_tstmp'].apply(lambda x: pd.to_datetime(x))\n",
    "em2eval_df['hire_tstmp']= em2eval['hire_tstmp'].apply(lambda x: pd.to_datetime(x))\n",
    "em2eval_df['status']=em2eval['status']\n",
    "em2eval_df['Age_years']=em2eval['Age_years']\n",
    "em2eval_df['Tenure_years']=em2eval['Tenure_years']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adjust_eval_by_x_years(df,year_val,modeling_columns,tstmp_cols=['birth_tstmp','hire_tstmp'],target_col='status'):\n",
    "    # construct\n",
    "  \n",
    "    ## set up method to assess the eval set\n",
    "    print \"There are {0} elements in the evaluation set\".format(len(df))\n",
    "   \n",
    "    print \"original target variable value counts:\", df[target_col].value_counts()\n",
    "    # restructure to deal with time_frame retirement (target variable)\n",
    "    yr_cut_val = year_val+0.5\n",
    "    # index of those that actually accomplish target within timeframe (allow 0.5 additional years)\n",
    "    eval_within_time_target_index = df[(df[target_col]==1) & (df.Tenure_years <= yr_cut_val)].index\n",
    "    # exclude indices that are active and have tenure less than this time\n",
    "    eval_excluded_index = df[(df[target_col]==0) & (df.Tenure_years  <= yr_cut_val)].index\n",
    "    \n",
    "    # the rest become my not-terminated set\n",
    "    eval_active_index = set(df.index) - set(eval_within_time_target_index) - set(eval_excluded_index)\n",
    "    print len(eval_excluded_index),len(eval_within_time_target_index), len(eval_active_index)\n",
    "    eval_idx_to_use =df.ix[set(df.index)-set(eval_excluded_index)].index\n",
    "    #len(eval_idx_to_use)\n",
    "    # reset the target to 0 for active\n",
    "    eval_new_target = df[target_col].copy()\n",
    "    eval_new_target.ix[eval_active_index] = 0\n",
    "    print \"new target variable value counts: \"\n",
    "    print eval_new_target.ix[eval_idx_to_use].value_counts()\n",
    "    print \"_____\"\n",
    "    y_eval = eval_new_target.ix[eval_idx_to_use].as_matrix().astype(np.int) # true values\n",
    "    eval_adj_tenure = df.ix[eval_idx_to_use].Tenure_years.apply(lambda x: x-year_val if (x>float(year_val)) else 0).values\n",
    "    print len(eval_adj_tenure), len(y_eval)\n",
    "    # now adjust age by length of time; use hire_age if not in set to use.\n",
    "    eval_adj_age = df.ix[eval_idx_to_use].Age_years.apply(lambda x: x-year_val)\n",
    "    hire_age = (df.ix[eval_within_time_target_index]['birth_tstmp']-df.ix[eval_within_time_target_index]['hire_tstmp'])/np.timedelta64(1,'Y')#.days/days_in_year\n",
    "    eval_adj_age.ix[eval_within_time_target_index] = hire_age #df.ix[eval_within_time_target_index]['birth_tstmp'#df_dates['hire_age']\n",
    "    \n",
    "    # construct the evaluation X matrix\n",
    "    print \"input matrix has {0} features\".format(len(modeling_columns))\n",
    "    Xeval = np.zeros((len(eval_idx_to_use),len(modeling_columns)))\n",
    "    # drop 'Age_years' and Tenure_years from the list\n",
    "    cols_to_use = []\n",
    "    cols_to_use+=modeling_columns\n",
    "    cols_to_use.remove('Age_years')\n",
    "    cols_to_use.remove('Tenure_years')#.copy()\n",
    "    \"\"\"\n",
    "    Xeval[:,:-2] = df.ix[eval_idx_to_use][cols_to_use].as_matrix().astype(np.float)\n",
    "    # now put the adjusted tenure and ages into this matrix\n",
    "    Xeval[:,-2] = eval_adj_age.values\n",
    "    Xeval[:,-1]=eval_adj_tenure\n",
    "    #print len(modeling_columns),np.shape(Xeval)\n",
    "    \"\"\"\n",
    "    # this version matches the changed ording of columns\n",
    "    Xeval[:,0]=eval_adj_age.values\n",
    "    Xeval[:,1]=eval_adj_tenure\n",
    "    Xeval[:,2:] = df.ix[eval_idx_to_use][cols_to_use].as_matrix().astype(np.float)\n",
    "    return Xeval, y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xe5,y5 =adjust_eval_by_x_years(em2eval_df,5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODEL_BASE_PATH = '/home/hrsepara/work/model/'\n",
    "#MODEL_BASE_PATH = 'C:\\\\Users\\\\kesj\\\\code\\\\hrsep1\\\\model_1\\\\'\n",
    "pred_cases = ['sep/','ret/']\n",
    "pred_years = map(np.str,np.arange(1,6))\n",
    "\n",
    "#eval_sep_proba_df = apply_time_models(Xe5,MODEL_BASE_PATH,pred_cases[0],pred_years)\n",
    "eval_sep_proba5_df = apply_time_models(Xe5,MODEL_BASE_PATH,pred_cases[0],['5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(eval_sep_proba5_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etemp = em2eval[['KEY','Age_years','Tenure_years','JOBCODE','EXT_FUNC_ID_SFI','status']].copy()\n",
    "etemp.index =np.arange(0,len(etemp))\n",
    "#etemp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "esep_df5 = pd.concat([etemp,eval_sep_proba5_df],axis=1)\n",
    "print len(esep_df5), len(y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def plot_conf_matrix(y_true,y_pred,normed=True,**kwargs):\n",
    "    my_c = metrics.confusion_matrix(y_true,y_pred)\n",
    "    \n",
    "    print metrics.matthews_corrcoef(y_true,y_pred)\n",
    "    if normed:\n",
    "        cm_normalized = my_c.astype('float') / my_c.sum(axis=1)[:, np.newaxis]\n",
    "        my_c = cm_normalized\n",
    "        plt.title('Normalized RF Classifier Confusion Matrix')\n",
    "    else:\n",
    "        plt.title('Random Forest Classifier Confusion Matrix')\n",
    "        \n",
    "    sns.heatmap(my_c, annot=True,  fmt='',cmap='Blues')\n",
    "    plt.ylabel('True')\n",
    "    #plt.yticks\n",
    "    plt.xlabel('Assigned')\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_roc_curve2(target_test, target_predicted_proba, **kwargs):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target_test, target_predicted_proba)\n",
    "    \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    label_txt = 'ROC curve (area = %0.3f)' % roc_auc\n",
    "    plt.plot(fpr, tpr, label=label_txt,**kwargs)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve2(y5,eval_sep_proba5_df.sep5yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y5, eval_sep_proba5_df.sep5yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(tpr - fpr,'d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydiff = tpr-fpr\n",
    "max(mydiff)\n",
    "#thresholds[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholds[np.where(mydiff == max(mydiff))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5,np.map())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(fpr, tpr)\n",
    "plt.scatter(fpr[np.where(tpr>=0.99)],tpr[np.where(tpr>=0.99)],color='indianred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholds[np.where(tpr >= 0.99)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(eval_sep_proba5_df.sep5yr>thresh).values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_sep_proba5_df.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_sep_proba4_df.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_sep_proba3_df.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_sep_proba2_df.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_sep_proba1_df.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcc_scores = []\n",
    "mcc_offsets = []\n",
    "for offset in np.arange(0,10)/float(10):\n",
    "    #offset+=0.6\n",
    "    score = metrics.matthews_corrcoef(y5,map(np.int,eval_sep_proba5_df.sep5yr+offset))\n",
    "    print offset,\":: \", score\n",
    "    mcc_scores.append(score)\n",
    "    mcc_offsets.append(offset)\n",
    "    \n",
    "plt.scatter(mcc_offsets,mcc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcc_offsets[mcc_scores.index(max(mcc_scores))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcc_5_scores = []\n",
    "mcc_5_offsets = []\n",
    "for offset in np.arange(0,20)/float(100):\n",
    "    offset+=0.6\n",
    "    score = metrics.matthews_corrcoef(y5,map(np.int,eval_sep_proba5_df.sep5yr+offset))\n",
    "    print offset,\":: \", score\n",
    "    mcc_5_scores.append(score)\n",
    "    mcc_5_offsets.append(offset)\n",
    "    \n",
    "plt.scatter(mcc_5_offsets,mcc_5_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5,map(np.int,eval_sep_proba5_df.sep5yr+0.69),normed=False)#gb_mdl5_pred_class.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ytest1 = eval_sep_proba5_df.sep5yr\n",
    "ytest2 = map(np.int,eval_sep_proba5_df.sep5yr)\n",
    "ytest3 = eval_sep_proba5_df.sep5yr.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_type = type(ytest2)\n",
    "print my_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(y4)\n",
    "r5= [x/100000. for x in random.sample(range(0,100000),len(y5))]#/10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(y_true,y_pred,normed=True, heatmap_color ='Blues', **kwargs):\n",
    "\n",
    "    ## check to make sure that y_pred is an array of integers if y_true is a bunch of integers\n",
    "    true_int_check = all(isinstance(a,int) for a in y_true)\n",
    "    pred_int_check = all(isinstance(a,int) for a in y_pred)\n",
    "    if true_int_check and not pred_int_check: # convert the y_pred values to integers\n",
    "        if isinstance(y_pred,pd.Series):\n",
    "            y_pred = y_pred.astype(int)\n",
    "\n",
    "    my_c = metrics.confusion_matrix(y_true,y_pred)\n",
    "\n",
    "    print metrics.matthews_corrcoef(y_true,y_pred)\n",
    "    if normed:\n",
    "        cm_normalized = my_c.astype('float') / my_c.sum(axis=1)[:, np.newaxis]\n",
    "        my_c = cm_normalized\n",
    "        plt.title('Normalized RF Classifier Confusion Matrix')\n",
    "    else:\n",
    "        plt.title('Random Forest Classifier Confusion Matrix')\n",
    "\n",
    "    sns.heatmap(my_c, annot=True,  fmt='',cmap=heatmap_color)\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Assigned')\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5,ytest1+0.3,normed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5,map(np.int,eval_sep_proba5_df.sep5yr+0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isinstance(ytest1,list),isinstance(ytest2,list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(eval_sep_proba5_df.sep5yr+0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off5 = 0.69\n",
    "(eval_sep_proba5_df.sep5yr+off5).values.astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(sep_df.sep5yr+off5).values.astype(int).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REPEAT for 1,2,3,4 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xe4,y4 =adjust_eval_by_x_years(em2eval_df,4,columns_for_modeling)\n",
    "print len(Xe4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODEL_BASE_PATH = '/home/hrsepara/work/model/'\n",
    "#MODEL_BASE_PATH = 'C:\\\\Users\\\\kesj\\\\code\\\\hrsep1\\\\model_1\\\\'\n",
    "pred_cases = ['sep/','ret/']\n",
    "pred_years = map(np.str,np.arange(1,6))\n",
    "\n",
    "#eval_sep_proba_df = apply_time_models(Xe5,MODEL_BASE_PATH,pred_cases[0],pred_years)\n",
    "eval_sep_proba4_df = apply_time_models(Xe4,MODEL_BASE_PATH,pred_cases[0],['4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve2(y4,eval_sep_proba4_df.sep4yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=76368, number of events=31927\n",
      "\n",
      "                       coef  exp(coef)  se(coef)          z          p  lower 0.95  upper 0.95     \n",
      "Age_years        -9.386e-01  3.912e-01 1.023e-02 -9.175e+01  0.000e+00  -9.587e-01  -9.185e-01  ***\n",
      "SAL1             -1.115e+00  3.278e-01 1.479e-02 -7.539e+01  0.000e+00  -1.144e+00  -1.086e+00  ***\n",
      "MERIT1            2.742e-01  1.315e+00 6.343e-03  4.323e+01  0.000e+00   2.618e-01   2.866e-01  ***\n",
      "PERF1            -1.016e-01  9.034e-01 1.240e-02 -8.195e+00  2.514e-16  -1.259e-01  -7.730e-02  ***\n",
      "BOX1             -4.839e-01  6.164e-01 6.824e-03 -7.090e+01  0.000e+00  -4.972e-01  -4.705e-01  ***\n",
      "SEX               1.643e-01  1.179e+00 6.098e-03  2.695e+01 5.826e-160   1.524e-01   1.763e-01  ***\n",
      "HAVE_INS         -3.066e-01  7.359e-01 9.072e-03 -3.380e+01 1.975e-250  -3.244e-01  -2.888e-01  ***\n",
      "HAVE_DEP         -2.326e-01  7.925e-01 1.147e-02 -2.027e+01  2.258e-91  -2.550e-01  -2.101e-01  ***\n",
      "DEPTCNT1         -3.471e-01  7.068e-01 9.569e-03 -3.627e+01 4.495e-288  -3.658e-01  -3.283e-01  ***\n",
      "EXTFUNC_CNT       9.591e-02  1.101e+00 5.597e-03  1.713e+01  8.204e-66   8.494e-02   1.069e-01  ***\n",
      "FUNC_CNT         -1.504e-01  8.603e-01 8.158e-03 -1.844e+01  6.098e-76  -1.664e-01  -1.344e-01  ***\n",
      "REMOTE           -1.546e-01  8.567e-01 1.116e-02 -1.386e+01  1.179e-43  -1.765e-01  -1.328e-01  ***\n",
      "DIRECT_RPT_CNT    1.569e-01  1.170e+00 3.968e-03  3.955e+01  0.000e+00   1.491e-01   1.647e-01  ***\n",
      "HUBIND           -8.338e-02  9.200e-01 6.762e-03 -1.233e+01  6.280e-35  -9.663e-02  -7.012e-02  ***\n",
      "REH_CNT          -2.330e-01  7.921e-01 6.523e-03 -3.572e+01 1.758e-279  -2.458e-01  -2.202e-01  ***\n",
      "JOB_FUNCTION_PSA -7.550e-02  9.273e-01 6.798e-03 -1.111e+01  1.179e-28  -8.883e-02  -6.217e-02  ***\n",
      "---\n",
      "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n",
      "\n",
      "Concordance = 0.887\n"
     ]
    }
   ],
   "source": [
    "sep_mdl.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(eval_sep_proba4_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_max_f1_value(ytrue,ypred):\n",
    "    scores = []\n",
    "    offsets = []\n",
    "    # stage 1:\n",
    "    for offset in np.arange(0,10)/float(10):\n",
    "        score = metrics.f1_score(ytrue,map(np.int,ypred+offset))\n",
    "        scores.append(score)\n",
    "        offsets.append(offset)\n",
    "    # find the max\n",
    "    mxscore = max(scores)\n",
    "    mx_idx = scores.index(mxscore)\n",
    "    #now offset below and above\n",
    "    if mx_idx == 0:\n",
    "        for offset in np.arange(0,16)/float(100):\n",
    "            offset+=0.0\n",
    "            score = metrics.f1_score(ytrue,map(np.int,ypred+offset))\n",
    "            scores.append(score)\n",
    "            offsets.append(offset)\n",
    "    elif mx_idx == 9:\n",
    "        for offset in np.arange(0,21)/float(100):\n",
    "            offset+=0.8\n",
    "            score = metrics.f1_score(ytrue,map(np.int,ypred+offset))\n",
    "            scores.append(score)\n",
    "            offsets.append(offset)\n",
    "    else:\n",
    "        base_offset = offsets[mx_idx-1]\n",
    "        for offset in np.arange(0,21)/float(100):\n",
    "            offset+=base_offset\n",
    "            score = metrics.f1_score(ytrue,map(np.int,ypred+offset))\n",
    "            scores.append(score)\n",
    "            offsets.append(offset)\n",
    "            \n",
    "    #if m\n",
    "    #for offset in np.arange(0,20)/float(100):\n",
    "    #    offset+=0.6\n",
    "    #\n",
    "    #print offset,\":: \", score\n",
    "    #\n",
    "    #mcc_5_offsets.append(offset)\n",
    "    plt.scatter(offsets,scores,color='midnightblue')\n",
    "    plt.xlabel('offset value')\n",
    "    plt.ylabel('F1 score')\n",
    "    \n",
    "    mxmxscore = max(scores)\n",
    "    mxmx_idx = scores.index(mxmxscore)\n",
    "    print mxmxscore, offsets[mxmx_idx]\n",
    "    #return mcc_scores, mcc_offsets\n",
    "    return offsets[mxmx_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_max_mcc_value(ytrue,ypred):\n",
    "    mcc_scores = []\n",
    "    mcc_offsets = []\n",
    "    # stage 1:\n",
    "    for offset in np.arange(0,10)/float(10):\n",
    "        score = metrics.matthews_corrcoef(ytrue,map(np.int,ypred+offset))\n",
    "        mcc_scores.append(score)\n",
    "        mcc_offsets.append(offset)\n",
    "    # find the max\n",
    "    mxscore = max(mcc_scores)\n",
    "    mx_idx = mcc_scores.index(mxscore)\n",
    "    #now offset below and above\n",
    "    if mx_idx == 0:\n",
    "        for offset in np.arange(0,11)/float(100):\n",
    "            offset+=0.0\n",
    "            score = metrics.matthews_corrcoef(ytrue,map(np.int,ypred+offset))\n",
    "            mcc_scores.append(score)\n",
    "            mcc_offsets.append(offset)\n",
    "    elif mx_idx == 9:\n",
    "        for offset in np.arange(0,11)/float(100):\n",
    "            offset+=0.9\n",
    "            score = metrics.matthews_corrcoef(ytrue,map(np.int,ypred+offset))\n",
    "            mcc_scores.append(score)\n",
    "            mcc_offsets.append(offset)\n",
    "    else:\n",
    "        base_offset = mcc_offsets[mx_idx-1]\n",
    "        for offset in np.arange(0,21)/float(100):\n",
    "            offset+=base_offset\n",
    "            score = metrics.matthews_corrcoef(ytrue,map(np.int,ypred+offset))\n",
    "            mcc_scores.append(score)\n",
    "            mcc_offsets.append(offset)\n",
    "            \n",
    "    #if m\n",
    "    #for offset in np.arange(0,20)/float(100):\n",
    "    #    offset+=0.6\n",
    "    #\n",
    "    #print offset,\":: \", score\n",
    "    #\n",
    "    #mcc_5_offsets.append(offset)\n",
    "    plt.scatter(mcc_offsets,mcc_scores)\n",
    "    plt.xlabel('offset value')\n",
    "    plt.ylabel('mcc score')\n",
    "    \n",
    "    mxmxscore = max(mcc_scores)\n",
    "    mxmx_idx = mcc_scores.index(mxmxscore)\n",
    "    print mxmxscore, mcc_offsets[mxmx_idx]\n",
    "    #return mcc_scores, mcc_offsets\n",
    "    return mcc_offsets[mxmx_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off4 = find_max_mcc_value(y4,eval_sep_proba4_df.sep4yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off4f = find_max_f1_value(y4,eval_sep_proba4_df.sep4yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off5f = find_max_f1_value(y5,eval_sep_proba5_df.sep5yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off5 = find_max_mcc_value(y5,eval_sep_proba5_df.sep5yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y4,map(np.int,eval_sep_proba4_df.sep4yr+off4),normed=False)\n",
    "#plt.title('4 year')\n",
    "print \"4 year\"\n",
    "print sum(map(np.int, eval_sep_proba4_df.sep4yr+off4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(sep_df.sep4yr+off4).values.astype(int).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xe3,y3 =adjust_eval_by_x_years(em2eval_df,3,columns_for_modeling)\n",
    "\n",
    "print \"______________\"\n",
    "#MODEL_BASE_PATH = '/home/hrsepara/work/model/'\n",
    "#MODEL_BASE_PATH = 'C:\\\\Users\\\\kesj\\\\code\\\\hrsep1\\\\model_1\\\\'\n",
    "#pred_cases = ['sep/','ret/']\n",
    "#pred_years = map(np.str,np.arange(1,6))\n",
    "\n",
    "#eval_sep_proba_df = apply_time_models(Xe5,MODEL_BASE_PATH,pred_cases[0],pred_years)\n",
    "eval_sep_proba3_df = apply_time_models(Xe3,MODEL_BASE_PATH,pred_cases[0],['3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve2(y3,eval_sep_proba3_df.sep3yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off3 = find_max_mcc_value(y3,eval_sep_proba3_df.sep3yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off3f = find_max_f1_value(y3,eval_sep_proba3_df.sep3yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y3,map(np.int,eval_sep_proba3_df.sep3yr+off3),normed=False)\n",
    "#plt.title('4 year')\n",
    "print \"3 year\"\n",
    "print sum(map(np.int, eval_sep_proba3_df.sep3yr+off3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(sep_df.sep3yr+off3).values.astype(int).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xe2,y2 =adjust_eval_by_x_years(em2eval_df,2,columns_for_modeling)\n",
    "\n",
    "print \"______________\"\n",
    "#MODEL_BASE_PATH = '/home/hrsepara/work/model/'\n",
    "#MODEL_BASE_PATH = 'C:\\\\Users\\\\kesj\\\\code\\\\hrsep1\\\\model_1\\\\'\n",
    "#pred_cases = ['sep/','ret/']\n",
    "#pred_years = map(np.str,np.arange(1,6))\n",
    "\n",
    "#eval_sep_proba_df = apply_time_models(Xe5,MODEL_BASE_PATH,pred_cases[0],pred_years)\n",
    "eval_sep_proba2_df = apply_time_models(Xe2,MODEL_BASE_PATH,pred_cases[0],['2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve2(y2,eval_sep_proba2_df.sep2yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off2 = find_max_mcc_value(y2,eval_sep_proba2_df.sep2yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off2f = find_max_f1_value(y2,eval_sep_proba2_df.sep2yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y2,map(np.int,eval_sep_proba2_df.sep2yr+off2),normed=False)\n",
    "#plt.title('4 year')\n",
    "print \"2 year\"\n",
    "print sum(map(np.int, eval_sep_proba2_df.sep2yr+off2))\n",
    "print \" Number of separations predicted is \",(sep_df.sep2yr+off2).values.astype(int).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xe1,y1 =adjust_eval_by_x_years(em2eval_df,1,columns_for_modeling)\n",
    "\n",
    "print \"______________\"\n",
    "#MODEL_BASE_PATH = '/home/hrsepara/work/model/'\n",
    "#MODEL_BASE_PATH = 'C:\\\\Users\\\\kesj\\\\code\\\\hrsep1\\\\model_1\\\\'\n",
    "#pred_cases = ['sep/','ret/']\n",
    "#pred_years = map(np.str,np.arange(1,6))\n",
    "\n",
    "#eval_sep_proba_df = apply_time_models(Xe5,MODEL_BASE_PATH,pred_cases[0],pred_years)\n",
    "eval_sep_proba1_df = apply_time_models(Xe1,MODEL_BASE_PATH,pred_cases[0],['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve2(y1,eval_sep_proba1_df.sep1yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off1 = find_max_mcc_value(y1,eval_sep_proba1_df.sep1yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off1f = find_max_f1_value(y1,eval_sep_proba1_df.sep1yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y1,map(np.int,eval_sep_proba1_df.sep1yr+off1),normed=False)\n",
    "#plt.title('4 year')\n",
    "print \"1 year\"\n",
    "print sum(map(np.int, eval_sep_proba1_df.sep1yr+off1))\n",
    "print \" Number of separations predicted is \",(sep_df.sep1yr+off1).values.astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_proba_df.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1_offsets = [off1f,off2f,off3f,off4f,off5f]\n",
    "f1_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(sep_proba_df+f1_offsets).values.astype(int).sum(axis=0)\n",
    "#print \" Number of separations predicted is \",(sep_df.sep1yr+off1).values.astype(int).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now check for the specific jobcodes & extended functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## count how many examples in the current dataframe\n",
    "[(v,len(sep_df[sep_df.EXT_FUNC_ID_SFI==k])) for k,v in extFuncDict.iteritems()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extFuncDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_pred_cols = ['sep1yr','sep2yr','sep3yr','sep4yr','sep5yr']\n",
    "ext_val = 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val])\n",
    "(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val][sep_pred_cols]+f1_offsets).values.astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ext_val = 517\n",
    "print extFuncDict[ext_val]\n",
    "print len(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val])\n",
    "(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val][sep_pred_cols]+f1_offsets).values.astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ext_val = 892\n",
    "print extFuncDict[ext_val]\n",
    "print len(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val])\n",
    "(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val][sep_pred_cols]+f1_offsets).values.astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ext_val = 816\n",
    "print extFuncDict[ext_val]\n",
    "print len(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val])\n",
    "(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val][sep_pred_cols]+f1_offsets).values.astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ext_val = 909\n",
    "print extFuncDict[ext_val]\n",
    "print len(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val])\n",
    "(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val][sep_pred_cols]+f1_offsets).values.astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ext_val = 910\n",
    "print extFuncDict[ext_val]\n",
    "print len(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val])\n",
    "(sep_df[sep_df.EXT_FUNC_ID_SFI==ext_val][sep_pred_cols]+f1_offsets).values.astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "invJobCodeDict = {}\n",
    "invJobCodeDict['CCC Service Rep'] = [6200]\n",
    "invJobCodeDict['CCC Sales Rep'] = [1876]\n",
    "invJobCodeDict['Life Customer Service Asst'] = [2638,2639,2641]\n",
    "invJobCodeDict['Claim Associate-Express'] = [983,984]\n",
    "invJobCodeDict['Claim Associate-ILR'] = [1009]\n",
    "invJobCodeDict['Claim Team Manager-ILR'] = [986]\n",
    "invJobCodeDict['Bank Customer Service Rep'] = [851,852,853]\n",
    "invJobCodeDict['SFPP Account Rep'] = [4105]#2638,2639,2641]\n",
    "interest_job_names_list = invJobCodeDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in invJobCodeDict.keys():\n",
    "    print k, sum(sep_df['JOBCODE'].isin(invJobCodeDict[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jc_val = 'CCC Service Rep'\n",
    "print invJobCodeDict[jc_val]\n",
    "print len(sep_df[sep_df.JOBCODE.isin(invJobCodeDict[jc_val])])\n",
    "pred_vals = (sep_df[sep_df.JOBCODE.isin(invJobCodeDict[jc_val])][sep_pred_cols]+f1_offsets).values.astype(int).sum(axis=0)\n",
    "for v in pred_vals:\n",
    "    print \"predicted separation count in 1 years = \",v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for jc_val in invJobCodeDict.keys():\n",
    "    print \"----\"\n",
    "    print invJobCodeDict[jc_val]\n",
    "    print jc_val\n",
    "    print len(sep_df[sep_df.JOBCODE.isin(invJobCodeDict[jc_val])])\n",
    "    pred_vals = (sep_df[sep_df.JOBCODE.isin(invJobCodeDict[jc_val])][sep_pred_cols]+f1_offsets).values.astype(int).sum(axis=0)\n",
    "    for v in pred_vals:\n",
    "        print \"predicted separation count in 1 years = \",v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## now check on the rates of retirements for each of the coming years\n",
    "* calculate the total number of retirements and rate of retirement.\n",
    "    * option 1: sum the probabilities\n",
    "    * option 2: apply a threshold and sum in binary way.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the survival model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_survival_models(df,MDL_BASE_PATH,pkl_name,pred_years):\n",
    "\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    mdl_name = MDL_BASE_PATH+pkl_name\n",
    "\n",
    "\n",
    "    try:\n",
    "        stored_mdl = pickle.load(open(mdl_name,'rb'))\n",
    "        #stored_mdl = jl.load(mdl_name)\n",
    "\n",
    "        sf_pred = stored_mdl.predict_survival_function(df)\n",
    "        sf_pred.index.name='years'\n",
    "        sf_pred.reset_index(inplace=True)\n",
    "        pred_proba = get_survival_prediction(df,sf_pred,yr_vals=pred_years)\n",
    "\n",
    "    except IOError:\n",
    "        print \"requested pickle file not found {0}, using default parameters.\".format(mdl_name)\n",
    "        # TODO create default predictions from simple Survival model for retirement.\n",
    "        pred_proba = pd.DataFrame()\n",
    "\n",
    "    return pred_proba\n",
    "\n",
    "\n",
    "#Define a function to calculate the survival prediction from a pickled model\n",
    "def get_survival_prediction(edf,psf, age_col='Age_years',yr_vals=[1,2,3,4,5]):\n",
    "    from scipy import interpolate\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    pred_col_names = ['proba_'+str(y) for y in yr_vals]\n",
    "    df = pd.DataFrame(index=edf.index, columns=pred_col_names, dtype=float)\n",
    "    print pred_col_names\n",
    "    for employee_id,age in enumerate(edf['Age_years']):\n",
    "        if employee_id % 5000 ==0 :\n",
    "            print employee_id, age\n",
    "\n",
    "        prob_vals =np.ones((len(yr_vals),))\n",
    "        if age >= 50.0: # only deal with over 50\n",
    "            for idx, year in enumerate(yr_vals):\n",
    "                ck_yr = age+year\n",
    "                try:\n",
    "                    prior_idx = np.where(psf.years < ck_yr)[0][-1]\n",
    "                    posterior_idx = np.where(psf.years > ck_yr)[0][0]\n",
    "\n",
    "                    x = [psf.ix[prior_idx]['years'], psf.ix[posterior_idx]['years']]\n",
    "                    y = [psf.ix[prior_idx][employee_id+1], psf.ix[posterior_idx][employee_id+1]]\n",
    "                    # there is an extra column in my processing\n",
    "                    # now interpolate these\n",
    "                    y_interp = interpolate.interp1d(x,y)\n",
    "                    proba = y_interp(ck_yr)\n",
    "                except IndexError:\n",
    "                    proba = psf.ix[np.where(psf.years == ck_yr)[0]][employee_id+1]\n",
    "\n",
    "                prob_vals[idx] = proba\n",
    "\n",
    "        df.loc[edf.index[employee_id]]=prob_vals\n",
    "    df.fillna(1.0,inplace=True)  # fill in missing values with ones\n",
    "    df[df<0] = 0.0  # replace negative probabilities with zero\n",
    "\n",
    "    return 1-df  # convert to probability of retirement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cover50 = employee_df[employee_df.Age_years>=50].copy()\n",
    "len(cover50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cover50['hire_age'] = current[current.Age_years>=50].hire_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cover50.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arange(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sfret_pred = apply_survival_models(cover50,MODEL_BASE_PATH,'retirement_sfA.pkl',np.arange(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sfret_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to develop an independent assessment using the evaluation sets above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "over50eval = em2eval_df[em2eval.Age_years>=50].copy()\n",
    "len(over50eval)\n",
    "over50eval['hire_age'] = (over50eval['hire_tstmp']-over50eval['birth_tstmp'])/np.timedelta64(1,'Y')\n",
    "over50eval['retired']=em2eval[em2eval.Age_years>=50]['retired']\n",
    "#Xe5,y5 =adjust_eval_by_x_years(em2eval_df,5,columns_for_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(over50eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "over50eval.retired.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(over50eval.retired,over50eval.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get rid of those that are status==1 and retired == 0 --> just classifying on retired or not\n",
    "over50eval = over50eval[~((over50eval.retired==0)&(over50eval.status==1))]\n",
    "len(over50eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cover50.columns\n",
    "sfret_pred_eval_set = apply_survival_models(over50eval[cover50.columns],MODEL_BASE_PATH,'retirement_sfA.pkl',np.arange(1,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now assess the accuracy for each year based upon this evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sfret_pred_eval_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sfret_pred_eval_set['retired']=over50eval['retired']\n",
    "sfret_pred_eval_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sfret_pred_eval_set['term_tstmp'] = em2eval.ix[sfret_pred_eval_set.index]['term_tstmp']\n",
    "sfret_pred_eval_set[sfret_pred_eval_set['term_tstmp']!='2015-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sfret_pred_eval_set.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ret_off1f = find_max_f1_value(sfret_pred_eval_set.retired,sfret_pred_eval_set.proba_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ret_off2f = find_max_f1_value(sfret_pred_eval_set.retired,sfret_pred_eval_set.proba_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ret_off3f = find_max_f1_value(sfret_pred_eval_set.retired,sfret_pred_eval_set.proba_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ret_off4f = find_max_f1_value(sfret_pred_eval_set.retired,sfret_pred_eval_set.proba_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ret_off5f = find_max_f1_value(sfret_pred_eval_set.retired,sfret_pred_eval_set.proba_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(sfret_pred_eval_set.retired,map(np.int,sfret_pred_eval_set.proba_1+0.94),normed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret_offsets = [ret_off1f,ret_off2f,ret_off3f,ret_off4f,ret_off5f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(sfret_pred_eval_set[['proba_1','proba_2','proba_3','proba_4','proba_5']]+ret_offsets).values.astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying retirement directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "retirement_mdl = pickle.load(open(MODEL_BASE_PATH+'retirement_sfA.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retire_pred = retirement_mdl.predict_expectation(over50eval[cover50.columns])\n",
    "retire_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retire_pred.rename(columns={0:'pred_retire_age'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retire_pred[['Age_years','retired']]=over50eval[['Age_years','retired']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual_retired = retire_pred[retire_pred.retired==1][['pred_retire_age','Age_years']].diff(axis=1)['Age_years'].apply(lambda x: np.abs(x))#.apply(lambda x: x[0]-x[1] ,row=1)# 0 else )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_notretired = retire_pred[retire_pred.retired==0][['pred_retire_age','Age_years']].diff(axis=1)['Age_years'].apply(lambda x: np.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(actual_retired)\n",
    "print \"\\t TP\\t\\t FN\"\n",
    "for i in [1.5,2.5,3.5,4.5,5.5]:\n",
    "    print i, sum(actual_retired<=i), sum(actual_retired>=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(actual_notretired)\n",
    "print \"\\t TN\\t\\t FP\"\n",
    "for i in [1.5,2.5,3.5,4.5,5.5]:\n",
    "    print i, sum(actual_notretired>i), sum(actual_notretired<=i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More assessment of the Survival-based models\n",
    "1. load the survival model for separation\n",
    "2. look at confidence intervals and how to join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/kesj/work/hrsepara/proc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_cf1 = pickle.load(open('separation_sf1.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nr_em = em2002[em2002.retired== 0].copy()\n",
    "nr_em.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# break into evaluation and build sets\n",
    "print \"Starting with subset of {0} employees.\".format(len(nr_em))\n",
    "eval_fraction = 0.20\n",
    "ne2build, ne2eval = train_test_split(nr_em,test_size=eval_fraction,random_state = 60333)\n",
    "print \"Evaluation set has {0} employees; training set has {1} employees.\".format(len(ne2eval),len(ne2build))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(repodir)\n",
    "import bear.bear as br\n",
    "os.chdir('/home/kesj/work/hrsepara/proc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_cols = br.get_columns_with_nulls(ne2build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_descriptions = em2002.LOC_TYPE_DESCR_SFI.unique().tolist()\n",
    "short_loc_descript = {}\n",
    "for loc_name in loc_descriptions:\n",
    "    if loc_name.endswith(')'):\n",
    "        short_name = loc_name[-4:-1]\n",
    "        if short_name == 'NCE':\n",
    "            short_loc_descript[loc_name]='TELE'\n",
    "        else:\n",
    "            short_loc_descript[loc_name]=short_name\n",
    "    elif loc_name.startswith('TELE'):\n",
    "        short_loc_descript[loc_name]='TELE'\n",
    "    elif loc_name.endswith('SIU'):\n",
    "        short_loc_descript[loc_name]='SIU'\n",
    "    elif loc_name.startswith('OPERATIONS'):\n",
    "        short_loc_descript[loc_name]='OC'\n",
    "    elif loc_name.startswith('CORP'):\n",
    "        short_loc_descript[loc_name]='CORP'\n",
    "    elif loc_name.endswith('CENTER'):\n",
    "        short_loc_descript[loc_name]='MC' # marketing center\n",
    "    elif loc_name.endswith('AFO'):\n",
    "        short_loc_descript[loc_name]='AFO'\n",
    "    elif loc_name.endswith('OFFICE'):\n",
    "        if loc_name.startswith('AGENT'):\n",
    "            short_loc_descript[loc_name]='AO' # agent office\n",
    "        elif loc_name.startswith('REGION'):\n",
    "            short_loc_descript[loc_name]='RO' # regional office\n",
    "        elif loc_name.startswith('CATA'):\n",
    "            short_loc_descript[loc_name]='CAT' # catastrophe office\n",
    "    elif loc_name.startswith('EST'):\n",
    "        short_loc_descript[loc_name]='EST' # estimating station\n",
    "    elif loc_name.startswith('ADM'):\n",
    "        short_loc_descript[loc_name]='ADM' # estimating station\n",
    "    elif loc_name.startswith('WARE'):\n",
    "        short_loc_descript[loc_name]='WARE' # estimating station\n",
    "    elif loc_name.startswith('VAC'):\n",
    "        short_loc_descript[loc_name]='VAC' # estimating station\n",
    "    elif loc_name.startswith('MULT-USE'):\n",
    "        short_loc_descript[loc_name]='MF' # estimating station\n",
    "    elif loc_name.startswith('MULT-REG'):\n",
    "        short_loc_descript[loc_name]='MRSF' # estimating station\n",
    "    else: \n",
    "        short_loc_descript[loc_name]='UNK'\n",
    "\n",
    "print len(short_loc_descript.keys()), len(set(short_loc_descript.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_label_encode_cols = ['GRADE','JOB_FAMILY','LOC_STATE']\n",
    "cat_cols_to_dummy = ['EMPL_TYPE','FULL_PART_TIME','SHIFT','EMPL_CLASS','EEO1CODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#cate_list = br.get_categorical(X)\n",
    "# need to break the categorical into types\n",
    "pipeS = Pipeline([#(\"null\", br.RemoveAllNull()),  \n",
    "                 #(\"label_encode\",br.LabelEncodeColumn(my_label_encode_cols)),\n",
    "                 #(\"dummy_encode\", br.DummyEncodeColumn(cat_cols_to_dummy)),\n",
    "                 #(\"survival_encode\",SurvivalEncodeColumn(my_label_encode_cols[:5],method='median')),\n",
    "                 #(\"cat\", br.ConvertCategorical(cate_list, rows_to_scan=0.3)),\n",
    "                 (\"fixout_min\",br.FixNumericOutlier(columns_to_fix=['SAL1','MIN_RT_ANNUAL','MERIT1','PERF1'],\n",
    "                                                    criteria_coef=('percentile',2),\n",
    "                                                   method='lower',fill_with='nearest_value')),\n",
    "                  (\"fixout_max\",br.FixNumericOutlier(columns_to_fix=['MAX_RT_ANNUAL'],criteria_coef=('percentile',2),\n",
    "                                                   method='both',fill_with='nearest_value')) ])#,\n",
    "                 #(\"fill_missingzero\",FillMissingValue(columns_to_fix=['BOX1','FUNC_CNT','EXTFUNC_CNT','TOTAL_RPT_CNT','DIRECT_RPT_CNT'],fill_value=0)),\n",
    "                 #(\"imp_mode\",br.ImputeData(columns_to_impute=missing_cols,rows_to_scan=0.8))])\n",
    "                 #(\"imp_mean\", br.ImputeData(columns_to_impute='auto', rows_to_scan=0.8))])\n",
    "                 #(\"redu\", br.DimensionReduction(rows_to_scan=0.3, n_components=10))])\n",
    "#pipe.fit(X, y).transform(testX)[0:30]\n",
    "#\n",
    "#Xft = pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep_surv_cols1 = ['status','Age_years','Tenure_years','SAL1','MERIT1','PERF1','BOX1','SEX','HAVE_INS','HAVE_DEP',\n",
    "                  'DEPTCNT1','EXTFUNC_CNT','FUNC_CNT','REMOTE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne2b = pipeS.fit_transform(ne2build[sep_surv_cols1],ne2build.status)\n",
    "ne2e = pipeS.fit(ne2build[sep_surv_cols1],ne2build.status).transform(ne2eval[sep_surv_cols1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne2e_psf = sep_cf1.predict_survival_function(ne2e)\n",
    "ne2e_psf.index.name = 'years'\n",
    "ne2e_psf.reset_index(inplace=True)\n",
    "ne2b_psf = sep_cf1.predict_survival_function(ne2b)\n",
    "ne2b_psf.index.name = 'years'\n",
    "ne2b_psf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ne2b_psf.years,ne2b_psf[53117])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ne2b_expect = sep_cf1.predict_expectation(ne2b)\n",
    "ne2b_med = sep_cf1.predict_median(ne2b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne2b_uci = sep_cf1.predict_percentile(ne2b,p=0.95)\n",
    "ne2b_uci.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ne2b_lci = sep_cf1.predict_percentile(ne2b,p=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne2b_pred = pd.concat([ne2b.Tenure_years,ne2b_expect,ne2b_lci,ne2b_med,ne2b_uci],axis=1)\n",
    "ne2b_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne2b_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mx_tenure = nr_em.Tenure_years.max()\n",
    "mx_tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne2b_pred.replace({ np.inf: mx_tenure},inplace=True) #].any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ne2b_pred['status']=ne2b['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(ne2b_pred[0]-ne2b_pred[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(ne2b_pred[ne2b_pred.status==0][0]-ne2b_pred[ne2b_pred.status==0][0.5],label='current')\n",
    "sns.distplot(ne2b_pred[ne2b_pred.status==1][0]-ne2b_pred[ne2b_pred.status==1][0.5],label='former')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(ne2b_psf.years,ne2b_psf[37240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne2b_pred['med_diff'] = ne2b_pred[0.5] - ne2b_pred['Tenure_years']\n",
    "ne2b_pred['p05_diff'] = ne2b_pred[0.05] - ne2b_pred['Tenure_years']\n",
    "ne2b_pred['p95_diff'] = ne2b_pred[0.95] - ne2b_pred['Tenure_years']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "take20 = ne2b.head(20).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_cf1.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "take20_cum_hazard = sep_cf1.predict_cumulative_hazard(take20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "take20_cum_hazard.apply(lambda x: np.exp(-1*x)).plot() # this is the survival function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_cf1.baseline_survival_, sep_cf1.hazards_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_cf1.confidence_intervals_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_cf1.hazards_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_cf1.predict_partial_hazard(take20)#.apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lifelines.utils import normalize\n",
    "normt20 = normalize(take20[sep_cf1.hazards_.columns], sep_cf1._norm_mean.values, sep_cf1._norm_std.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_cf1.normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_partial_hazard_ci(mdl,X):\n",
    "    index = X.index\n",
    "    if mdl.normalize:\n",
    "        X = normalize(X,mdl._norm_mean.values, mdl._norm_std.values)\n",
    "    df = pd.DataFrame(np.exp(np.dot(X,mdl.confidence_intervals.T)),index=index)\n",
    "    df.columns.names = ['upperbound','lowerbound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if mdl.normalize:\n",
    "    mdl._n\n",
    "sep_cf1.normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtemp = pd.DataFrame(np.exp(np.dot(normt20,sep_cf1.confidence_intervals_.T)),index=take20.index)\n",
    "dtemp.rename(columns = {0: 'upperbound',1: 'lowerbound'},inplace=True)\n",
    "dtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(-np.dot(np.log(s_0),\n",
    "sep_cf1.predict_partial_hazard(take20).T#),index=s_0.index,columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(dtemp.upperbound).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now caluculate the cumulative_hazard from this:\n",
    "s_0 = sep_cf1.baseline_survival_\n",
    "col = dtemp.index.tolist()\n",
    "dtemp_up = pd.DataFrame(-np.dot(np.log(s_0),pd.DataFrame(dtemp['upperbound']).T),index=s_0.index,columns=col)\n",
    "dtemp_low = pd.DataFrame(-np.dot(np.log(s_0),pd.DataFrame(dtemp['lowerbound']).T),index=s_0.index,columns=col)\n",
    "dtemp_up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t20_up = dtemp_up.apply(lambda x: np.exp(-1*x))\n",
    "t20_lo = dtemp_low.apply(lambda x: np.exp(-1*x))\n",
    "t20_psf = sep_cf1.predict_survival_function(take20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t20_psf[53117].plot()\n",
    "t20_up[53117].plot()\n",
    "t20_lo[53117].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "take20.iloc[0].Tenure_years+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t20_up[53117].ix[9.34:9.356]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.exp(np.dot(normt20,sep_cf1.hazards_.T)),index=take20.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.exp(np.dot(\n",
    "take20[sep_cf1.hazards_.columns]#, sep_cf1.hazards_.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne2b_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "take20.Tenure_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "take20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_relevant_baseline_sf(mdl,df,yr_range = [0,1,2,3,4,5],base_time_col='Tenure_years'):\n",
    "    individuals = df.index.tolist()\n",
    "    for indiv in individuals:\n",
    "        my_times = np.array([df.loc[indiv,base_time_col]+year for year in yr_range])\n",
    "        print indiv, my_times\n",
    "        # now for these I want to calculate the forecasted survival probability\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_interp = interpolate.interp1d(x,y)\n",
    "                    proba = y_interp(ck_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_relevant_baseline_sf(sep_cf1,take20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalize(take20[sep_cf1.hazards_.columns], sep_cf1._norm_mean.values, sep_cf1._norm_std.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let me just apply this model to the current set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current = em2002[em2002.status == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_cf1.baseline_survival_.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr = pipeS.fit(ne2build[sep_surv_cols1],ne2build.status).transform(current[sep_surv_cols1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_psf = sep_cf1.predict_survival_function(curr)\n",
    "curr_psf.index.name = 'years'\n",
    "curr_psf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_survival_prediction(edf,psf, time_col='Tenure_years', yr_vals=[1,2,3,4,5],restrict_time=None):\n",
    "    from scipy import interpolate\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    pred_col_names = ['proba_'+str(y) for y in yr_vals]\n",
    "    df = pd.DataFrame(index=edf.index, columns=pred_col_names, dtype=float)\n",
    "    print pred_col_names\n",
    "    employee_idx = edf.index.tolist()\n",
    "    emp_cols = edf.columns.tolist()\n",
    "    tcol_idx = emp_cols.index(time_col)+1\n",
    "    age_idx = emp_cols.index('Age_years')+1\n",
    "    #define the maximum survival_time_range\n",
    "    mx_surv_time = psf.years.max()\n",
    "    if restrict_time is None:\n",
    "            restrict_time = 0.0\n",
    "            \n",
    "    for employee in edf.itertuples():\n",
    "        my_index = employee[0]\n",
    "        my_age = employee[age_idx]\n",
    "        my_time = employee[tcol_idx]\n",
    "        #print my_index,my_age, my_time\n",
    "        prob_vals = np.ones(len(yr_vals))\n",
    "        if my_index % 5000 ==0 :\n",
    "            print my_index, my_age, my_time\n",
    "        \n",
    "        \n",
    "        if my_age >= restrict_time: # only deal with over 50 (restrict_time = 50.0)\n",
    "            for idx, year in enumerate(yr_vals):\n",
    "                ck_yr = my_time+year\n",
    "                if ck_yr>=mx_surv_time:\n",
    "                    proba = psf.iloc[-1].loc[my_index]\n",
    "                else:\n",
    "                    try:\n",
    "                        prior_idx = np.where(psf.years < ck_yr)[0][-1]\n",
    "                        posterior_idx = np.where(psf.years > ck_yr)[0][0]\n",
    "\n",
    "                        x = [psf.loc[prior_idx]['years'], psf.loc[posterior_idx]['years']]\n",
    "                        y = [psf.loc[prior_idx][my_index], psf.loc[posterior_idx][my_index]]\n",
    "                            \n",
    "                        # now interpolate these\n",
    "                        y_interp = interpolate.interp1d(x,y)\n",
    "                        proba = y_interp(ck_yr)\n",
    "                    \n",
    "                    except IndexError:\n",
    "                        #print \"\\t IE\", proba, idx,my_index\n",
    "                        proba = psf.loc[np.where(psf.years == ck_yr)[0]][my_index]\n",
    "\n",
    "                prob_vals[idx] = proba\n",
    "        \n",
    "        df.loc[my_index]=prob_vals\n",
    "    \n",
    "    df.fillna(1.0,inplace=True)  # fill in missing values with ones\n",
    "    df[df<0] = 0.0  # replace negative probabilities with zero\n",
    "\n",
    "    return 1-df  # convert to probability of separation or retirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_sep_pred1 = get_survival_prediction(curr,curr_psf,'Tenure_years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_sep_pred1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_cf1.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(curr_sep_pred1+0.1).values.astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_sep_pred1.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sep_def_off = [0.1,0.3,0.5,0.7,0.9]\n",
    "sep_def_off = [0.5,0.5,0.5,0.5,0.5]\n",
    "(curr_sep_pred1+sep_def_off).values.astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(curr_sep_pred1+sep_def_off-0.1).values.astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(curr_sep_pred1+sep_def_off+0.1).values.astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_rates = pd.DataFrame(sep_proba_df.sum()/float(len(sep_proba_df)))\n",
    "simple_rates.index = ['yr1','yr2','yr3','yr4','yr5']\n",
    "simple_rates.columns = ['Separation']\n",
    "simple_rates['Annual Separation'] = simple_rates.diff()\n",
    "simple_rates.loc['yr1','Annual Separation']= simple_rates.loc['yr1','Separation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_rates = pd.DataFrame(ret_proba_df.sum()/float(len(ret_proba_df)))\n",
    "tmp_rates.index = ['yr1','yr2','yr3','yr4','yr5']\n",
    "tmp_rates.columns = ['Retirement']\n",
    "tmp_rates['Annual Retirement'] = tmp_rates.diff()\n",
    "tmp_rates.loc['yr1','Annual Retirement']= tmp_rates.loc['yr1','Retirement']\n",
    "simple_rates = pd.concat([simple_rates,tmp_rates],axis=1)\n",
    "simple_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what were historical rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### load in the federal unemployment data\n",
    "unempl_raw = pd.read_csv('../eda/us_unemployment_monthly_seas.csv')\n",
    "unempl_raw.head()\n",
    "### convert to useable format\n",
    "unempl = pd.melt(unempl_raw, id_vars='Year')\n",
    "unempl.sort('Year', inplace=True)\n",
    "unempl['date'] = unempl[['Year','variable']].apply(lambda x: pd.to_datetime(x[1]+str(x[0]),format='%b%Y'),axis=1)\n",
    "unempl.sort('date',inplace=True)\n",
    "unempl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(unempl.date,unempl.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unempl.groupby('Year')['value'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the historical rates of retirement and separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em2002[['hire_tstmp','term_tstmp']] = em2002[['HIRE_DT','TERMINATION_DT']].applymap(lambda x: pd.to_datetime(datetime.datetime.strptime(x,'%d%b%Y')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monthly_range_terminations = pd.date_range(em2002.term_tstmp.min(),em2002.term_tstmp.max(),freq='M')\n",
    "print len(monthly_range_terminations)\n",
    "monthly_range_terminations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monthly_range_terminations[0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(em2002[(em2002.term_tstmp <= monthly_range_terminations[1]) & (em2002.retired == 0) & (em2002.term_tstmp > monthly_range_terminations[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nactive = []\n",
    "nsep2 = []\n",
    "nhired = []\n",
    "nretired = []\n",
    "prev_date = monthly_range_terminations[0]-1\n",
    "#nsep.append(0.0)\n",
    "for idx, my_date in enumerate(monthly_range_terminations):\n",
    "    nactive.append( len(em2002[(em2002.hire_tstmp < my_date) &(em2002.term_tstmp > my_date)]))\n",
    "    if idx == 0:\n",
    "        nsep2.append(len(em2002[(em2002.term_tstmp <= my_date) & (em2002.hire_tstmp < my_date)]))\n",
    "        nretired.append(len(em2002[(em2002.term_tstmp <= my_date) & (em2002.hire_tstmp < my_date) & (em2002.retired==1)]))\n",
    "        nhired.append( len(em2002[(em2002.hire_tstmp <= my_date) &(em2002.hire_tstmp > prev_date)]))\n",
    "    else:\n",
    "        nsep2.append(len(em2002[(em2002.term_tstmp <= my_date) & (em2002.hire_tstmp < my_date) &( em2002.term_tstmp > monthly_range_terminations[idx-1])]))\n",
    "        nretired.append(len(em2002[(em2002.term_tstmp <= my_date) & (em2002.hire_tstmp < my_date) & (em2002.retired==1) &( em2002.term_tstmp > monthly_range_terminations[idx-1])]) )\n",
    "        nhired.append( len(em2002[(em2002.hire_tstmp <= my_date) &(em2002.hire_tstmp > monthly_range_terminations[idx-1])]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workforce= pd.DataFrame(data =nactive,index=monthly_range_terminations,columns=['Active'])\n",
    "delta = workforce.diff()\n",
    "workforce['netChange'] = delta\n",
    "workforce['AllSeparations'] = nsep2\n",
    "workforce['Hires'] = nhired\n",
    "workforce['Retirements'] = nretired\n",
    "workforce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(monthly_range_terminations,nactive)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Worforce Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annualwf = pd.DataFrame()\n",
    "annualwf = workforce[['AllSeparations','Hires','Retirements']].resample('A',how='sum')#.plot()\n",
    "annualwf['Active'] =workforce['Active'].resample('A',how='last')\n",
    "annualwf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annualwf['Separations']=annualwf['AllSeparations']-annualwf['Retirements']\n",
    "annualwf['SepRate']=annualwf['Separations']/annualwf['Active']\n",
    "annualwf['RetRate']=annualwf['Separations']/annualwf['Active']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(annualwf.AllSeparations/annualwf.Active).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feb. 10, 2016\n",
    "### trying a survival model for separation (omitting the known retired elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X20 = take20['Tenure_years'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[X20[0]+tp for tp in [0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_cf1.durations.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
