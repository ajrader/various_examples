{
 "metadata": {
  "name": "",
  "signature": "sha256:44264f6fbc9ce2135ff0f918a7485901c830fd2ed021aac13c0e015c50fe1d53"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# chapter 5 from Machine Learning with Python Packt publishing\n",
      "## Classification -- detecting Poor Answers\n",
      "Idea is to use data from stackoverflow.com to provide immediate feedback on the quality of their answer\n",
      "\n",
      "## github location of code:\n",
      "https://github.com/luispedro/BuildingMachineLearningSystemsWithPython\n",
      "\n",
      "\n",
      "### Roadmap\n",
      "Begin with a noisy dataset -- to illustrate the need to sometimes adjust our initial goals in order to obtain some sort of solution.\n",
      "\n",
      "First start with a kNN approach, switch to logistic regression, and switch to a solution that has good predictions but only\n",
      "for a subset of the data.\n",
      "\n",
      "### Learning to classify classy answers\n",
      "While classifying, we want to find the corresponding classes, sometimes also called labels, for the given data examples. \n",
      "To acheive this, we need to answer teh following questions:\n",
      "    \n",
      "    1. How should we represent the data example/instances?\n",
      "    2. Which model or structure should our classifier possess?\n",
      "    \n",
      "### Tuning the instance\n",
      "The data instance is the text of the answer (converted somehow into numerical features) and a label (0,1) to \n",
      "indicate if it is an acceptable answer or not.\n",
      "\n",
      "### Tuning the classifier\n",
      "Once we have found (or collected) enough text-label pairs we train the '''classifier'''.\n",
      "For the underlying structure of the classifier, we have a lot of possible options, each with pros and cons. Some fo the prominent \n",
      "choices include '''logistic regression''', decision trees, SVMs, and Naive Bayes.\n",
      "\n",
      "### Fetching the Data\n",
      "stackoverflow has the data in a dump at http://www.clearbits.net/torrents/2076-aug-2012\n",
      "\n",
      "'\"SF blocks this site\"'\n",
      "datafiles include: badges.xml, comments.xml, posthistory.xml, posts.xml, users.xml, votes.xml --> only keep posts.xml \n",
      "hich has all the questions and answers as individual row  tags within the root tag posts."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Slimming the data down into chewable chunks.\n",
      "Rather than try evaluations ont he whole 12 GB file. \n",
      "Filtering `row` with `CreationDate` of 2011 or later is tstill over 6 million posts -- this is more than enough.\n",
      "Operating on XML file will slow down the process so we'll convert it using `cElementTree` to tsv within python."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Preselection and processing of attributes\n",
      "We need to keep attributes that we think will help us.\n",
      "Look at the following attributes:\n",
      "\n",
      "* `PostType` --> only necessary to distinguish between questions and answers; set this to 1.\n",
      "* `CreationDate` --> keep it because it could show time between responses.\n",
      "* `Score` ---> very important as a measure of success\n",
      "* `ViewCount` --> because no info on time when answer is submitted, can't use it (drop)\n",
      "* `Body` --> important; stored as HTML; need to decode into plain text\n",
      "* `OwnerUserId` --> userful if we consider user-dependent features (not going to do here but could couple to user.xml file in future version).\n",
      "* `Title` --> ignored for now\n",
      "* `CommentCount` --> ignored because can't help as the answer is being typed.\n",
      "* `AcceptedAnswerId` --> similar to `Score`; want to convert this to `IsAccepted` feature to show if a given answer is good or not (1,0).\n",
      "\n",
      "The following format will be generated:\n",
      "`Id <tab> ParentId <tab> IsAccepted <tab> TimeToAnswer <tab> Score <tab> text`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For concrete parsing details, please refer to `so_xml_to_tsv.py` and `choose_instance.py`. It will suffice to say that in order to speed up the process, we will split the data into two files. In meta.json, we store a dictionary, mapping a post's Id to its other data (except Text in the JSON format) so that we can read it in the proper format. For example, the score of a post would reside at $meta[Id]['Score']$. In `data.tsv`, we store Id and Text, which we can easily read with the following method:\n",
      "\n",
      " def fetch_posts():\n",
      "\n",
      "      for line in open(\"data.tsv\", \"r\"):\n",
      "\n",
      "      post_id, text = line.split(\"\\t\")\n",
      "\n",
      "      yield int(post_id), text.strip()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Creating our First Classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Starting with the k-nearest neighbor (kNN) algorithm\n",
      "Use the `sklearn` implementation of the knn. Begin with a simple 2-nearest neighbor classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import neighbors\n",
      "knn= neighbors.KNeighborsClassifier(n_neighbors=2)\n",
      "print(knn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "KNeighborsClassifier(algorithm=auto, leaf_size=30, metric=minkowski,\n",
        "           n_neighbors=2, p=2, weights=uniform)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train it with fit:\n",
      "knn.fit([[1],[2],[3],[4],[5],[6]],[0,0,0,1,1,1])\n",
      "knn.predict(1.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "array([0])"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn.predict(37)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "array([1])"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn.predict(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "array([0])"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn.predict_proba(1.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([[ 1.,  0.]])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn.predict_proba(3.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "array([[ 0.5,  0.5]])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}