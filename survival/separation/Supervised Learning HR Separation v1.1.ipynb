{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning for HR Separations\n",
    "## July 1, 2015\n",
    "<hr>\n",
    "\n",
    "### 1. Return to the ETL to correct the dataset \n",
    "* (no longer do I need to labelEncode GRADE)\n",
    "* use bear\n",
    "#### define the source repo\n",
    "* '/home/kesj/lib/repo/'\n",
    "\n",
    "### 2. Define the correct working directories\n",
    "* '/data/discovery/hrsepara/core/' for HDFS\n",
    "* '/data/discovery/hrsepara/staging/eda' and '/home/kesj/working/hrsepara/eda/' for HDFS and LFS on phd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coredir = '/data/discovery/hrsepara/core/'\n",
    "stgdir1 = '/data/discovery/hrsepara/staging/eda'\n",
    "stgdir1local = '/home/kesj/work/hrsepara/eda'\n",
    "repodir = '/home/kesj/lib/repo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### load the basic files\n",
    "import os,subprocess,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "import random\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(repodir)\n",
    "import bear.bear as br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(stgdir1local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so try to reload employee data and parse using BEAR?\n",
    "* first load things that won't change like the economic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the unemployment measure into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Jan</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1987-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1987</td>\n",
       "      <td>Feb</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1987-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1987</td>\n",
       "      <td>Mar</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1987-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1987</td>\n",
       "      <td>Apr</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1987-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1987</td>\n",
       "      <td>May</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1987-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year variable  value       date\n",
       "0    1987      Jan    6.6 1987-01-01\n",
       "29   1987      Feb    6.6 1987-02-01\n",
       "58   1987      Mar    6.6 1987-03-01\n",
       "87   1987      Apr    6.3 1987-04-01\n",
       "116  1987      May    6.3 1987-05-01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load in the federal unemployment data\n",
    "unempl_raw = pd.read_csv('us_unemployment_monthly_seas.csv')\n",
    "unempl_raw.head()\n",
    "### convert to useable format\n",
    "unempl = pd.melt(unempl_raw, id_vars='Year')\n",
    "unempl.sort('Year', inplace=True)\n",
    "unempl['date'] = unempl[['Year','variable']].apply(lambda x: pd.to_datetime(x[1]+str(x[0]),format='%b%Y'),axis=1)\n",
    "unempl.sort('date',inplace=True)\n",
    "unempl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unempl.set_index('date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a0e254f10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAFpCAYAAAAyUUkOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a4018ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(unempl.date,unempl.value,'d--',color='limegreen')\n",
    "unempl['value'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_unempl_rate(my_date,unempl):\n",
    "    try :\n",
    "        un_rate = unempl[unempl.index <= my_date]['value'].values[-1]\n",
    "    except IndexError:\n",
    "        un_rate = unempl['value'].ix[0]\n",
    "        \n",
    "    return un_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to truncate POSTAL_ZIP to zip5\n",
    "def truncate_postal_zip(in_zip):\n",
    "    try:\n",
    "        out_zip = in_zip[:5]\n",
    "        #print out_zip\n",
    "    except:\n",
    "        #out_zip = str(in_zip)[:5]\n",
    "        out_zip = np.nan\n",
    "    return out_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize_dataframe2(df,show_example=False):\n",
    "    nrow = len(df)\n",
    "    summary_df = pd.DataFrame(columns = ['Column','datatype','nmissing','arity','accepted values'])\n",
    "    len_df = len(summary_df)\n",
    "    for col in df.columns:\n",
    "        nmiss = nrow - df[col].value_counts().sum()\n",
    "        narity = len(df[col].unique())\n",
    "        if show_example:\n",
    "            print col, df[col].dtype,nmiss, \"\\t\", narity,\":\\t\", df[col].ix[8320]\n",
    "        else:\n",
    "            print col, df[col].dtype,nmiss, \"\\t\", narity\n",
    "        accept_val = None\n",
    "        if narity < 20:\n",
    "            accept_val = df[col].unique()\n",
    "        summary_df.loc[len_df] = [col,df[col].dtype,nmiss,narity,accept_val]\n",
    "        len_df+=1\n",
    "    # assing fraction of missing\n",
    "    summary_df['x_missing'] = summary_df['nmissing']/float(nrow)\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load un-filled file and try using BEAR\n",
    "'employee_dataframe.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243010, 185)\n"
     ]
    }
   ],
   "source": [
    "datafile = 'employee_dataframe.ssv'\n",
    "emplraw = pd.read_csv(datafile,sep=';',dtype={'KEY':np.str})\n",
    "print emplraw.shape\n",
    "emplraw.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTRES1</th>\n",
       "      <th>ACTRES10</th>\n",
       "      <th>ACTRES2</th>\n",
       "      <th>ACTRES3</th>\n",
       "      <th>ACTRES4</th>\n",
       "      <th>ACTRES5</th>\n",
       "      <th>ACTRES6</th>\n",
       "      <th>ACTRES7</th>\n",
       "      <th>ACTRES8</th>\n",
       "      <th>ACTRES9</th>\n",
       "      <th>ADDRCNT1</th>\n",
       "      <th>ADDRCNT10</th>\n",
       "      <th>ADDRCNT3</th>\n",
       "      <th>ADDRCNT5</th>\n",
       "      <th>ADDRESS1</th>\n",
       "      <th>ADDRESS2</th>\n",
       "      <th>ANNUAL_RT</th>\n",
       "      <th>Age_tdelta</th>\n",
       "      <th>Age_years</th>\n",
       "      <th>BIRTHDATE</th>\n",
       "      <th>BOX1</th>\n",
       "      <th>BOX10</th>\n",
       "      <th>BOX2</th>\n",
       "      <th>BOX3</th>\n",
       "      <th>BOX4</th>\n",
       "      <th>BOX5</th>\n",
       "      <th>BOX6</th>\n",
       "      <th>BOX7</th>\n",
       "      <th>BOX8</th>\n",
       "      <th>BOX9</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>COMP_FREQUENCY</th>\n",
       "      <th>CUR_DEPT_MOS</th>\n",
       "      <th>CUR_EFUNC_MOS</th>\n",
       "      <th>CUR_FUNC_MOS</th>\n",
       "      <th>CUR_GRADE_MOS</th>\n",
       "      <th>CUR_JOB_MOS</th>\n",
       "      <th>CUR_LOC_MOS</th>\n",
       "      <th>DEPTCNT1</th>\n",
       "      <th>DEPTCNT10</th>\n",
       "      <th>DEPTCNT3</th>\n",
       "      <th>DEPTCNT5</th>\n",
       "      <th>DIRECT_RPT_CNT</th>\n",
       "      <th>DIVISION_CODE_SFI</th>\n",
       "      <th>EEO1CODE</th>\n",
       "      <th>EFUNCCNT1</th>\n",
       "      <th>EFUNCCNT10</th>\n",
       "      <th>EFUNCCNT3</th>\n",
       "      <th>EFUNCCNT5</th>\n",
       "      <th>EMPL_CLASS</th>\n",
       "      <th>EMPL_TYPE</th>\n",
       "      <th>ETHNIC_GROUP</th>\n",
       "      <th>EXTFUNC_CNT</th>\n",
       "      <th>EXT_FUNC_ID_SFI</th>\n",
       "      <th>FLOORCNT1</th>\n",
       "      <th>FLOORCNT10</th>\n",
       "      <th>FLOORCNT3</th>\n",
       "      <th>FLOORCNT5</th>\n",
       "      <th>FLOR_SFI</th>\n",
       "      <th>FLSA_STATUS</th>\n",
       "      <th>FTE</th>\n",
       "      <th>FTPTCNT1</th>\n",
       "      <th>FTPTCNT10</th>\n",
       "      <th>FTPTCNT3</th>\n",
       "      <th>FTPTCNT5</th>\n",
       "      <th>FULLPART1</th>\n",
       "      <th>FULLPART10</th>\n",
       "      <th>FULLPART3</th>\n",
       "      <th>FULLPART5</th>\n",
       "      <th>FULL_PART_TIME</th>\n",
       "      <th>FUNCCNT1</th>\n",
       "      <th>FUNCCNT10</th>\n",
       "      <th>FUNCCNT3</th>\n",
       "      <th>FUNCCNT5</th>\n",
       "      <th>FUNC_CNT</th>\n",
       "      <th>FUNC_ID_SFI</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>GRADECNT1</th>\n",
       "      <th>GRADECNT10</th>\n",
       "      <th>GRADECNT3</th>\n",
       "      <th>GRADECNT5</th>\n",
       "      <th>HIRE_DT</th>\n",
       "      <th>HUBIND</th>\n",
       "      <th>INTERN</th>\n",
       "      <th>JOBCNT1</th>\n",
       "      <th>JOBCNT10</th>\n",
       "      <th>JOBCNT3</th>\n",
       "      <th>JOBCNT5</th>\n",
       "      <th>JOBCODE</th>\n",
       "      <th>JOB_FAMILY</th>\n",
       "      <th>JOB_FUNCTION</th>\n",
       "      <th>KEY</th>\n",
       "      <th>LAST_HIRE_DT</th>\n",
       "      <th>LEGACY_DEPT_SFI</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>LOCCNT1</th>\n",
       "      <th>LOCCNT10</th>\n",
       "      <th>LOCCNT3</th>\n",
       "      <th>LOCCNT5</th>\n",
       "      <th>LOCSTCNT1</th>\n",
       "      <th>LOCSTCNT10</th>\n",
       "      <th>LOCSTCNT3</th>\n",
       "      <th>LOCSTCNT5</th>\n",
       "      <th>LOC_CITY</th>\n",
       "      <th>LOC_STATE</th>\n",
       "      <th>LOC_TYPE_DESCR_SFI</th>\n",
       "      <th>MAR_STATUS_DT</th>\n",
       "      <th>MAR_STA_SNAME_SFI</th>\n",
       "      <th>MAX_RT_ANNUAL</th>\n",
       "      <th>MERIT1</th>\n",
       "      <th>MERIT10</th>\n",
       "      <th>MERIT2</th>\n",
       "      <th>MERIT3</th>\n",
       "      <th>MERIT4</th>\n",
       "      <th>MERIT5</th>\n",
       "      <th>MERIT6</th>\n",
       "      <th>MERIT7</th>\n",
       "      <th>MERIT8</th>\n",
       "      <th>MERIT9</th>\n",
       "      <th>MIN_RT_ANNUAL</th>\n",
       "      <th>PARTFULL1</th>\n",
       "      <th>PARTFULL10</th>\n",
       "      <th>PARTFULL3</th>\n",
       "      <th>PARTFULL5</th>\n",
       "      <th>PERF1</th>\n",
       "      <th>PERF10</th>\n",
       "      <th>PERF2</th>\n",
       "      <th>PERF3</th>\n",
       "      <th>PERF4</th>\n",
       "      <th>PERF5</th>\n",
       "      <th>PERF6</th>\n",
       "      <th>PERF7</th>\n",
       "      <th>PERF8</th>\n",
       "      <th>PERF9</th>\n",
       "      <th>PER_ORG</th>\n",
       "      <th>POSTAL_SFI</th>\n",
       "      <th>PTFTCNT1</th>\n",
       "      <th>PTFTCNT10</th>\n",
       "      <th>PTFTCNT3</th>\n",
       "      <th>PTFTCNT5</th>\n",
       "      <th>RATE1</th>\n",
       "      <th>RATE10</th>\n",
       "      <th>RATE2</th>\n",
       "      <th>RATE3</th>\n",
       "      <th>RATE4</th>\n",
       "      <th>RATE5</th>\n",
       "      <th>RATE6</th>\n",
       "      <th>RATE7</th>\n",
       "      <th>RATE8</th>\n",
       "      <th>RATE9</th>\n",
       "      <th>REH_CNT</th>\n",
       "      <th>RELOCATE_ALL_SFI</th>\n",
       "      <th>RELO_STATE_CNT_SFI</th>\n",
       "      <th>REMOTE</th>\n",
       "      <th>REMOTE_SUPV</th>\n",
       "      <th>SAL1</th>\n",
       "      <th>SAL10</th>\n",
       "      <th>SAL2</th>\n",
       "      <th>SAL3</th>\n",
       "      <th>SAL4</th>\n",
       "      <th>SAL5</th>\n",
       "      <th>SAL6</th>\n",
       "      <th>SAL7</th>\n",
       "      <th>SAL8</th>\n",
       "      <th>SAL9</th>\n",
       "      <th>SERVICE_DT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SHIFT</th>\n",
       "      <th>SKEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STD_HOURS</th>\n",
       "      <th>SUPVCNT1</th>\n",
       "      <th>SUPVCNT10</th>\n",
       "      <th>SUPVCNT3</th>\n",
       "      <th>SUPVCNT5</th>\n",
       "      <th>SUPV_DIFF_LOC</th>\n",
       "      <th>TELE_MOS</th>\n",
       "      <th>TERMINATION_DT</th>\n",
       "      <th>TOTAL_RPT_CNT</th>\n",
       "      <th>TOT_MO_SERVICE_SFI</th>\n",
       "      <th>Tenure_months</th>\n",
       "      <th>Tenure_tdelta</th>\n",
       "      <th>VOLINVOL</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DECEMBER NEW HIRE;RRTR W/O JOB NUMBER CHANGE;B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMPLOYEE NEW HIRE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6506 MOJAVE ST NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68301.00</td>\n",
       "      <td>14904 days, 00:00:00</td>\n",
       "      <td>40.805766</td>\n",
       "      <td>1968-10-10 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.258065</td>\n",
       "      <td>7.258065</td>\n",
       "      <td>7.258065</td>\n",
       "      <td>7.258065</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>3</td>\n",
       "      <td>1078</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>N</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5196</td>\n",
       "      <td>9</td>\n",
       "      <td>UNS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-24 00:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3101</td>\n",
       "      <td>AGYINT</td>\n",
       "      <td>NSA</td>\n",
       "      <td>812163208058180</td>\n",
       "      <td>2008-12-24 00:00:00</td>\n",
       "      <td>124038TB5D4</td>\n",
       "      <td>24TB5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ALBUQUERQUE</td>\n",
       "      <td>NM</td>\n",
       "      <td>TELEWORKER - MOBILE</td>\n",
       "      <td>24DEC2008</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMP</td>\n",
       "      <td>87120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>68301.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-12-24 00:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>4.728472e+14</td>\n",
       "      <td>NM</td>\n",
       "      <td>38.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-07-31 00:00:00</td>\n",
       "      <td>63</td>\n",
       "      <td>7</td>\n",
       "      <td>7.195220</td>\n",
       "      <td>219 days, 00:00:00</td>\n",
       "      <td>VOLUNTARY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISCELLANEOUS DATA CHANGE;MISCELLANEOUS DATA C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1949 E UNIVERSITY DR. APT.4048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16099.20</td>\n",
       "      <td>7788 days, 00:00:00</td>\n",
       "      <td>21.322820</td>\n",
       "      <td>1993-09-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>6.709677</td>\n",
       "      <td>6.709677</td>\n",
       "      <td>6.709677</td>\n",
       "      <td>6.709677</td>\n",
       "      <td>6.709677</td>\n",
       "      <td>6.709677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>1827</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>N</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3846</td>\n",
       "      <td>933</td>\n",
       "      <td>PA1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-06-09 00:00:00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>RSCREP</td>\n",
       "      <td>PSA</td>\n",
       "      <td>490903510940682</td>\n",
       "      <td>2014-06-09 00:00:00</td>\n",
       "      <td>12400451524</td>\n",
       "      <td>24515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TEMPE</td>\n",
       "      <td>AZ</td>\n",
       "      <td>OPERATIONS CENTER</td>\n",
       "      <td>09JUN2014</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>38026.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22400.90</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMP</td>\n",
       "      <td>85281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>16099.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-06-09 00:00:00</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3.419407e+14</td>\n",
       "      <td>AZ</td>\n",
       "      <td>24.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>6.768106</td>\n",
       "      <td>206 days, 00:00:00</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MERIT;INCENTIVE;ANOTHER OPPORTUNITY</td>\n",
       "      <td>EMPLOYEE NEW HIRE;MISCELLANEOUS DATA CHANGE;JO...</td>\n",
       "      <td>MERIT;INCENTIVE;MISCELLANEOUS DATA CHANGE</td>\n",
       "      <td>MERIT</td>\n",
       "      <td>PROMOTION;MERIT;RRTR W/JOB NUMBER CHANGE</td>\n",
       "      <td>SALARY PLAN CHANGE;MERIT;MISCELLANEOUS DATA CH...</td>\n",
       "      <td>MERIT;MISCELLANEOUS DATA CHANGE;MISCELLANEOUS ...</td>\n",
       "      <td>MERIT;MISCELLANEOUS DATA CHANGE;MISCELLANEOUS ...</td>\n",
       "      <td>MISCELLANEOUS DATA CHANGE;MERIT</td>\n",
       "      <td>MISCELLANEOUS DATA CHANGE;MERIT;JOB CODE CHANG...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14110 ANGELTON TERR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58551.95</td>\n",
       "      <td>12981 days, 00:00:00</td>\n",
       "      <td>35.540771</td>\n",
       "      <td>1976-03-08 00:00:00</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>L</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>40.645161</td>\n",
       "      <td>40.645161</td>\n",
       "      <td>109.580645</td>\n",
       "      <td>51.096774</td>\n",
       "      <td>40.645161</td>\n",
       "      <td>40.645161</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>3465</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>N</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29679</td>\n",
       "      <td>14</td>\n",
       "      <td>RB2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2002-08-05 00:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>167</td>\n",
       "      <td>FCLMRP</td>\n",
       "      <td>PTB</td>\n",
       "      <td>867989974034945</td>\n",
       "      <td>2002-08-05 00:00:00</td>\n",
       "      <td>521052119F2</td>\n",
       "      <td>21119</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SILVER SPRING</td>\n",
       "      <td>MD</td>\n",
       "      <td>OPERATIONS CENTER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>84150.00</td>\n",
       "      <td>2999.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2846.12</td>\n",
       "      <td>3517.01</td>\n",
       "      <td>2371.20</td>\n",
       "      <td>1848.49</td>\n",
       "      <td>1762.15</td>\n",
       "      <td>1725.53</td>\n",
       "      <td>997.18</td>\n",
       "      <td>731.43</td>\n",
       "      <td>46096.11</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1999.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1897.42</td>\n",
       "      <td>1893.78</td>\n",
       "      <td>1016.23</td>\n",
       "      <td>792.21</td>\n",
       "      <td>755.21</td>\n",
       "      <td>671.04</td>\n",
       "      <td>0</td>\n",
       "      <td>487.62</td>\n",
       "      <td>EMP</td>\n",
       "      <td>20866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R2C3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R3C2</td>\n",
       "      <td>R3C2</td>\n",
       "      <td>R2C2</td>\n",
       "      <td>R2C2</td>\n",
       "      <td>R2C2</td>\n",
       "      <td>R2C2</td>\n",
       "      <td>L1PRO</td>\n",
       "      <td>L2DEV</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>58551.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55552.13</td>\n",
       "      <td>52706.01</td>\n",
       "      <td>44714.08</td>\n",
       "      <td>39572.79</td>\n",
       "      <td>37724.30</td>\n",
       "      <td>35962.15</td>\n",
       "      <td>34236.62</td>\n",
       "      <td>33239.44</td>\n",
       "      <td>2002-08-05 00:00:00</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3.473630e+14</td>\n",
       "      <td>MD</td>\n",
       "      <td>38.75</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-09-22 00:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>109</td>\n",
       "      <td>109.571038</td>\n",
       "      <td>3335 days, 00:00:00</td>\n",
       "      <td>VOLUNTARY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISCELLANEOUS DATA CHANGE;BECAME AN AGENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMPLOYEE NEW HIRE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4740 HIGHWAY 51 N APT 21101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61220.90</td>\n",
       "      <td>13591 days, 00:00:00</td>\n",
       "      <td>37.210894</td>\n",
       "      <td>1975-03-16 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>10.290323</td>\n",
       "      <td>10.290323</td>\n",
       "      <td>10.290323</td>\n",
       "      <td>10.290323</td>\n",
       "      <td>10.290323</td>\n",
       "      <td>10.290323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1130</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>N</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4783</td>\n",
       "      <td>9</td>\n",
       "      <td>UNS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-23 00:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3053</td>\n",
       "      <td>AGCYIT</td>\n",
       "      <td>NSA</td>\n",
       "      <td>323476882802079</td>\n",
       "      <td>2011-07-23 00:00:00</td>\n",
       "      <td>109038T50D1</td>\n",
       "      <td>09T50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOUTHAVEN</td>\n",
       "      <td>MS</td>\n",
       "      <td>TELEWORKER - MOBILE</td>\n",
       "      <td>14JUL2011</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMP</td>\n",
       "      <td>38671-7993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>61220.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-23 00:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>8.008665e+14</td>\n",
       "      <td>MS</td>\n",
       "      <td>40.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-05-31 00:00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>10.283579</td>\n",
       "      <td>313 days, 00:00:00</td>\n",
       "      <td>VOLUNTARY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANOTHER OPPORTUNITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMPLOYEE NEW HIRE;TRANSFER W/O JOB NUMBER CHAN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15 COLMAR AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31107.54</td>\n",
       "      <td>9845 days, 00:00:00</td>\n",
       "      <td>26.954694</td>\n",
       "      <td>1976-01-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>15797</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>N</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34341</td>\n",
       "      <td>14</td>\n",
       "      <td>PA3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002-03-04 00:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "      <td>ACLPRC</td>\n",
       "      <td>PSA</td>\n",
       "      <td>704793881953132</td>\n",
       "      <td>2002-03-04 00:00:00</td>\n",
       "      <td>117456226J1</td>\n",
       "      <td>17226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MELVILLE</td>\n",
       "      <td>NY</td>\n",
       "      <td>CLAIM SERVICE CENTER(CSC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>59760.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32280.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMP</td>\n",
       "      <td>11755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>31107.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-03-04 00:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>2.525976e+13</td>\n",
       "      <td>NY</td>\n",
       "      <td>38.75</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-03 00:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10.020740</td>\n",
       "      <td>305 days, 00:00:00</td>\n",
       "      <td>VOLUNTARY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243005</th>\n",
       "      <td>DEATH;COMPANY WIDE CONVERSION;REGIONAL CONVERSION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MERIT;ORGANIZATIONAL CHANGES;PROMOTION</td>\n",
       "      <td>EMPLOYEE NEW HIRE;TRANSFER W/ JOB NUMBER CHANG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>606 HAMILTON APT A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24282.00</td>\n",
       "      <td>8215 days, 00:00:00</td>\n",
       "      <td>22.491906</td>\n",
       "      <td>1970-09-17 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>823</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>823</td>\n",
       "      <td>521</td>\n",
       "      <td>SF4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1991-01-07 00:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344748747695586</td>\n",
       "      <td>1991-01-07 00:00:00</td>\n",
       "      <td>112018921</td>\n",
       "      <td>12921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BAKERSFIELD</td>\n",
       "      <td>CA</td>\n",
       "      <td>REGIONAL OFFICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>999999.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>EMP</td>\n",
       "      <td>92627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EXPE</td>\n",
       "      <td>PEXE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>24282.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1991-01-07 00:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>38.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1993-03-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>26.218197</td>\n",
       "      <td>798 days, 00:00:00</td>\n",
       "      <td>INVOLUNTARY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243006</th>\n",
       "      <td>EMPLOYEE NEW HIRE;TERMINATE SEASONAL EMPLOYEE;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>431 CLARK ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20779.20</td>\n",
       "      <td>8125 days, 00:00:00</td>\n",
       "      <td>22.245494</td>\n",
       "      <td>1975-08-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>20540</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33994</td>\n",
       "      <td>14</td>\n",
       "      <td>SF3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1997-10-22 00:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>438869032281856</td>\n",
       "      <td>1997-10-22 00:00:00</td>\n",
       "      <td>10145311869</td>\n",
       "      <td>01118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NAPERVILLE</td>\n",
       "      <td>IL</td>\n",
       "      <td>CLAIM SERVICE CENTER(CSC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>999999.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMP</td>\n",
       "      <td>60505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>20779.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-10-22 00:00:00</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL</td>\n",
       "      <td>38.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1997-10-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295694</td>\n",
       "      <td>9 days, 00:00:00</td>\n",
       "      <td>INVOLUNTARY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243007</th>\n",
       "      <td>MERIT;ANOTHER OPPORTUNITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MERIT;BIRTH OF CHILD</td>\n",
       "      <td>MERIT;TRANSFER W/ JOB NUMBER CHANGE;MISCELLANE...</td>\n",
       "      <td>MERIT;BIRTH OF CHILD;TRANSFER W/O JOB NUMBER C...</td>\n",
       "      <td>MISCELLANEOUS DATA CHANGE;MISCELLANEOUS DATA C...</td>\n",
       "      <td>MISCELLANEOUS DATA CHANGE;MERIT;JOB CODE CHANG...</td>\n",
       "      <td>REHIRE;MISCELLANEOUS DATA CHANGE;TRANSFER W/O ...</td>\n",
       "      <td>ADDRESS CHANGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27421 INGLE RD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77784.65</td>\n",
       "      <td>15040 days, 00:00:00</td>\n",
       "      <td>41.178121</td>\n",
       "      <td>1966-09-19 00:00:00</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>30.548387</td>\n",
       "      <td>30.548387</td>\n",
       "      <td>82.741935</td>\n",
       "      <td>62.580645</td>\n",
       "      <td>30.548387</td>\n",
       "      <td>82.741935</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1799</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>743</td>\n",
       "      <td>Z</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5741</td>\n",
       "      <td>38</td>\n",
       "      <td>RE3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1997-05-19 00:00:00</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7265</td>\n",
       "      <td>TECANT</td>\n",
       "      <td>PTE</td>\n",
       "      <td>126346710662519</td>\n",
       "      <td>2001-01-01 00:00:00</td>\n",
       "      <td>10098474305</td>\n",
       "      <td>00963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BLOOMINGTON</td>\n",
       "      <td>IL</td>\n",
       "      <td>CORPORATE HEADQUARTERS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>94630.16</td>\n",
       "      <td>2375.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2302.85</td>\n",
       "      <td>2005.06</td>\n",
       "      <td>1902.96</td>\n",
       "      <td>1687.77</td>\n",
       "      <td>2194.62</td>\n",
       "      <td>316.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57368.17</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2903.26</td>\n",
       "      <td>0</td>\n",
       "      <td>2814.60</td>\n",
       "      <td>2261.02</td>\n",
       "      <td>1556.96</td>\n",
       "      <td>1687.77</td>\n",
       "      <td>1724.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>EMP</td>\n",
       "      <td>64628</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R2C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R2C2</td>\n",
       "      <td>R2C2</td>\n",
       "      <td>L2PRO</td>\n",
       "      <td>L2PRO</td>\n",
       "      <td>L2PRO</td>\n",
       "      <td>AOBJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>77784.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75409.26</td>\n",
       "      <td>73106.41</td>\n",
       "      <td>71101.35</td>\n",
       "      <td>69198.39</td>\n",
       "      <td>67510.62</td>\n",
       "      <td>65316.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2000-10-18 00:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>6.172070e+14</td>\n",
       "      <td>MO</td>\n",
       "      <td>38.75</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-11-23 00:00:00</td>\n",
       "      <td>24</td>\n",
       "      <td>85</td>\n",
       "      <td>126.162755</td>\n",
       "      <td>3840 days, 00:00:00</td>\n",
       "      <td>VOLUNTARY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243008</th>\n",
       "      <td>SALARY ADJUSTMENT;MERIT;PROMOTION;ANOTHER OPPO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MERIT</td>\n",
       "      <td>EMPLOYEE NEW HIRE;MISCELLANEOUS DATA CHANGE;MI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1944 CASTLEBERRY WAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23573.31</td>\n",
       "      <td>10249 days, 00:00:00</td>\n",
       "      <td>28.060809</td>\n",
       "      <td>1979-09-13 00:00:00</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>27.322581</td>\n",
       "      <td>27.322581</td>\n",
       "      <td>27.322581</td>\n",
       "      <td>7.870968</td>\n",
       "      <td>7.870968</td>\n",
       "      <td>27.322581</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>769</td>\n",
       "      <td>835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>N</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1402</td>\n",
       "      <td>730</td>\n",
       "      <td>PA2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-06-27 00:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4107</td>\n",
       "      <td>SFPPAR</td>\n",
       "      <td>PSA</td>\n",
       "      <td>607689561605309</td>\n",
       "      <td>2005-06-27 00:00:00</td>\n",
       "      <td>109018921</td>\n",
       "      <td>09921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HOMEWOOD</td>\n",
       "      <td>AL</td>\n",
       "      <td>OPERATIONS CENTER</td>\n",
       "      <td>27JUN2005</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>36585.60</td>\n",
       "      <td>478.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>394.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21532.15</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>108.53</td>\n",
       "      <td>0</td>\n",
       "      <td>169.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>EMP</td>\n",
       "      <td>35214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R2C1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R2C1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>23573.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21552.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2005-06-27 00:00:00</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>6.976274e+14</td>\n",
       "      <td>AL</td>\n",
       "      <td>38.75</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-10-05 00:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>27.269554</td>\n",
       "      <td>830 days, 00:00:00</td>\n",
       "      <td>VOLUNTARY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243009</th>\n",
       "      <td>MERIT;REGULAR RETIREMENT</td>\n",
       "      <td>MERIT;MISCELLANEOUS DATA CHANGE</td>\n",
       "      <td>MERIT</td>\n",
       "      <td>MERIT;SALARY PLAN CHANGE</td>\n",
       "      <td>MERIT</td>\n",
       "      <td>MERIT</td>\n",
       "      <td>LOCATION/FLOOR CHANGE;MERIT;MISCELLANEOUS DATA...</td>\n",
       "      <td>TRANSFER W/O JOB NUMBER CHANGE;MERIT;RATING SC...</td>\n",
       "      <td>MERIT;BENEFITS TRANSACTION</td>\n",
       "      <td>MERIT;JOB RECLASSIFICATION</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221 HIGHLAND GLEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212327.86</td>\n",
       "      <td>23153 days, 00:00:00</td>\n",
       "      <td>63.390761</td>\n",
       "      <td>1947-01-09 00:00:00</td>\n",
       "      <td>L</td>\n",
       "      <td>S</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>L</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>72.774194</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>72.774194</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2248</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>Z</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4958</td>\n",
       "      <td>9</td>\n",
       "      <td>FA5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1981-03-01 00:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3144</td>\n",
       "      <td>AGYAFE</td>\n",
       "      <td>NSA</td>\n",
       "      <td>23559263918344</td>\n",
       "      <td>1995-07-01 00:00:00</td>\n",
       "      <td>12603136335</td>\n",
       "      <td>26363</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STILLWATER</td>\n",
       "      <td>OK</td>\n",
       "      <td>AGENCY FIELD OFFICE(AFO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>170000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6774.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2102.26</td>\n",
       "      <td>4122.07</td>\n",
       "      <td>4041.25</td>\n",
       "      <td>6833.02</td>\n",
       "      <td>2885.16</td>\n",
       "      <td>9160.00</td>\n",
       "      <td>7045.54</td>\n",
       "      <td>124000.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>EMP</td>\n",
       "      <td>73069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R1C1</td>\n",
       "      <td>COMM</td>\n",
       "      <td>R2C1</td>\n",
       "      <td>R1C1</td>\n",
       "      <td>R2C2</td>\n",
       "      <td>R2C2</td>\n",
       "      <td>R2C2</td>\n",
       "      <td>IMPR</td>\n",
       "      <td>COMM</td>\n",
       "      <td>COMM</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>212327.86</td>\n",
       "      <td>176138.56</td>\n",
       "      <td>212327.86</td>\n",
       "      <td>212327.86</td>\n",
       "      <td>210225.60</td>\n",
       "      <td>206103.53</td>\n",
       "      <td>202062.28</td>\n",
       "      <td>195229.26</td>\n",
       "      <td>192344.10</td>\n",
       "      <td>183184.10</td>\n",
       "      <td>1981-03-01 00:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>5.960672e+14</td>\n",
       "      <td>OK</td>\n",
       "      <td>38.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-05-31 00:00:00</td>\n",
       "      <td>560</td>\n",
       "      <td>350</td>\n",
       "      <td>350.988727</td>\n",
       "      <td>10683 days, 00:00:00</td>\n",
       "      <td>VOLUNTARY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "br.printall(emplraw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step through the DF with bear\n",
    "1. list all columns\n",
    "2. find those that have all nulls\n",
    "3. find those that have any missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACTRES1', 'ACTRES10', 'ACTRES2', 'ACTRES3', 'ACTRES4', 'ACTRES5', 'ACTRES6', 'ACTRES7', 'ACTRES8', 'ACTRES9', 'ADDRCNT1', 'ADDRCNT10', 'ADDRCNT3', 'ADDRCNT5', 'ADDRESS1', 'ADDRESS2', 'ANNUAL_RT', 'Age_tdelta', 'Age_years', 'BIRTHDATE', 'BOX1', 'BOX10', 'BOX2', 'BOX3', 'BOX4', 'BOX5', 'BOX6', 'BOX7', 'BOX8', 'BOX9', 'COMPANY', 'COMP_FREQUENCY', 'CUR_DEPT_MOS', 'CUR_EFUNC_MOS', 'CUR_FUNC_MOS', 'CUR_GRADE_MOS', 'CUR_JOB_MOS', 'CUR_LOC_MOS', 'DEPTCNT1', 'DEPTCNT10', 'DEPTCNT3', 'DEPTCNT5', 'DIRECT_RPT_CNT', 'DIVISION_CODE_SFI', 'EEO1CODE', 'EFUNCCNT1', 'EFUNCCNT10', 'EFUNCCNT3', 'EFUNCCNT5', 'EMPL_CLASS', 'EMPL_TYPE', 'ETHNIC_GROUP', 'EXTFUNC_CNT', 'EXT_FUNC_ID_SFI', 'FLOORCNT1', 'FLOORCNT10', 'FLOORCNT3', 'FLOORCNT5', 'FLOR_SFI', 'FLSA_STATUS', 'FTE', 'FTPTCNT1', 'FTPTCNT10', 'FTPTCNT3', 'FTPTCNT5', 'FULLPART1', 'FULLPART10', 'FULLPART3', 'FULLPART5', 'FULL_PART_TIME', 'FUNCCNT1', 'FUNCCNT10', 'FUNCCNT3', 'FUNCCNT5', 'FUNC_CNT', 'FUNC_ID_SFI', 'GRADE', 'GRADECNT1', 'GRADECNT10', 'GRADECNT3', 'GRADECNT5', 'HIRE_DT', 'HUBIND', 'INTERN', 'JOBCNT1', 'JOBCNT10', 'JOBCNT3', 'JOBCNT5', 'JOBCODE', 'JOB_FAMILY', 'JOB_FUNCTION', 'KEY', 'LAST_HIRE_DT', 'LEGACY_DEPT_SFI', 'LOCATION', 'LOCCNT1', 'LOCCNT10', 'LOCCNT3', 'LOCCNT5', 'LOCSTCNT1', 'LOCSTCNT10', 'LOCSTCNT3', 'LOCSTCNT5', 'LOC_CITY', 'LOC_STATE', 'LOC_TYPE_DESCR_SFI', 'MAR_STATUS_DT', 'MAR_STA_SNAME_SFI', 'MAX_RT_ANNUAL', 'MERIT1', 'MERIT10', 'MERIT2', 'MERIT3', 'MERIT4', 'MERIT5', 'MERIT6', 'MERIT7', 'MERIT8', 'MERIT9', 'MIN_RT_ANNUAL', 'PARTFULL1', 'PARTFULL10', 'PARTFULL3', 'PARTFULL5', 'PERF1', 'PERF10', 'PERF2', 'PERF3', 'PERF4', 'PERF5', 'PERF6', 'PERF7', 'PERF8', 'PERF9', 'PER_ORG', 'POSTAL_SFI', 'PTFTCNT1', 'PTFTCNT10', 'PTFTCNT3', 'PTFTCNT5', 'RATE1', 'RATE10', 'RATE2', 'RATE3', 'RATE4', 'RATE5', 'RATE6', 'RATE7', 'RATE8', 'RATE9', 'REH_CNT', 'RELOCATE_ALL_SFI', 'RELO_STATE_CNT_SFI', 'REMOTE', 'REMOTE_SUPV', 'SAL1', 'SAL10', 'SAL2', 'SAL3', 'SAL4', 'SAL5', 'SAL6', 'SAL7', 'SAL8', 'SAL9', 'SERVICE_DT', 'SEX', 'SHIFT', 'SKEY', 'STATE', 'STD_HOURS', 'SUPVCNT1', 'SUPVCNT10', 'SUPVCNT3', 'SUPVCNT5', 'SUPV_DIFF_LOC', 'TELE_MOS', 'TERMINATION_DT', 'TOTAL_RPT_CNT', 'TOT_MO_SERVICE_SFI', 'Tenure_months', 'Tenure_tdelta', 'VOLINVOL', 'status']\n"
     ]
    }
   ],
   "source": [
    "# step through using bear\n",
    "#1 identify columns with missing values\n",
    "all_cols = emplraw.columns.tolist()\n",
    "print [c for c in all_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emplraw[emplraw.TOT_MO_SERVICE_SFI< 0]) # check that all have positive mos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REmove those that have negative tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242867, 184)\n"
     ]
    }
   ],
   "source": [
    "emplpos = emplraw[emplraw.TOT_MO_SERVICE_SFI>=0].copy()\n",
    "print np.shape(emplpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DROP those that have a grade of UNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43521 employees with the GRADE UNS will be dropped.\n"
     ]
    }
   ],
   "source": [
    "## remove seasonal/interns\n",
    "print \"{0} employees with the GRADE UNS will be dropped.\".format((emplpos.GRADE=='UNS').sum())\n",
    "empl1=emplpos[emplpos.GRADE!='UNS'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## look for those with Ontario\n",
    "sum(empl1.LOC_STATE=='ON')#, sum(ret_empl.LOC_STATE == 'ON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there were no columns that were universally null.\n"
     ]
    }
   ],
   "source": [
    "# check if any column has all missing\n",
    "chk_for_null_columns = br.get_columns_with_all_nulls(empl1)\n",
    "if len(chk_for_null_columns) > 0:\n",
    "    print \"WARNING there are {0} columns that are completely null.\".format(chk_for_null_columns)\n",
    "    print chk_for_null_columns\n",
    "    empl1.drop(chk_for_null_columns,axis=1,inplace=True)\n",
    "else:\n",
    "    print \"there were no columns that were universally null.\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199346, 184)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(empl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VOLUNTARY      90007\n",
       "NOT            69806\n",
       "INVOLUNTARY    38718\n",
       "UNKNOWN          497\n",
       "OTHER            318\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empl1.VOLINVOL.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and JOIN with BENEFITS info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function to load into pandas from hdfs (by copying to local filespace)\n",
    "def pandas_read_hdfs(infile,sep = ';',dtype_dict = None):\n",
    "    # copy the infile to the cwd\n",
    "    !hdfs dfs -get {infile} .\n",
    "    # identify the local file name\n",
    "    inname = infile[infile.rfind('/')+1:]\n",
    "    # read into a data frame\n",
    "    if dtype_dict != None:\n",
    "        df = pd.read_csv(inname,sep=sep,dtype =dtype_dict)\n",
    "    else:\n",
    "        df = pd.read_csv(inname,sep=sep)\n",
    "    # clean up local filespace\n",
    "    !rm {inname}\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bene_df = pandas_read_hdfs('/data/discovery/hrsepara/core/SR_BENEFIT.txt',dtype_dict={'KEY':np.str})\n",
    "bene_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bene_df.replace({'Y': 1, 'N':0},inplace=True)\n",
    "bene_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename 'COUNT               ' 'DEP_COUNT'\n",
    "bene_df = bene_df.rename(columns={'COUNT               ':'DEP_COUNT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_bene = pd.merge(empl1,bene_df,on='KEY',how = 'left')\n",
    "print np.shape(empl_bene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encode some categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## try to deal with location via zipcode\n",
    "empl_bene['zip5'] = empl_bene['POSTAL_SFI'].apply(lambda(x): truncate_postal_zip(x))\n",
    "empl_bene.drop('POSTAL_SFI',axis=1,inplace=True)\n",
    "empl_bene['zip5'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#empl_ben\n",
    "#encode the VOLINVOL column as ['INVOLUNTARY':2,'VOLUNTARY':1,'NOT':0,'\n",
    "empl_bene['sep_status'] = empl_bene['VOLINVOL'].replace({'NOT':0,'VOLUNTARY':1,'INVOLUNTARY':2,'OTHER':3,'UNKNOWN':3})\n",
    "print empl_bene.sep_status.value_counts()\n",
    "empl_bene.drop('VOLINVOL',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## deal with MAR_STA_SNAME_SFI\n",
    "empl_bene['mar_status'] = empl_bene['MAR_STA_SNAME_SFI'].replace({'MARRIED':0,'SINGLE':1,'LEG SEPAR':2})\n",
    "print empl_bene.mar_status.value_counts()\n",
    "empl_bene.drop('MAR_STA_SNAME_SFI',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill missing values in as zeros\n",
    "empl_bene[bene_df.columns] = empl_bene[bene_df.columns].fillna(0)\n",
    "empl_bene['DEP_COUNT'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Retired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the list of ACTRES1 for  ReTIREMENT\n",
    "uniq_action_reasons_1 = empl1.ACTRES1.unique()\n",
    "print len(uniq_action_reasons_1)\n",
    "temp_list = [x.split(';') for x in map(str,uniq_action_reasons_1)]\n",
    "act_reason_1_list = list(chain.from_iterable(temp_list))\n",
    "print len(act_reason_1_list)\n",
    "#ret_action_reasons_1 = [x for x in uniq_action_reasons_1 if 'RETIREMENT' in x]\n",
    "#print len(ret_action_reasons_1)\n",
    "act_reason_1_set = set(act_reason_1_list)\n",
    "print len(act_reason_1_set)\n",
    "possible_retire_codes = [x for x in act_reason_1_set if ('RET' in x and  'RETURN' not in x) ]\n",
    "possible_retire_codes.append('DISABILITY')\n",
    "print len(possible_retire_codes)\n",
    "possible_retire_codes.sort()\n",
    "print [c for c in possible_retire_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_retired(x,ret_codes =possible_retire_codes):\n",
    "    matched = [a for a in str(x).split(';') if a in ret_codes]\n",
    "    if len(matched):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_bene['retired'] = empl_bene.ACTRES1.apply(lambda x: identify_retired(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_bene.retired.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_unempl_rate(my_date,unempl):\n",
    "    try :\n",
    "        un_rate = unempl[unempl.date <= my_date]['value'].values[-1]\n",
    "    except IndexError:\n",
    "        un_rate = unempl['value'].ix[0]\n",
    "        \n",
    "    return un_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unempl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## assign unemployement_rate\n",
    "empl_bene['unempl_rate'] = empl_bene.TERMINATION_DT.apply(lambda x: assign_unempl_rate(x,unempl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_bene.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# identify the columns with missing data\n",
    "cols_with_missing_data = br.get_columns_with_nulls(empl_bene)\n",
    "if len(cols_with_missing_data)==0:\n",
    "    print \"there were no columns with missing data.\"\n",
    "else:\n",
    "    print \"WARNING there are {0} columns that have missing data.\".format(len(cols_with_missing_data))\n",
    "    print \"These columns are:\\t\",cols_with_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Partition these with missing values into categorical/boolean/numeric\n",
    "all_numeric_cols = br.get_numeric(empl_bene)\n",
    "all_cat_cols = br.get_categorical(empl_bene)\n",
    "print len(all_numeric_cols),len(all_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## which columns are numeric and have missing?\n",
    "print len(list(set(all_numeric_cols).intersection(set(cols_with_missing_data))))\n",
    "print len(list(set(all_cat_cols).intersection(set(cols_with_missing_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf = summarize_dataframe2(empl_bene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf.sort('nmissing',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder() #assigns unique integers to values base upon alphabetical order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### use scikitlearn to label encode binary features: \n",
    "* N--> 0, Y --> 1\n",
    "* M--> 1, F --> 0\n",
    "* A-->0, H--> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boolean_cols = sdf[(sdf.arity==2) & (sdf.datatype=='object')].Column.values\n",
    "print boolean_cols\n",
    "for c in boolean_cols:\n",
    "    print c, sdf[sdf.Column==c]['accepted values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in boolean_cols:\n",
    "    empl_bene[col] = label_encoder.fit_transform(empl_bene[col]) # use sklearn.preprocesing.LabelEncoder()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl_bene.rename(columns={'SEX':'Male','COMP_FREQUENCY':'hourly_comp'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf[sdf.arity==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_bene.FLSA_STATUS.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###check on various  encoded variables\n",
    "* arity = 3,FLSA_STATUS: map N: 0, Z: 1, X: -1\n",
    "* arity = 4, for 'SHIFT' map 'N' --> 0 and make FULL_PART_TIME categorical\n",
    "* arity = 5 -- make EMPL_TYPE to categorical\n",
    "* arity = 6, fine\n",
    "* arity = 7, make COMPANY categorical\n",
    "* arity = 8,9,10, fine\n",
    "* arity = 11: EEO1CODE to categorical\n",
    "* arity = 12: EMPL_CLASS to categorical\n",
    "* arity = 19: JOB_FUNCTION to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl_bene['FLSA_STATUS'] = empl_bene['FLSA_STATUS'].replace({'N':0,'Z':1,'X':-1}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map N to 0 for 'SHIFT'\n",
    "### convert shift == N to 0\n",
    "empl_bene.replace({'SHIFT':{'N':0}},inplace=True)\n",
    "empl_bene.SHIFT.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## begin to Standardize some of these other columns\n",
    "1. BOX columns: missing -> 0, L -> 1, S -> 2, H -> 3\n",
    "2. RATE columns: use dictionary; missing -> 0, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### For BOX replace S with 2, H with 3, L with 1\n",
    "box_col_list = [x for x in empl_bene.columns if x.startswith('BOX')]\n",
    "print len(box_col_list)\n",
    "empl_bene[box_col_list] = empl_bene[box_col_list].replace({'H':3,'S':2,'L':1}).copy()\n",
    "empl_bene[box_col_list].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpler conversion of RATE* to 3 levels: Low, Solid or High\n",
    "dictionary below from Ron Davis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sdf[sdf.arity==4]\n",
    "# dictonary of ratings\n",
    "ratings_dict = {}\n",
    "high_ratings = ['R3C3','R3C2','L3EXC','L3-EXC','OTSD','L3PRO','L3-PRO',\n",
    "                'EXCELS','SUPR','EXC/SUS','EXC/IMP','PEXE','ME - MEETS']\n",
    "low_ratings = ['IMPR','L1INC','L1DEV','L1PRO','NTAC','R1C2','R1C3','INC/DEC',\n",
    "               'INC/SUS','INC/IMP','INCNSSTE','L1EXC','UNAC','R1C1','L2-INC','L2INC',\n",
    "               'L1-EXC','L1-PRO','BEXP','L1-DEV','L1-INC','DNM - DOES','R3C1','R2C1']\n",
    "solid_ratings = ['R2C3','R2C2','L2EXC','L2PRO','EXPE','/EX/','COMM','AOBJ','EXC/DEC',\n",
    "                 'PRO/IMP','PRO/SUS','PRO/DEC','SM - SUCCE','MS - MEETS','L2DEV','L3INC',\n",
    "                 'L3DEV','L2-DEV','L3-INC','ACPT','L3-DEV','L2-EXC','L2-PRO']\n",
    "\n",
    "# initialize\n",
    "for rating in high_ratings:\n",
    "    ratings_dict[rating] = 3\n",
    "for rating in low_ratings:\n",
    "    ratings_dict[rating]=1\n",
    "for rating in solid_ratings:\n",
    "    ratings_dict[rating]=2\n",
    "\n",
    "\n",
    "# function for assigning\n",
    "def assign_simple_rating(x,my_dict = ratings_dict):\n",
    "    try:\n",
    "        rval = my_dict[x.strip()]\n",
    "    except KeyError:\n",
    "        rval = 0\n",
    "    except AttributeError:\n",
    "        rval = 0\n",
    "    return rval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### For Rate replace solid with 2, High with 3, Low with 1\n",
    "rate_col_list = [x for x in empl_bene.columns if x.startswith('RATE')]\n",
    "print len(rate_col_list)\n",
    "empl_bene[rate_col_list] = empl_bene[rate_col_list].applymap(lambda x: assign_simple_rating(x))\n",
    "#empl[rate_col_list] = empl[rate_col_list].map(lambda(x): assign_simple_rating(x)).copy()\n",
    "empl_bene[rate_col_list].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save the data to a file\n",
    "empl_bene.to_csv('employee_dataframe9.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_bene=pd.read_csv('employee_dataframe9.tsv',sep='\\t',dtype={'zip5':np.str,'KEY':np.str,'SKEY':np.str})\n",
    "empl_bene.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_bene[box_col_list].fillna(0,inplace=True)#.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove grades starting with 'L' and 'AT'\n",
    "As we discussed, you’re already excluding seasonal employees, interns, and agency interns.  Let’s also exclude the L-Level executive employees are in the LDSH job group with job grades L1 to L10 (i.e., all job grades starting with “L”).  Let’s also  exclude Air Transportation as we don’t foresee applying the model to them either.  Their job group is AIRT with job grades AT1 to AT8 (i.e., all job grades starting with “AT”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_grades = empl_bene.GRADE.unique()\n",
    "print len(list_of_grades)\n",
    "grades_to_drop = [x for x in map(str,list_of_grades) if (x.startswith('L') or x.startswith('AT'))]\n",
    "print len(grades_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[a for a in em2002[em2002.FULL_PART_TIME_X==1].columns if a.endswith('months')]\n",
    "em2002[em2002.FULL_PART_TIME_X==1].Tenure_months.describe()#hist(normed=True)\n",
    "#em2002[em2002.FULL_PART_TIME_X!=1].Tenure_months.hist(normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002[em2002.FULL_PART_TIME_X==0].Tenure_months.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_bene.FULL_PART_TIME.value_counts(), empl_bene.EMPL_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print grades_to_drop,len(grades_to_drop)\n",
    "grades_to_drop.remove('LS2')\n",
    "grades_to_drop.remove('LS1')\n",
    "grades_to_drop.remove('LS3')\n",
    "grades_to_drop.remove('LM1')\n",
    "grades_to_drop.remove('LM2')\n",
    "grades_to_drop.remove('LP1')\n",
    "print len(grades_to_drop),grades_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"removing these {0} grades removes {1} employees\".format(len(grades_to_drop),len(empl_bene[empl_bene.GRADE.isin(grades_to_drop)]))\n",
    "empl=empl_bene[~empl_bene.GRADE.isin(grades_to_drop)].copy()\n",
    "print np.shape(empl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keep only those that are known (vol,invol, not) per discussion on April 22, 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl = empl[empl.sep_status <=2]\n",
    "print np.shape(empl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop PER_ORG (all the same value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl.drop('PER_ORG',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create a column for terminated (i.e. separated but NOT retired)\n",
    "empl['terminated']= 0\n",
    "my_rows = empl[(empl.status==1) & (empl.retired==0)].index\n",
    "print \"Out of {0} rows, {1} are separated and not retired.\".format(len(empl),len(my_rows))\n",
    "#sum(empl_df['terminated']))#, len(my_rows)\n",
    "empl.loc[my_rows,'terminated']=1\n",
    "print sum(empl.terminated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a Time Slice to consider \n",
    "* only after 2002-01-01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date0 = '2002-01-01'\n",
    "em2002 = empl.ix[empl.TERMINATION_DT>=date0].copy()\n",
    "print date0, len(em2002)\n",
    "print \"--------- STATUS \"\n",
    "print em2002.status.value_counts()\n",
    "print \"--------- TERMINATED\"\n",
    "print em2002.terminated.value_counts()\n",
    "print \"--------- RETIRED\"\n",
    "print em2002.retired.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assign random indices to this df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_indices = list(range(em2002.KEY.nunique()))\n",
    "print len(list_of_indices )\n",
    "random.seed(883321)\n",
    "#new_indices = [x for x in random.shuffle(list_of_indices)\n",
    "random.shuffle(list_of_indices)#, len(list_of_indices))\n",
    "em2002.index = list_of_indices # note that random.shuffle does this shuffling inplace\n",
    "em2002.sort_index(inplace=True)\n",
    "em2002.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a data frame with just dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_dates=pd.DataFrame()\n",
    "empl_dates[['hire_tstmp','term_tstmp','birth_tstmp']] = em2002[['HIRE_DT','TERMINATION_DT','BIRTHDATE']].apply(lambda x: pd.to_datetime(x))\n",
    "empl_dates[['hire_year','term_year','birth_year']]= empl_dates[['hire_tstmp','term_tstmp','birth_tstmp']].apply(lambda x: x.dt.year)\n",
    "empl_dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a column for Age at hire date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## now calculate age at hire\n",
    "hire_age_tdelta = empl_dates['hire_tstmp']-empl_dates['birth_tstmp']#)/np.timedelta64(1,'D')\n",
    "# convert to days, months or years\n",
    "empl_dates['hire_age'] = hire_age_tdelta/np.timedelta64(1,'Y')\n",
    "\n",
    "#empl_dates.drop('hire_age_tdelta',axis=1,inplace=True)\n",
    "em2002['hire_age']=empl_dates['hire_age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define some superfluous columns (don't want these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_to_omit = []\n",
    "#columns_to_omit.append('PER_ORG')\n",
    "columns_to_omit.append('ADDRESS1')\n",
    "columns_to_omit.append('ADDRESS2')\n",
    "columns_to_omit.append('LOC_CITY')\n",
    "#columns_to_omit.append('LOC_TYPE_DESCR_SFI')\n",
    "columns_to_omit.append('STATE')\n",
    "columns_to_omit.append('zip5')\n",
    "columns_to_omit.append('SKEY')\n",
    "columns_to_omit.append('KEY')\n",
    "columns_to_omit.append('MAR_STATUS_DT')\n",
    "columns_to_omit.append('SAL1')\n",
    "for col in empl.columns:\n",
    "    if col.startswith('ACTRE'):\n",
    "        columns_to_omit.append(col)\n",
    "\n",
    "print len(columns_to_omit), columns_to_omit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mos_cols = [x for x in em2002.columns if x.endswith('MOS')]\n",
    "print len(mos_cols), mos_cols\n",
    "date_cols = [x for x in em2002.columns if x.endswith('DT')]\n",
    "date_cols.append('BIRTHDATE')\n",
    "date_cols.append('Tenure_tdelta')\n",
    "date_cols.append('Age_tdelta')\n",
    "print len(date_cols), date_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_to_omit_2 = columns_to_omit+date_cols\n",
    "len(columns_to_omit_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_columns_list = em2002.columns.tolist()\n",
    "cols_to_consider1 = list(set(all_columns_list)-set(columns_to_omit_2))\n",
    "list_with_missing2 = br.get_columns_with_nulls(em2002[cols_to_consider1])\n",
    "print len(list_with_missing2), len(cols_to_consider1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_categorical_1 = br.get_categorical(em2002[cols_to_consider1])\n",
    "for c in cols_to_categorical_1:\n",
    "    print c, len(em2002[c].unique()), sum(em2002[c].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_factorized_df(input_df,column_name):\n",
    "    tmp_df = pd.get_dummies(input_df[column_name],prefix=column_name)\n",
    "    # now drop the largest category\n",
    "    lgst_category = input_df[column_name].value_counts().index[0]\n",
    "    #print tmp_df.shape, tmp_df.columns\n",
    "    #print lgst_category\n",
    "    base_category = column_name+'_'+str(lgst_category)\n",
    "    tmp_df.drop(base_category,axis=1,inplace=True)\n",
    "    print tmp_df.shape, base_category\n",
    "    return tmp_df,base_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_cols2_as_floats =[]\n",
    "missing_cols2_as_cats = []\n",
    "for c in list_with_missing2:\n",
    "    my_dtype = em2002[c].dtype\n",
    "    \n",
    "    if my_dtype == np.float64:\n",
    "        \n",
    "        missing_cols2_as_floats.append(c)\n",
    "    else:\n",
    "        print c, sum(em2002[c].isnull()), em2002[c].dtype\n",
    "        missing_cols2_as_cats.append(c)\n",
    "        \n",
    "print len(missing_cols2_as_floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em2002['LOC_STATE'].fillna('XX',inplace=True)\n",
    "em2002['GRADE'].fillna('XXX',inplace=True)\n",
    "em2002['JOB_FAMILY'].fillna('XXXXX',inplace=True)\n",
    "em2002['LOC_TYPE_DESCR_SFI'].fillna('UNKNOWN LOCATION TYPE',inplace=True)\n",
    "em2002['JOB_FUNCTION'].fillna('XXX',inplace=True)\n",
    "cols_to_survival = ['GRADE','JOB_FAMILY','JOB_FUNCTION','LOCATION']\n",
    "cols_to_cat3 = ['EMPL_CLASS','EEO1CODE','EMPL_TYPE','FULL_PART_TIME']\n",
    "cols_to_label_encode = ['LOC_TYPE_DESCR_SFI','LOC_STATE']\n",
    "\n",
    "em2002.drop('LEGACY_DEPT_SFI',axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002.COMPANY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dummified dataframe.\n",
    "base_category_list =[]\n",
    "dummy_categories_list = []\n",
    "print em2002.shape\n",
    "for acol in cols_to_cat3:\n",
    "    print acol\n",
    "    t_df,bc1 = create_factorized_df(em2002,acol)\n",
    "    # drop the original column\n",
    "    #new_col_names = t_df.columns.tolist()\n",
    "    #dummy_categories_list+=new_col_names\n",
    "    em2002.drop(acol,inplace=True,axis=1)\n",
    "    # append the factorized categories\n",
    "    em2002 = pd.concat([em2002,t_df],axis=1)\n",
    "    base_category_list.append(bc1)\n",
    "\n",
    "print em2002.shape,len(base_category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for acol in cols_to_cat3:\n",
    "    #if acol != 'EMPL_CLASS':\n",
    "    cols_to_consider1.remove(acol)\n",
    "    added_cols = [x for x in em2002.columns if x.startswith(acol)]\n",
    "    cols_to_consider1+=added_cols\n",
    "cols_to_consider1.remove('LEGACY_DEPT_SFI')\n",
    "len(cols_to_consider1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Label Encode those 2 columns: LOC_STATE and LOC_TYPE_DESCR_SFI\n",
    "for acol in cols_to_label_encode:\n",
    "    label_encoder.fit_transform(em2002[acol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in cols_to_consider1 if 'FUNC_ID' in x]\n",
    "# add these to the cols_to_survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002.EXT_FUNC_ID_SFI.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(em2002.FUNC_ID_SFI.unique()), len(em2002.EXT_FUNC_ID_SFI.unique())\n",
    "cols_to_survival.append('FUNC_ID_SFI')\n",
    "cols_to_survival.append('EXT_FUNC_ID_SFI')\n",
    "cols_to_survival\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_list_of_missing_cols = br.get_columns_with_nulls(em2002[cols_to_consider1])\n",
    "missing_counts_cols = [x for x  in my_list_of_missing_cols if 'CNT' in x]\n",
    "print missing_counts_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make these 'counts' go to -1 for missing\n",
    "for acolumn in missing_counts_cols:\n",
    "    em2002.fillna({acolumn: -1},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace the boxes with 0 \n",
    "chg_to_zero_cols = ['BOX1','BOX2','BOX3','BOX4','BOX5','BOX6','BOX7','BOX8','BOX9','BOX10']\n",
    "for box_col in chg_to_zero_cols:\n",
    "    em2002.fillna({box_col: 0},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_list_missing_2 = br.get_columns_with_nulls(em2002[cols_to_consider1])\n",
    "print len(my_list_missing_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in em2002.columns if x.startswith('EMPL_CLASS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns=[]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.columns]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct values for the floats:\n",
    "* if min value (MIN_RT_ANNUAL)\n",
    "    * is zero reset to min value\n",
    "    * is nan reset to median?\n",
    "* if max value  (MAX_RT_ANNUAL) is \n",
    "    * zero reset to min value\n",
    "    * nan reset to median?\n",
    "    \n",
    "#### examine how many of these are the cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sum(em2002.MAX_RT_ANNUAL <= 1), sum(em2002.ANNUAL_RT <= 1), sum(em2002.MIN_RT_ANNUAL<=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_value = 0\n",
    "salary_cols = ['MIN_RT_ANNUAL','MAX_RT_ANNUAL','ANNUAL_RT']\n",
    "for col in salary_cols:\n",
    "    #my_mtd = 'max'\n",
    "    my_data = em2002[em2002[col]!=my_value][col]\n",
    "    print col, my_data.min(), my_data.max(), my_data.mean(), my_data.median()\n",
    "#em2002[em2002['MAX_RT_ANNUAL']!=my_value]['MAX_RT_ANNUAL'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(em2002[em2002['ANNUAL_RT']==0])#['ANNUAL_RT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002[em2002['MAX_RT_ANNUAL']<999999]['MAX_RT_ANNUAL'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002[em2002['ANNUAL_RT']==0][['BIRTHDATE','TERMINATION_DT','HIRE_DT','GRADE','MAX_RT_ANNUAL']]#[cols_to_consider1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[a for a in em2002.GRADE.unique() if a.startswith('C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(em2002[em2002.GRADE == 'C23'][['TERMINATION_DT','ANNUAL_RT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FixZeroValues(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_fix, value_to_replace=0, method='median'):\n",
    "        #criteria_coef=('percentile', 5), fill_with='nearest_value', \n",
    "        #         method='both', columns_to_fix='all', rows_to_scan='all'):\n",
    "        #def __init__(self, categorical_columns, method='factorize', rows_to_scan='all'):\n",
    "        \"\"\"\n",
    "        A class that can be inserted into a pipeline.\n",
    "        \n",
    "        This will fix the values in numeric columns of the dataframe that are artificially assigned \n",
    "        as zeros. Columns with all nulls or categorical values will not be changed.\n",
    "        Missing values will remain missing. Inf values will be fixed.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        X: Pandas dataframe\n",
    "        \n",
    "        columns_to_fix: a list of column names, the columns should be numerical.\n",
    "        \n",
    "        value_to_replace: int or float. This is the 'zero' that is being replaced\n",
    "            TODO make this able to accept a dictionary?\n",
    "        \n",
    "        method: str, default='median'. How the zero values will be replaced.\n",
    "            Others can be 'mean', 'min', 'max', or a specific value (entered as a string).\n",
    "        \n",
    "        \n",
    "        returns a pandas dataframe\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.columns_to_fix = columns_to_fix\n",
    "        self.value_to_replace = value_to_replace\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.map_values = {}\n",
    "        self.new_values = {}\n",
    "        \n",
    "        for col in self.columns_to_fix:\n",
    "            my_values = X[col]!=value_to_\n",
    "            if self.method == 'median':\n",
    "                map_values = X[col].\n",
    "                 yy = y[:rows_to_scan_in].copy()\n",
    "                self.map_values[col] = dict(pd.crosstab(XX[col], y).apply(lambda x: x[1]/float(x.sum()), axis=1))\n",
    "        if self.criteria_coef != 'all':\n",
    "            \n",
    "            self.max_val = {}\n",
    "            self.min_val = {}\n",
    "            self.coef = self.criteria_coef[1]\n",
    "            self.criteria = self.criteria_coef[0]\n",
    "            rows_to_scan_in = get_rows_to_scan(self.rows_to_scan, X.shape[0])\n",
    "                      \n",
    "            if self.columns_to_fix == 'auto':\n",
    "                self.columns_to_fix_in = get_numeric(X)\n",
    "            else:\n",
    "                self.columns_to_fix_in = get_list_of_columns_to_check(self.columns_to_fix, X.columns)\n",
    "\n",
    "            temp_numeric = get_numeric(X[self.columns_to_fix_in])\n",
    "            temp_not_numeric = set(self.columns_to_fix_in)-set(temp_numeric)\n",
    "            if len(temp_not_numeric) > 0:\n",
    "                raise Exception('Columns '+str(list(temp_not_numeric))+' are not numeric!')\n",
    "            XX = X[:rows_to_scan_in].copy()\n",
    "            for col in self.columns_to_fix_in:\n",
    "                temp = XX[col][np.isfinite(XX[col])]\n",
    "                if self.criteria == 'percentile':\n",
    "                    self.max_val[col] = np.percentile(temp, 100-self.coef)\n",
    "                    self.min_val[col] = np.percentile(temp, self.coef)\n",
    "                elif self.criteria == 'sd':\n",
    "                    self.max_val[col] = np.mean(temp)+self.coef*np.std(temp)\n",
    "                    self.min_val[col] = np.mean(temp)-self.coef*np.std(temp)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if self.criteria_coef != 'all':\n",
    "            XX = X.copy()\n",
    "            if self.fill_with == 'nearest_value':\n",
    "                if self.method == 'upper':\n",
    "                    for col in self.columns_to_fix_in:\n",
    "                        XX.loc[XX[col] > self.max_val[col], col] = self.max_val[col]\n",
    "                elif self.method == 'lower':\n",
    "                    for col in self.columns_to_fix_in:\n",
    "                        XX.loc[XX[col] < self.min_val[col], col] = self.min_val[col]\n",
    "                else:\n",
    "                    for col in self.columns_to_fix_in:\n",
    "                        XX.loc[XX[col] > self.max_val[col], col] = self.max_val[col]\n",
    "                        XX.loc[XX[col] < self.min_val[col], col] = self.min_val[col]\n",
    "            elif self.fill_with == 'missing':\n",
    "                if self.method == 'upper':\n",
    "                    for col in self.columns_to_fix_in:\n",
    "                        XX.loc[XX[col] > self.max_val[col], col] = np.nan\n",
    "                elif self.method == 'lower':\n",
    "                    for col in self.columns_to_fix_in:\n",
    "                        XX.loc[XX[col] < self.min_val[col], col] = np.nan\n",
    "                else:\n",
    "                    for col in self.columns_to_fix_in:\n",
    "                        XX.loc[XX[col] > self.max_val[col], col] = np.nan\n",
    "                        XX.loc[XX[col] < self.min_val[col], col] = np.nan\n",
    "            return XX\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print em2002.MIN_RT_ANNUAL.describe()\n",
    "print sum(em2002.MIN_RT_ANNUAL <=1)\n",
    "em2002[em2002.MIN_RT_ANNUAL>1].MIN_RT_ANNUAL.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW to define the imputation approaches\n",
    "* by Mean/median/min?\n",
    "* by Survival function\n",
    "* by counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_recent_missing_col = [ c for c in my_list_missing_2 if c.endswith('1')]\n",
    "most_recent_missing_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now I need to split into build-eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2002.terminated.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(em2002.columns)\n",
    "cols_to_survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(columns_to_omit), len(columns_to_omit_2)\n",
    "columns_to_omit_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_label_encode.append('COMPANY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(em2002.columns.tolist()) - set(columns_to_omit_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(cols_to_consider1), len(my_list_missing_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(a,em2002[a].isnull().sum(), em2002[a].median(), em2002[a].mean()) for a in my_list_missing_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cols_to_consider1\n",
    "* Create a test train split\n",
    "* then use pipelines for the following\n",
    "* try to apply class that adjusts the missing values in my_list_missing_2 to median?\n",
    "* try to apply class that adjusts the zero values of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_to_omit_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert tenure_months into tenure Years \n",
    " and drop the tenure_months columns. Tenure in years is just easier to think about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print np.shape(em2002)\n",
    "em2002['Tenure_years'] = em2002['Tenure_months']/12.\n",
    "em2002.drop('Tenure_months',axis=1,inplace=True)\n",
    "np.shape(em2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace in the cols_to_consider list\n",
    "cols_to_consider = [a for a in cols_to_consider1 if not a.startswith('Tenure')]\n",
    "print len(cols_to_consider),len(cols_to_consider1)\n",
    "cols_to_consider.append('Tenure_years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encode the 3 like that\n",
    "* and alter the cols_to_consider listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in cols_to_label_encode:\n",
    "    newcol = 'le_'+col.lower()\n",
    "    cols_to_consider.remove(col)\n",
    "    cols_to_consider.append(newcol)\n",
    "    print col,newcol\n",
    "    em2002[newcol] = label_encoder.fit_transform(em2002[col]) # use sklearn.preprocesing.LabelEncoder()\n",
    "\n",
    "print len(cols_to_consider)\n",
    "cols_to_consider[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the training data into two parts\n",
    "from sklearn.cross_validation import train_test_split\n",
    "emBuild, emEval = train_test_split(em2002, test_size=0.25, random_state=92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.shape(emBuild), np.shape(emEval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset the indices of these two sets and the dates\n",
    "emBuild_dates = empl_dates.ix[emBuild.index].copy()\n",
    "emEval_dates = empl_dates.ix[emEval.index].copy()\n",
    "#build_indices = emBuild.index\n",
    "#eval_indices = emEval.index\n",
    "emBuild.index = np.arange(0,len(emBuild))\n",
    "emBuild_dates.index = np.arange(0,len(emBuild))\n",
    "emEval.index = np.arange(0,len(emEval))\n",
    "emEval_dates.index= np.arange(0,len(emEval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_consider_A = br.get_numeric(emBuild[cols_to_consider])\n",
    "print len(numeric_consider_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply the survival function to the remaining 6\n",
    "* first calculate the tenure in years (done above)\n",
    "* create dictionary based upon the build set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mthl_tenure_range = np.linspace(0,65,781)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_survival_functions(df,time_col, event_col, col_name,num_cutoff = 40,timerange =mthl_tenure_range):\n",
    "    \n",
    "    \"\"\" Function to generically return a dataframe of survival function, grouped by some categorical column\n",
    "    inputs:\n",
    "        df --> database to derive survival functions from\n",
    "        time_col --> the temporal column to use for SF modeling (Kaplan Meier fitter applied)\n",
    "        event_col --> the truncated column to use for SF modeling\n",
    "        col_name --> the column to group up and determine KMF sf for\n",
    "        num_cutoff --> number of groups to consider\n",
    "        timerange --> min and max range\n",
    "    outputs:\n",
    "        survivalfunc_df --> a data frame that contains survival function.\n",
    "\n",
    "    other options:\n",
    "        *frac_cutoff --> the fraction of unique elements that will be kept as separate groups\n",
    "        *min_size_cutoff --> min size to use for the cutoff.\n",
    "        * these last two are not implemented\n",
    "    \"\"\"\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    kmf=KaplanMeierFitter()\n",
    "    # create example for all cases -- serves as background\n",
    "    # create a time range\n",
    "    \n",
    "    kmf.fit(df[time_col],timeline=timerange,event_observed=df[event_col],label='all')\n",
    "    survivalfunc_df = pd.DataFrame(kmf.survival_function_)\n",
    "    # groupify the dataframe\n",
    "    grp_value_counts = df[col_name].value_counts()\n",
    "    #if frac_cutoff == None:\n",
    "    #    #by default take 15 %\n",
    "    #    frac_cutoff = .15 \n",
    "    #top_n_groups = int(frac_cutoff *len(grp_value_counts))\n",
    "    #if min_size_cutoff == None:\n",
    "        # by default \n",
    "    # Take the top num_cutoff groups\n",
    "    #my_grps = grp_value_counts.ix[:num_cutoff].index.tolist() \n",
    "    my_grps = grp_value_counts.iloc[:num_cutoff].index.tolist() \n",
    "    \n",
    "    # make a list of elements in each of these groups\n",
    "    grp_dict = {}\n",
    "    for grp in my_grps: \n",
    "        grp_dict[grp] = df[df[col_name] == grp].index.tolist()\n",
    "    # loop through grps and create kmf survival function\n",
    "    for i,jgrp in enumerate(my_grps):\n",
    "        j_idx = grp_dict[jgrp]\n",
    "        #print i, jgrp, len(j_idx)\n",
    "        kmf.fit(df[time_col].ix[j_idx],timeline=mthl_tenure_range,event_observed=df[event_col].ix[j_idx],label=str(jgrp))\n",
    "        survivalfunc_df = pd.concat([survivalfunc_df,kmf.survival_function_],axis=1)\n",
    "    \n",
    "    \n",
    "    return survivalfunc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_first_time_survival(sfdf,thresh=0.5):\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # assign all value to the default\n",
    "    default_value = sfdf[sfdf['all']<=thresh].index[0]\n",
    "    median_survival_dict = defaultdict(lambda: default_value)\n",
    "    for c in sfdf.columns[1:]:\n",
    "        #print c\n",
    "        try:\n",
    "            my_sf_date = sfdf[sfdf[c]<=thresh].index[0]\n",
    "        except IndexError: # because never reached that threshold value\n",
    "            my_sf_date = sfdf.index[-1]\n",
    "        except KeyError: # because of type of the key\n",
    "            my_sf_date = sfdf[sfdf[int(c)]<=thresh].index[0]\n",
    "\n",
    "        median_survival_dict[c]=my_sf_date\n",
    "        \n",
    "    return median_survival_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,col in enumerate(cols_to_survival):\n",
    "    print col, emBuild[col].unique().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#job_related_cols = ['JOBCODE','grade_code','job_fcode']\n",
    "#new_job_sf_cols = ['surv_med_jobcode','surv_med_grade','surv_med_jobfamily']\n",
    "list_sf_dict = []\n",
    "new_surv_med_cols =[]\n",
    "for i, col in enumerate(cols_to_survival):\n",
    "    # check type of column and cast as str\n",
    "    my_dtype = emBuild[col].unique().dtype\n",
    "    if my_dtype == 'float64':\n",
    "        #print col\n",
    "        emBuild[col].apply(lambda x: np.str(x))    \n",
    "        emEval[col].apply(lambda x: np.str(x))    \n",
    "\n",
    "    num_cutoff=40\n",
    "    newcol = 'survmed_'+col.lower()\n",
    "    nuniq = len(emBuild[col].unique())\n",
    "    if nuniq < num_cutoff:\n",
    "        num_cutoff = nuniq\n",
    "    else:\n",
    "        num_cutoff = int(nuniq/4.)\n",
    "\n",
    "    frac_accounted_for = emBuild[col].value_counts().iloc[:num_cutoff].sum()/float(len(emBuild))\n",
    "    print i,col,newcol, nuniq, num_cutoff,num_cutoff/float(nuniq),frac_accounted_for\n",
    "    # I want to make this fraction close to 80%?\n",
    "    \n",
    "    #len(emBuild[col].value_counts())\n",
    "    #if nuniq < num_cutoff:\n",
    "    #    num_cutoff = nuniq\n",
    "    # calc survival functions\n",
    "    sf_df = calculate_survival_functions(emBuild,'Tenure_years', 'terminated', col,num_cutoff)\n",
    "    ## create the dictionary\n",
    "    list_sf_dict.append(return_first_time_survival(sf_df,thresh=0.5))\n",
    "    # apply the dictionary and create a new column\n",
    "    new_surv_med_cols.append(newcol)\n",
    "    emBuild[newcol]= emBuild[col].apply(lambda x: list_sf_dict[i][x])\n",
    "    emEval[newcol] = emEval[col].apply(lambda x: list_sf_dict[i][x])\n",
    "    cols_to_consider.remove(col)\n",
    "    cols_to_consider.append(newcol)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## July 9, 2015 made it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## examine the values of these new columns\n",
    "emBuild.survmed_grade.hist(label='Grade',bins=30)\n",
    "emBuild.survmed_job_family.hist(alpha=0.7,label='Jobfamily',bins=30)\n",
    "emBuild.survmed_job_function.hist(alpha=0.4,label='jobfcn',bins=30)\n",
    "emBuild.survmed_location.hist(alpha=0.4,bins=30,label='location')\n",
    "plt.legend(loc=2)\n",
    "plt.title('Histograms of Median Survival time (months) from EmBuild set')\n",
    "#emBuild.plot(kind='scatter',x =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin by looking at collinearity of the data in emBuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_with_missing_numeric = br.get_columns_with_nulls(emBuild[cols_to_consider])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### okay because of these missing values I need to impute/fill in\n",
    "* try using median value (based upon emBuild)\n",
    "* also apply fix_outliers to ANNUAL_RT, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = emBuild.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.ANNUAL_RT.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if categorical columns are included, an error will be raised\n",
    "# this class is usually inserted after ConvertCategorical in pipelines\n",
    "fixout=br.FixNumericOutlier(columns_to_fix=['ANNUAL_RT','MIN_RT_ANNUAL'], criteria_coef=('percentile', 10), \n",
    "                            method = 'lower', fill_with='nearest_value')\n",
    "                            \n",
    "X1 = fixout.fit(X).transform(X)\n",
    "print X1['ANNUAL_RT'].describe()\n",
    "X[['mod_annual_rt','mod_min_rt_annual']]=X1[['ANNUAL_RT','MIN_RT_ANNUAL']]\n",
    "fixout_max = br.FixNumericOutlier(columns_to_fix=['MAX_RT_ANNUAL'], criteria_coef=('percentile', 10), \n",
    "                            method = 'both', fill_with='nearest_value')\n",
    "X1 = fixout_max.fit(X).transform(X)\n",
    "X['mod_max_rt_annual']=X1['MAX_RT_ANNUAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp = br.ImputeData(method='median', columns_to_impute=cols_with_missing_numeric, impute_inf=False, keep_dummies=False)\n",
    "X1 = imp.fit(X).transform(X)\n",
    "X[cols_with_missing_numeric]=X1[cols_with_missing_numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in ['ANNUAL_RT','MIN_RT_ANNUAL','MAX_RT_ANNUAL']:\n",
    "    new_a = 'mod_'+a.lower()\n",
    "    cols_to_consider.remove(a)\n",
    "    cols_to_consider.append(new_a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "br.perfect_collinearity_test(X[cols_to_consider])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_columns = cols_to_consider\n",
    "\n",
    "#model_columns.remove('retired')\n",
    "for c in model_columns:\n",
    "    if c.startswith('RATE'):\n",
    "        model_columns.remove(c)\n",
    "        print c, len(model_columns)\n",
    "\n",
    "        \n",
    "print len(model_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[c for c in model_columns if c.startswith('RATE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_columns.remove('terminated')\n",
    "model_columns.remove('status')\n",
    "model_columns.remove('sep_status')\n",
    "print len(model_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "br.perfect_collinearity_test(X[model_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_columns.remove('unempl_rate') # hard to predict this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## progress toward the Temporal Fold work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_temporal_kfolds(dates_df,date_range,time_delta):\n",
    "    min_date = pd.to_datetime(date_range[0])\n",
    "    max_date = pd.to_datetime(date_range[-1])\n",
    "    my_index = dates_df[(dates_df.term_tstmp>=min_date)].index\n",
    "    # calculate number of kfolds\n",
    "    date_span_years = np.int(np.round((max_date-min_date).days/365.24,0))\n",
    "    nfolds = date_span_years - time_delta\n",
    "    print date_span_years, time_delta, nfolds, len(my_index)\n",
    "    all_pairs = list(itertools.combinations(date_range,2))\n",
    "    # now filter if difference in time  == time_delta\n",
    "    filtered_pairs = []\n",
    "    for i0,i1 in all_pairs:\n",
    "        if int(i1[:4])-int(i0[:4]) == time_delta:\n",
    "            filtered_pairs.append([i0,i1])\n",
    "            #print i0,i1\n",
    "    print len(filtered_pairs)\n",
    "    # now process each of these filtered pairs\n",
    "    kf = []\n",
    "    for j0,j1 in filtered_pairs: # omit the last one because it has no\n",
    "        start_date = pd.to_datetime(j0)\n",
    "        end_date = pd.to_datetime(j1)\n",
    "        #print j0,j1#,len(k)\n",
    "        \n",
    "        \n",
    "        kfold_idx = dates_df[(dates_df.term_tstmp >= start_date) & (dates_df.hire_tstmp<start_date)].index\n",
    "        after_idx = dates_df[(dates_df.hire_tstmp>=end_date)].index\n",
    "        before_idx = list(set(my_index)-set(kfold_idx)-set(after_idx))\n",
    "        #temporal_kfold(dates_df[dates_df.term_tstmp>=min_date],start_date,end_date)\n",
    "        #print \"\\t\",len(kfold_idx), len(after_idx),len(before_idx)\n",
    "        \n",
    "        # combined out of fold\n",
    "        not_kfold_idx = list(set(after_idx).union(set(before_idx)))\n",
    "        \n",
    "        print j0,j1,len(kfold_idx),len(not_kfold_idx)\n",
    "        kf.append([kfold_idx,not_kfold_idx])\n",
    "    \n",
    "    return kf,filtered_pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_years(paired_times,indices,dates_df,df,cols_to_alter = ['Age_years','Tenure_years']):\n",
    "    # calc the Age at beginnning of time period\n",
    "    ## now calculate age at hire\n",
    "    reset_age_tdelta = pd.to_datetime(paired_times[0])-dates_df['birth_tstmp']#)/np.timedelta64(1,'D')\n",
    "    reset_tenure_tdelta = pd.to_datetime(paired_times[0])-dates_df['hire_tstmp']#)/np.timedelta64(1,'D')\n",
    "    # convert to days, months or years\n",
    "    reset_age = reset_age_tdelta/np.timedelta64(1,'Y')\n",
    "    reset_tenure = reset_tenure_tdelta/np.timedelta64(1,'Y')\n",
    "    # look at terminated or not\n",
    "    #empl_df['terminated']= 0\n",
    "    \n",
    "    \n",
    "    return reset_age,reset_tenure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_target_within_x_years(dates_df,df,paired_dates,tfold,n_years,target_col):\n",
    "    print len(tfold)#, paired_dates\n",
    "\n",
    "    df_dict = {}\n",
    "    for i,tf in enumerate(tfold):\n",
    "        start_date = paired_dates[i][0]\n",
    "        end_date = paired_dates[i][1]\n",
    "        print start_date,end_date,n_years\n",
    "        #altered_fold_df = pd.DataFrame(columns=['fold_mbr','adj_age','adj_tenure','adj_term'])\n",
    "        # if in the fold reset the age to start of fold; define new window of termination\n",
    "        in_fold_idx = tfold[i][0]\n",
    "        # note that \"sex\" is just used to create a value that then gets dummied out\n",
    "        cols_to_copy = ['Male','Age_years','Tenure_years']\n",
    "        cols_to_copy.append(target_col)\n",
    "        #altered_fold_df= df[['SEX','Age_years','Tenure_years','terminated']].copy()\n",
    "        altered_fold_df = df[cols_to_copy].copy()\n",
    "        # adjust these\n",
    "        altered_fold_df.columns=['fold_mbr','adj_age','adj_tenure','adj_term']\n",
    "        altered_fold_df.fold_mbr = 0\n",
    "\n",
    "        ra,rt = reset_years(paired_dates,in_fold_idx,dates_df,df)\n",
    "        altered_fold_df.ix[in_fold_idx]['adj_age']=ra\n",
    "        altered_fold_df.ix[in_fold_idx]['adj_tenure']=rt\n",
    "        new_term = (dates_df.ix[in_fold_idx]['term_tstmp']<= end_date).as_matrix().astype(np.int)\n",
    "        # deal with last time-fold specially\n",
    "        if i == len(tfold)-1:\n",
    "            new_term = (dates_df.ix[in_fold_idx]['term_tstmp']< end_date).as_matrix().astype(np.int)\n",
    "        #print \"\\t\", len(new_term),sum(new_term)\n",
    "        altered_fold_df.loc[in_fold_idx,'adj_term']=new_term\n",
    "        altered_fold_df.loc[in_fold_idx,'fold_mbr']=1\n",
    "        df_dict[i]=altered_fold_df\n",
    "    # now append this to a larger panel\n",
    "    tfold_panel = pd.Panel.from_dict(data =df_dict)\n",
    "    return tfold_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_date_range = [str(a)+'-01-01' for a in np.arange(2002,2016)]\n",
    "print len(full_date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_tfold_models(myX,dates,yr_val,cols_of_interest,tgt_value='terminated',date_range=full_date_range):\n",
    "    # create the folds\n",
    "    yr_tfolds,yr_times = create_temporal_kfolds(dates,date_range,yr_val)\n",
    "    # create the panels (offset)\n",
    "    myPanel = define_target_within_x_years(dates,myX,yr_times,yr_tfolds,yr_val,tgt_value)\n",
    "    # create the tfold training sets\n",
    "    #[(a,emBuild.ix[five_yr_tfolds[a][0]].terminated.sum()) for a in xrange(0,9)]\n",
    "    Xfold = np.zeros((len(myX),len(cols_of_interest)+2,len(yr_tfolds)))\n",
    "    ## So now\n",
    "    yfold = []\n",
    "    for i in xrange(0,len(yr_tfolds)):\n",
    "        Xfold[:,:-2,i]=myX[cols_of_interest].as_matrix().astype(np.float)\n",
    "        Xfold[:,-2:,i]=myPanel[i][['adj_age','adj_tenure']]\n",
    "        my_y=myPanel[i][['adj_term']].as_matrix().astype(np.int)\n",
    "        yfold.append(my_y)\n",
    "    \n",
    "    return yr_tfolds, yr_times, myPanel, Xfold, yfold\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build t_fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfold5,tfold5_times,panel5term,X5fold,y5fold = setup_tfold_models(X,emBuild_dates,5,model_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "five_rf_mdl = []\n",
    "for i in xrange(0,len(tfold5)):\n",
    "    train_y = y5fold[i].flatten()[tfold5[i][0]]\n",
    "    train_X = X5fold[tfold5[i][0],:,i]\n",
    "    rfmdl = ensemble.RandomForestClassifier(n_jobs=50,n_estimators=500,max_features=None)\n",
    "    rfmdl.fit(train_X,train_y)\n",
    "#baseline_singleRFC = ensemble.RandomForestClassifier(n_jobs=50,n_estimators=500,max_features=None)\n",
    "#baseline_singleRFC.fit(X,y_term)\n",
    "#baseline_singleRFC_importances= baseline_singleRFC.feature_importances_\n",
    "    five_rf_mdl.append(rfmdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "def adjust_eval_by_x_years(df,df_dates,year_val,modeling_columns,target_col='terminated'):\n",
    "    # construct\n",
    "  \n",
    "    ## set up method to assess the eval set\n",
    "    print \"There are {0} elements in the evaluation set\".format(len(df))\n",
    "   \n",
    "    print \"original target variable value counts:\", df[target_col].value_counts()\n",
    "    # restructure to deal with time_frame retirement (target variable)\n",
    "    yr_cut_val = year_val+0.5\n",
    "    # index of those that actually accomplish target within timeframe (allow 0.5 additional years)\n",
    "    eval_within_time_target_index = df[(df[target_col]==1) & (df.Tenure_years <= yr_cut_val)].index\n",
    "    # exclude indices that are active and have tenure less than this time\n",
    "    eval_excluded_index = df[(df[target_col]==0) & (df.Tenure_years  <= yr_cut_val)].index\n",
    "    \n",
    "    # the rest become my not-terminated set\n",
    "    eval_active_index = set(df.index) - set(eval_within_time_target_index) - set(eval_excluded_index)\n",
    "    print len(eval_excluded_index),len(eval_within_time_target_index), len(eval_active_index)\n",
    "    eval_idx_to_use =df.ix[set(df.index)-set(eval_excluded_index)].index\n",
    "    #len(eval_idx_to_use)\n",
    "    # reset the termination to 0 for active\n",
    "    eval_new_target = df[target_col].copy()\n",
    "    eval_new_target.ix[eval_active_index] = 0\n",
    "    print \"new target variable value counts: \"\n",
    "    print eval_new_target.ix[eval_idx_to_use].value_counts()\n",
    "    print \"_____\"\n",
    "    y_eval = eval_new_target.ix[eval_idx_to_use].as_matrix().astype(np.int) # true values\n",
    "    eval_adj_tenure = df.ix[eval_idx_to_use].Tenure_years.apply(lambda x: x-year_val if (x>float(year_val)) else 0).values\n",
    "    print len(eval_adj_tenure), len(y_eval)\n",
    "    # now adjust age by length of time; use hire_age if not in set to use.\n",
    "    eval_adj_age = df.ix[eval_idx_to_use].Age_years.apply(lambda x: x-year_val)\n",
    "    eval_adj_age.ix[eval_within_time_target_index] = df_dates['hire_age']\n",
    "    \n",
    "    # construct the evaluation X matrix\n",
    "    print \"input matrix has {0} features\".format(len(modeling_columns)+2)\n",
    "    Xeval = np.zeros((len(eval_idx_to_use),len(modeling_columns)+2))\n",
    "    Xeval[:,:-2] = df.ix[eval_idx_to_use][modeling_columns].as_matrix().astype(np.float)\n",
    "    # now put the adjusted tenure and ages into this matrix\n",
    "    Xeval[:,-2] = eval_adj_age.values\n",
    "    Xeval[:,-1]=eval_adj_tenure\n",
    "    #print len(modeling_columns),np.shape(Xeval)\n",
    "    return Xeval, y_eval\n",
    "\n",
    "\n",
    "## now apply each model to my eval set\n",
    "def evaluate_models(model_list,Xeval):\n",
    "    eval_pred_class = np.zeros((len(Xeval),len(model_list)))\n",
    "    eval_pred_proba = np.zeros((len(Xeval),2,len(model_list)))\n",
    "\n",
    "    for i,mdl in enumerate(model_list):\n",
    "        eval_proba = mdl.predict_proba(Xeval)\n",
    "        eval_pred_class[:,i]=mdl.predict(Xeval)\n",
    "        eval_pred_proba[:,:,i]=eval_proba\n",
    "    #print np.shape(eval_prediction_proba3)\n",
    "    return eval_pred_class, eval_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xeval = emEval.copy()\n",
    "#fixout=br.FixNumericOutlier(columns_to_fix=['ANNUAL_RT','MIN_RT_ANNUAL'], criteria_coef=('percentile', 10), \n",
    "#                            method = 'lower', fill_with='nearest_value')\n",
    "                            \n",
    "X1b = fixout.fit(X).transform(Xeval)\n",
    "print X1b['ANNUAL_RT'].describe()\n",
    "Xeval[['mod_annual_rt','mod_min_rt_annual']]=X1b[['ANNUAL_RT','MIN_RT_ANNUAL']]\n",
    "#fixout_max = br.FixNumericOutlier(columns_to_fix=['MAX_RT_ANNUAL'], criteria_coef=('percentile', 10), \n",
    "#                            method = 'both', fill_with='nearest_value')\n",
    "X1b = fixout_max.fit(X).transform(Xeval)\n",
    "Xeval['mod_max_rt_annual']=X1b['MAX_RT_ANNUAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imp = br.ImputeData(method='median', columns_to_impute=cols_with_missing_numeric, impute_inf=False, keep_dummies=False)\n",
    "X1b = imp.fit(X).transform(Xeval)\n",
    "Xeval[cols_with_missing_numeric]=X1b[cols_with_missing_numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X5eval, y5eval = adjust_eval_by_x_years(Xeval,emEval_dates,5,model_columns,target_col='terminated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_pred_class5,eval_pred_proba5 = evaluate_models(five_rf_mdl,X5eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5eval,map(np.int,eval_pred_class5.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y5eval,map(np.int,eval_pred_class5.mean(axis=1)),normed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(target_test, target_predicted_proba):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "    \n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(y3eval,eval_prediction_proba3[:,])\n",
    "plot_roc_curve(y5eval,eval_pred_proba5[:,:,:].mean(axis=2))\n",
    "plt.ylim([0,1.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## begin to explore the factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to push feature_importances for a set of RF models into a dataframe\n",
    "def create_fi_df(mdl_list,feature_names):\n",
    "    list_feature_importances = []\n",
    "    col_list = []\n",
    "    for i,mdl in enumerate(mdl_list):\n",
    "        list_feature_importances.append(plotFI(mdl,feature_names,show_plot=False))\n",
    "        col_list.append('fold'+str(i)+'_value')\n",
    "        col_list.append('fold'+str(i)+'_std')\n",
    "\n",
    "    fi_df = pd.concat(list_feature_importances,axis=1)\n",
    "    # create column headings\n",
    "    fi_df.columns = col_list\n",
    "    # create the average of the values\n",
    "    value_cols = [x for x in col_list if x.endswith('value')]\n",
    "    \n",
    "    fi_df['avg_val']=fi_df[value_cols].mean(axis=1)\n",
    "    fi_df['avg_variance']=fi_df[value_cols].std(axis=1)\n",
    "#t2_eval_fi_df[['avg_val','avg_std']].sort('avg_val',ascending=False)\n",
    "    return fi_df\n",
    "\n",
    "def plotFI(forest,featureNames=[],show_plot=True):#,autoscale=True,headroom=0.05):\n",
    "    \"\"\"\n",
    "    forest is the model to be graphed.\n",
    "    featureNames is the list of features to be displayed\n",
    "    \n",
    "    \"\"\"\n",
    "    #if autoscale:\n",
    "    #    x_scale = forest.feature_importances_.max()+ headroom\n",
    "    #else:\n",
    "    #    x_scale = 1\n",
    "    \n",
    "    featureImportances=forest.feature_importances_\n",
    "    # sort the importances from biggest to least\n",
    "    indices = np.argsort(featureImportances)[::-1]\n",
    "    estimators = forest.estimators_\n",
    "    # calculate the variance over the forest \n",
    "    \n",
    "    std = np.std([tree.feature_importances_ for tree in estimators],axis=0)\n",
    "    # print summary statement\n",
    "    nfeatures = len(featureImportances)\n",
    "    print(\"Number of Features: %d\" % (nfeatures))\n",
    "    print(\"Number of Trees: %d\" %(len(estimators)))\n",
    "    \n",
    "    #print featureNames\n",
    "    if len(featureNames)==0:\n",
    "        featureNames = map(str,indices)\n",
    "    \n",
    "    fN2 = [featureNames[a] for a in indices]\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(len(indices)):\n",
    "        print(\"%d. feature %d=%s (%f)\" % (f + 1, indices[f], featureNames[indices[f]],featureImportances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    # define a cutoff in terms of feature_importance\n",
    "    if nfeatures <= 30:\n",
    "        kfeatures = nfeatures # keep all if smaller than 30\n",
    "    else:\n",
    "        kfeatures = 30\n",
    "        \n",
    "    kindices = indices[:kfeatures]\n",
    "    if show_plot:\n",
    "        plt.title(\"Feature importances\")\n",
    "        plt.barh(range(len(kindices)), featureImportances[kindices],\n",
    "           color=\"steelblue\", xerr=std[kindices], align=\"center\",ecolor='k')#,lw=2)\n",
    "    \n",
    "        plt.yticks(range(len(kindices)),fN2)\n",
    "        #grid(True)\n",
    "    \n",
    "    c1 = 'value'\n",
    "    c2 = 'std'\n",
    "    tdata = np.vstack([featureImportances[indices],std[indices]])\n",
    "    df = pd.DataFrame(data = tdata.T,index=fN2,columns=[c1,c2])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(five_rf_mdl[0].feature_importances_), len(model_columns)\n",
    "feature_names1 = [a for a in model_columns]\n",
    "feature_names1.append('adj_age')\n",
    "feature_names1.append('adj_tenure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fiveRFmdl_fidf = create_fi_df(five_rf_mdl,feature_names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "from sklearn import tree\n",
    "out = StringIO()\n",
    "out = tree.export_graphviz(five_rf_mdl[0].estimators_[0], out_file=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so 52 of 164 columns have missing values still. Work on Correcting these.\n",
    "#### some logic:\n",
    "* if it is a count (like ADDRCNT*) set missing to -1\n",
    "\n",
    "* if it is a performance assessment (like BOX*) set to 0; L will become 1, S will become 2, H will become 3.\n",
    "* if it is a float (like MERIT*, PERF*, ...) try to reassign by imputation.\n",
    "* assign a value:\n",
    "    * if 'HAVE_INS' or 'HAVE_DEP' assign 0, 0 to values\n",
    "    * if LOC_STATE or GRADE or JOB_FAMILY or JOB_FUNCTION or LOC_TYPE_DESCR_SFI assign to XX*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chg_to_zero_cols = ['BOX1','BOX2','BOX3','BOX4','BOX5','BOX6','BOX7','BOX8','BOX9','BOX10']\n",
    "#['HAVE_INS','HAVE_DEP','DEP_COUNT','BOX1','BOX2','BOX3','BOX4','BOX5','BOX6','BOX7','BOX8','BOX9','BOX10']\n",
    "chg_to_neg_one_cols = ['ADDRCNT1','ADDRCNT3','ADDRCNT5','ADDRCNT10',\n",
    "                           'DIRECT_RPT_CNT', 'DIVISION_CODE_SFI','EXTFUNC_CNT','FUNC_CNT','TOTAL_RPT_CNT']\n",
    "                          \n",
    "chg_to_MISSING_cols = ['ACTRES1','ACTRES2','ACTRES3','ACTRES4','ACTRES5','ACTRES6','ACTRES7','ACTRES8','ACTRES9','ACTRES10',\n",
    "                      'ADDRESS1','JOB_FAMILY','LOC_CITY','LOC_TYPE_DESCR_SFI','SKEY',\n",
    "                      'RATE1', 'RATE10', 'RATE2', 'RATE3', 'RATE4', 'RATE5', 'RATE6', 'RATE7', 'RATE8', 'RATE9',]\n",
    "#chg_to_MISSING =['ACTRES1','ACTRES2','ADDRESS1','JOB_FAMILY', 'LOC_CITY','LOC_TYPE_DESCR_SFI']#'POSTAL_SFI',\n",
    "chg_to_00000 = ['EXT_FUNC_ID_SFI','FUNC_ID_SFI']#,'zip5']\n",
    "chg_to_XXX = ['GRADE','JOB_FUNCTION']\n",
    "chg_to_XX = ['LOC_STATE']\n",
    "col_to_drop = ['STATE','ADDRESS2','MAR_STATUS_DT'] # drop 'STATE'; some strange values; 'address2 x_missing too high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## map some categorical to their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## restrict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove extraneous columns\n",
    "* historical ones\n",
    "* PER_ORG (all the same)\n",
    "* addresses\n",
    "* SAL1 == ANNUAL_RT\n",
    "## Actually the better option is to just extract the desired columns and do the modeling on these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_to_omit = ['ADDRCNT10','ADDRCNT3','ADDRCNT5','DEPTCNT10','DEPTCNT3','DEPTCNT5',\n",
    "                   'EFUNCCNT10','EFUNCCNT3','EFUNCCNT5','FLOORCNT10','FLOORCNT3','FLOORCNT5',\n",
    "                  'FTPTCNT10','FTPTCNT3','FTPTCNT5','FULLPART10','FULLPART3','FULLPART5',\n",
    "                  'FUNCCNT10','FUNCCNT3','FUNCCNT5','GRADECNT10','GRADECNT3','GRADECNT5',\n",
    "                  'JOBCNT10','JOBCNT3','JOBCNT5','LOCCNT10','LOCCNT3','LOCCNT5','LOCSTCNT10','LOCSTCNT3','LOCSTCNT5',\n",
    "                  'PARTFULL10','PARTFULL3','PARTFULL5','PTFTCNT10','PTFTCNT3','PTFTCNT5',\n",
    "                   'SUPVCNT10','SUPVCNT3','SUPVCNT5','SAL10','SAL9','SAL8','SAL7','SAL6','SAL5','SAL4','SAL3',\n",
    "                   'SAL2','MERIT2','MERIT3','MERIT4','MERIT5','MERIT6','MERIT7','MERIT8','MERIT9','MERIT10',\n",
    "                    'PERF2','PERF3','PERF4','PERF5','PERF6','PERF7','PERF8','PERF9','PERF10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the ACTRES2/3 and ADDRESS1/2 lines\n",
    "# add *_tdelta, BIRTHDATE, PER_ORG\n",
    "# add POSTAL_SFI, zip5, MAR_STA_SNAME_SFI, LOC_TYPE_DESC_SFI\n",
    "others_to_omit = ['ADDRESS1','Age_tdelta','BIRTHDATE','LAST_HIRE_DT',\n",
    "                  'LOC_CITY','LOC_TYPE_DESCR_SFI','MAR_STATUS_DT','MAR_STA_SNAME_SFI',\n",
    "                  'PER_ORG','POSTAL_SFI','SKEY','SERVICE_DT','TERMINATION_DT',\n",
    "                  'Tenure_tdelta','zip5']#'TOT_MO_SERVICE_SFI','Tenure_months']\n",
    "                 #'MERIT1','MERIT2','MERIT3','MERIT4','MERIT5','MERIT6','MERIT7','MERIT8','MERIT9','MERIT10',\n",
    "                 #'PERF1','PERF2','PERF3','PERF4','PERF5','PERF6','PERF7','PERF8','PERF9','PERF10']\n",
    "history_to_omit = ['ADDRCNT10','ADDRCNT3','ADDRCNT5','DEPTCNT10','DEPTCNT3','DEPTCNT5',\n",
    "                   'EFUNCCNT10','EFUNCCNT3','EFUNCCNT5','FLOORCNT10','FLOORCNT3','FLOORCNT5',\n",
    "                  'FTPTCNT10','FTPTCNT3','FTPTCNT5','FULLPART10','FULLPART3','FULLPART5',\n",
    "                  'FUNCCNT10','FUNCCNT3','FUNCCNT5','GRADECNT10','GRADECNT3','GRADECNT5',\n",
    "                  'JOBCNT10','JOBCNT3','JOBCNT5','LOCCNT10','LOCCNT3','LOCCNT5','LOCSTCNT10','LOCSTCNT3','LOCSTCNT5',\n",
    "                  'PARTFULL10','PARTFULL3','PARTFULL5','PTFTCNT10','PTFTCNT3','PTFTCNT5',\n",
    "                   'SUPVCNT10','SUPVCNT3','SUPVCNT5','ACTRES2','SAL10','SAL9','SAL8','SAL7','SAL6','SAL5','SAL4','SAL3',\n",
    "                   'SAL2','MERIT2','MERIT3','MERIT4','MERIT5','MERIT6','MERIT7','MERIT8','MERIT9','MERIT10',\n",
    "                    'PERF2','PERF3','PERF4','PERF5','PERF6','PERF7','PERF8','PERF9','PERF10']\n",
    "cols_to_categorical = ['COMPANY','COMP_FREQUENCY','DIVISION_CODE_SFI','EEO1CODE','EMPL_CLASS','EMPL_TYPE','ETHNIC_GROUP',\n",
    "                       'FLSA_STATUS','FULLPART1','FULL_PART_TIME','GRADE','HUBIND','INTERN','JOB_FUNCTION','RELOCATE_ALL_SFI',\n",
    "                       'REMOTE','REMOTE_SUPV','SEX','SHIFT','SUPV_DIFF_LOC','VOLINVOL','status']\n",
    "for col in others_to_omit:\n",
    "    columns_to_omit.append(col)\n",
    "\n",
    "for col in history_to_omit:\n",
    "    columns_to_omit.append(col)\n",
    "    \n",
    "print len(columns_to_omit),len(cols_to_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## READ the data June 10, 2015\n",
    "* use employee_dataframe8.tsv --> contains text fields including dates for HIRE_DT..\n",
    "* use employee_df_[1,2].csv --> contains just numeric data.\n",
    "    - employee_df_1 has 180 columns:\n",
    "        + Historical data there \n",
    "        + max value of EXT_FUNC_ID_SFI and FUNC_ID_SFI (represents missing ) changed to 2000.\n",
    "        + median values used to fill missing values for float columns\n",
    "        + COMPANY dropped\n",
    "        + 'LOC_TYPE_DESCR_SFI','GRADE','LOC_STATE','JOB_FAMILY' label encoded\n",
    "        + ANNUAL_RT droped in lieu of SAL1\n",
    "        + BOX* kept; RATE*  dropped\n",
    "        + PTFTCNT* kept; PARTFULL dropped\n",
    "        + FTCNT* kept; FULLPART dropped\n",
    "    - keep only the most recent historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# omit those that have more than 25% missing:\n",
    "missing_threshold = 0.25\n",
    "columns_to_omit = list(sdf[sdf['x_missing'] > missing_threshold].Column.values)\n",
    "print len(columns_to_omit)\n",
    "print columns_to_omit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a simple DataFrame of employee dates using Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let me return to removing columns I don't want\n",
    "* keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "columns_to_remove = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"DF_Converter\", br.DataFrameConverter(columns=X.columns)),\n",
    "                     (\"Cat_Converter\", br.ConvertCategorical(categorical_columns=categorical_columns)),\n",
    "                     (\"Impute\", br.ImputeData()),\n",
    "                     (\"clf\", RandomForestClassifier(n_jobs=50))])\n",
    "pipeline.fit(X, y)\n",
    "pipeline.predict_proba(X_2014_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add/replace some relevant columns to this dataframe\n",
    "* POSTAL_SFI --> zip5 \n",
    "* unempl_rate by joining on unemployment\n",
    "* Age_hire\n",
    "* terminated \n",
    "* sep_status\n",
    "\n",
    "use a parallel dataframe for dates/timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnSelector(TransformerMixin):\n",
    "    \"\"\" Selects column(s) from a pandas DataFrame\n",
    "    \"\"\"\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols\n",
    "    def tranform(self, X, y=None):\n",
    "        return X[:,self.cols]\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Per discussion with HR COE team decide to truncate data after a particular date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emSets = []\n",
    "date_list =['1994-01-01','1998-01-01','2002-01-01','2006-01-01']\n",
    "print len(empl_df)\n",
    "for date0 in date_list:\n",
    "    my_em = empl_df.ix[emplfull.TERMINATION_DT>=date0].copy()\n",
    "    emSets.append(my_em)\n",
    "    print date0, len(my_em)\n",
    "    print '----\\n', my_em.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl_dates=pd.DataFrame()\n",
    "empl_dates[['hire_tstmp','term_tstmp','birth_tstmp']] = emplfull[['HIRE_DT','TERMINATION_DT','BIRTHDATE']].apply(lambda x: pd.to_datetime(x))\n",
    "empl_dates[['hire_year','term_year','birth_year']]= empl_dates[['hire_tstmp','term_tstmp','birth_tstmp']].apply(lambda x: x.dt.year)\n",
    "empl_dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions Follow\n",
    "* Most taken from ```bear.py```\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## bear.py \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ConvertCategorical(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_columns, method='factorize'):\n",
    "        \"\"\"\n",
    "        method: factorize, value_counts, group_means\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.categorical_columns = categorical_columns\n",
    "        self.map_values = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.categorical_columns:\n",
    "            if col in X.columns:\n",
    "                if self.method == 'factorize':           \n",
    "                    map_values = X[col].unique() # Can sample data here for speed\n",
    "                    self.map_values[col] = {key: index for index, key in enumerate(map_values)}                 \n",
    "                elif self.method == 'value_counts':\n",
    "                    self.map_values[col] = dict(X[col].value_counts())\n",
    "                elif self.method == 'group_means':\n",
    "                    self.map_values[col] = dict(pd.crosstab(X[col], y).apply(lambda x: x[1]/float(x.sum()), axis=1))\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        for col in self.categorical_columns:\n",
    "            if col in X.columns:\n",
    "                X[str(col)+\"_f\"] = X[col].map(self.map_values[col], 'ignore')\n",
    "        X = X[br.get_numeric(X)]\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "def graph_feature_importances(model, feature_names, autoscale=True, headroom=0.05, width=10, summarized_columns=None):\n",
    "    \"\"\"\n",
    "    Graphs the feature importances of a random decision forest using a horizontal bar chart. \n",
    "    Probably works but untested on other sklearn.ensembles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ensemble = Name of the ensemble whose features you would like graphed.\n",
    "    feature_names = A list of the names of those featurs, displayed on the Y axis.\n",
    "    autoscale = True (Automatically adjust the X axis size to the largest feature +.headroom) / False = scale from 0 to 1\n",
    "    headroom = used with autoscale, .05 default\n",
    "    width=figure width in inches\n",
    "    summarized_columns = a list of column prefixes to summarize on, for dummy variables (e.g. [\"day_\"] would summarize all day_ vars\n",
    "    \"\"\"\n",
    "    \n",
    "    if autoscale:\n",
    "        x_scale = model.feature_importances_.max()+ headroom\n",
    "    else:\n",
    "        x_scale = 1\n",
    "    \n",
    "    feature_dict=dict(zip(feature_names, model.feature_importances_))\n",
    "    \n",
    "    if summarized_columns: \n",
    "        #some dummy columns need to be summarized\n",
    "        for col_name in summarized_columns: \n",
    "            #sum all the features that contain col_name, store in temp sum_value\n",
    "            sum_value = sum(x for i, x in feature_dict.iteritems() if col_name in i )  \n",
    "            \n",
    "            #now remove all keys that are part of col_name\n",
    "            keys_to_remove = [i for i in feature_dict.keys() if col_name in i ]\n",
    "            for i in keys_to_remove:\n",
    "                feature_dict.pop(i)\n",
    "            #lastly, read the summarized field\n",
    "            feature_dict[col_name] = sum_value\n",
    "        \n",
    "    results = pd.Series(feature_dict.values(), index=feature_dict.keys())\n",
    "    results.sort(axis=1)\n",
    "    results.plot(kind=\"barh\", figsize=(width,len(results)/4), xlim=(0,x_scale))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## read in the full dataset\n",
    "new_read_dict = {'KEY':np.str,'LOCATION':np.str,'EEO1CODE':np.str,'SKEY':np.str,'JOBCODE':np.str,'EMPL_CLASS':np.str, \n",
    "                        'COMPANY':np.str,'EXT_FUNC_ID_SFI':np.str,'FUNC_ID_SFI':np.str,\n",
    "                          'DIVISION_CODE_SFI':np.str,'JOB_FAMILY':np.str,'JOB_FUNCTION':np.str,'ACTRES1':np.str,\n",
    "                          'ACTRES2':np.str,'ACTRES3':np.str,'ACTRES4':np.str,'ACTRES5':np.str,'ACTRES6':np.str,\n",
    "                          'ACTRES7':np.str,'ACTRES8':np.str,'ACTRES9':np.str,'ACTRES10':np.str,'zip5':np.str}\n",
    "emplfull = pd.read_csv('employee_dataframe8.tsv',sep='\\t',dtype={'KEY':np.str,'SKEY':np.str,'zip5':np.str})#,dtype=new_read_dict)\n",
    "print emplfull.shape\n",
    "emplfull.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function\n",
    "## function to load into pandas from hdfs (by copying to local filespace)\n",
    "def pandas_read_hdfs(infile,**kwargs):\n",
    "    # copy the infile to the cwd\n",
    "    !hdfs dfs -get {infile} .\n",
    "    # identify the local file name\n",
    "    inname = infile[infile.rfind('/')+1:]\n",
    "    # read into a data frame\n",
    "    df = pd.read_csv(inname,**kwargs)\n",
    "    # clean up local filespace\n",
    "    !rm {inname}\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note make sure you have run kinit before the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fnames = !hdfs dfs -ls {coredir}\n",
    "infilenames = [f.split()[-1] for f in fnames[1:]]\n",
    "print len(infilenames)\n",
    "print infilenames[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the absence (EAS) empl table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empl_abs = pandas_read_hdfs(infilenames[0],sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "printall(empl_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "describe_categorical(emplfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emplfull[['HIRE_DT']].ix[:3].apply(lambda x: pd.to_datetime(x).dt.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a simple DataFrame of employee dates using timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_dates=pd.DataFrame()\n",
    "empl_dates[['hire_tstmp','term_tstmp','birth_tstmp']] = emplfull[['HIRE_DT','TERMINATION_DT','BIRTHDATE']].apply(lambda x: pd.to_datetime(x))\n",
    "empl_dates[['hire_year','term_year','birth_year']]= empl_dates[['hire_tstmp','term_tstmp','birth_tstmp']].apply(lambda x: x.dt.year)\n",
    "empl_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "describe_categorical(empl_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_numeric(empl_dates)\n",
    "#hist_of_numeric(empl_dates)\n",
    "     \n",
    "for c in get_numeric(empl_dates):     \n",
    "    empl_dates[c].hist(label=c,alpha=0.5)\n",
    "    plt.legend(loc=2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ the data June 10, 2015\n",
    "* use employee_dataframe8.tsv --> contains text fields including dates for HIRE_DT..\n",
    "* use employee_df_[1,2].csv --> contains just numeric data.\n",
    "    - employee_df_1 has 180 columns:\n",
    "        + Historical data there \n",
    "        + max value of EXT_FUNC_ID_SFI and FUNC_ID_SFI (represents missing ) changed to 2000.\n",
    "        + median values used to fill missing values for float columns\n",
    "        + COMPANY dropped\n",
    "        + 'LOC_TYPE_DESCR_SFI','GRADE','LOC_STATE','JOB_FAMILY' label encoded\n",
    "        + ANNUAL_RT droped in lieu of SAL1\n",
    "        + BOX* kept; RATE*  dropped\n",
    "        + PTFTCNT* kept; PARTFULL dropped\n",
    "        + FTCNT* kept; FULLPART dropped\n",
    "    - keep only the most recent historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_df = pd.read_csv('employee_df_1.csv')\n",
    "empl_df.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "print empl_df.shape\n",
    "empl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## assign unemployement_rate\n",
    "empl_df['unempl_rate'] = emplfull.TERMINATION_DT.apply(lambda x: assign_unempl_rate(x,unempl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine collinearity of these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "collinearity_empl_df = perfect_collinearity_test(empl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collinearity_empl_df.sort(ascending=False)\n",
    "collinearity_empl_df[collinearity_empl_df>0.95]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's begin with just a few columns and revisit this later to get the logic correct\n",
    "* further cleans-up the dataset\n",
    "    1. clean-up (remove) historical data\n",
    "    2. MOS data?\n",
    "    3. Try to encode survival value for some categorical variables\n",
    "        - JOB_FAMILY \n",
    "        - GRADE <-> grade_code\n",
    "        - JOB_FAMILY <-> job_fcode (not used/recognized by HR)\n",
    "        - JOBCODE <-> recast this into a form that has ordinal sense\n",
    "    4. Revist columns to keep/exclude:\n",
    "        - JOB FUNCTION IS categorical; 19 unique values\n",
    "        - job_fcode should be but is label encoded as integers; 1456 unique values\n",
    "        - EXTFUNC_CNT has 10352 unique values -->\n",
    "        - EXT_FUNC_ID_SFI has 422 unique values\n",
    "        - FUNC_CNT has 12070 unique values\n",
    "        - FUNC_ID_SFI has 64 unique values\n",
    "* build model based upon those with known separation ONLY\n",
    "  - create a hold out (eval) set.\n",
    "  - apply to current employees\n",
    "  - question: _How to make this time-dependent?_\n",
    "      * bucket the test set into time-segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_list = empl_df.columns.tolist()\n",
    "three_cols = [x for x in col_list if x.endswith('CNT3')]\n",
    "five_cols = [x for x in col_list if x.endswith('CNT5')]\n",
    "ten_cols = [x for x in col_list if x.endswith('CNT10')]\n",
    "# drop all BOX, MERIT, SAL, PERF and add back in those from last year\n",
    "to_drop_cols = [x for x in col_list if x.startswith('PERF')]\n",
    "to_drop_cols+= [x for x in col_list if x.startswith('SAL')]\n",
    "to_drop_cols += [x for x in col_list if x.startswith('MERIT')]\n",
    "to_drop_cols += [x for x in col_list if x.startswith('BOX')]\n",
    "to_drop_cols+=three_cols\n",
    "to_drop_cols+=five_cols\n",
    "to_drop_cols+=ten_cols\n",
    "to_add_cols = ['BOX1','SAL1','MERIT1','PERF1']\n",
    "empl = empl_df.copy()\n",
    "empl.drop(to_drop_cols,inplace=True,axis=1)\n",
    "empl[to_add_cols] = empl_df[to_add_cols].copy()\n",
    "print empl.shape ## this is the same as if I read in employee_df_2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## check collinearity of this\n",
    "empl_collin_test = perfect_collinearity_test(empl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_collin_test.hist(label='removed_historical',bins=20)\n",
    "collinearity_empl_df.hist(alpha=0.3,label='all_columns',bins=20)\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel('correlation score')\n",
    "plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_collin_test[empl_collin_test>0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_cols = empl.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin to look at slicing in Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emSets = []\n",
    "date_list =['1994-01-01','1998-01-01','2002-01-01','2006-01-01']\n",
    "print len(empl_df)\n",
    "for date0 in date_list:\n",
    "    my_em = empl_df.ix[emplfull.TERMINATION_DT>=date0].copy()\n",
    "    emSets.append(my_em)\n",
    "    print date0, len(my_em)\n",
    "    print '----\\n', my_em.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_lengths = [len(em) for em in emSets]\n",
    "plt.bar(np.arange(0,len(set_lengths)),set_lengths,color='darkorchid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider set B: index = 1\n",
    "* length is 159376, split is 89570 to 69806\n",
    "* date is 2002-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collinearity_test_B = perfect_collinearity_test(emSets[1][reduced_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(empl_collin_test,collinearity_test_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collinearity_test_B[collinearity_test_B>0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emSets[1].plot(kind='scatter',x='SAL1',y='MIN_RT_ANNUAL')\n",
    "emSets[1].plot(kind='scatter',x='SAL1',y='MAX_RT_ANNUAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a set of those who are separated only\n",
    "emB_build = emSets[1][emSets[1][reduced_cols].status ==1].copy()\n",
    "emB_active = emSets[1][emSets[1][reduced_cols].status==0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emB_build.terminated.value_counts(), emB_build.retired.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(emB_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emB_build.terminated.value_counts()/float(len(emB_build))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "emB_build.Tenure_years.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tenure_years_range= [0.0,65.0]\n",
    "emB_build.Tenure_years.hist(bins=66,range=tenure_years_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_tenure_class = pd.cut(emB_build.Tenure_years,[0,1,2,3,4,5,6,7,8,200],labels=False,right=False)#,labels=[1,2,3,4,5,6,7,8])#.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.value_counts(y_tenure_class).plot(kind='bar')#.reindex(y_tenure_class.levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create evaluation set and test set\n",
    "from sklearn import cross_validation\n",
    "eval_fraction = 0.15\n",
    "emB, emB_eval = cross_validation.train_test_split(emB_build,test_size=eval_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_index = emB.index.tolist()\n",
    "eval_index = emB_eval.index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_tenure_class.ix[eval_index].value_counts()/float(len(eval_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_tenure_class.ix[train_index].value_counts()/float(len(train_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_collinear_cols = ['EMPL_CLASS_P','EMPL_CLASS_O','EEO1CODE_9']\n",
    "mos_columns = [x for x in reduced_cols if x.endswith('MOS')]\n",
    "other_cols_to_drop = ['status','sep_status','EXTFUNC_CNT','EXT_FUNC_ID_SFI','FUNC_CNT','FUNC_ID_SFI','retired','terminated','Tenure_years']\n",
    "modeling_cols = list(set(reduced_cols)-set(high_collinear_cols)-set(other_cols_to_drop)-set(mos_columns))\n",
    "print len(reduced_cols), len(modeling_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = emB[modeling_cols].as_matrix().astype(np.float)\n",
    "print np.shape(X)\n",
    "y_tenure = emB.Tenure_years.as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotFI(forest,modeling_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(forest[0],out_file='tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pydot as pyd\n",
    "#import fig_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f0_graph = pyd.graph_from_dot_file('tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f0_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return a linear regression fit of some data\n",
    "def linear_reg_fit(x,y,n_samples = 50, verbose=False):\n",
    "    import statsmodels.api as sm\n",
    "    # create the x_prime variable\n",
    "    x_prime = np.linspace(x.min(),x.max(),n_samples)[:,np.newaxis]\n",
    "    # add a constant to the predictor\n",
    "    x = sm.add_constant(x)# Adds a constant term to the predictor\n",
    "    # create linear regression object\n",
    "    ols = sm.OLS(y, x)\n",
    "    est = ols.fit()\n",
    "    if verbose:\n",
    "        print est.summary()\n",
    "    x_prime = sm.add_constant(x_prime)  # add constant as we did before\n",
    "\n",
    "    # Now we calculate the predicted values\n",
    "    y_hat = est.predict(x_prime)\n",
    "   \n",
    "    #print \"\\n ====================== \\n\"\n",
    "    coef = est.params[1]\n",
    "    rsquared = est.rsquared\n",
    "    return x_prime[:,1],y_hat, coef,rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ols=linear_model.LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_p,y_p = linear_reg_fit(emB_eval.Tenure_years.values, pred_tenure_eval)#,pred_tenure_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create survival median dictionary and apply to desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now assign these values to the arrays\n",
    "emB['med_surv'] = emB['JOBCODE'].apply(lambda x: med_survival[x] )\n",
    "emB_eval['med_surv'] = emB_eval['JOBCODE'].apply(lambda x: med_survival[x] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeling_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(modeling_cols)\n",
    "sm_mod_cols = [a for a in modeling_cols]\n",
    "job_function_cols = [b for b in modeling_cols if b.startswith('JOB_FUNCTION')]\n",
    "job_function_cols\n",
    "#for a in ['JOBCODE','grade_code','loc_descr','job_fcode','']\n",
    "sm_mod_cols.remove('JOBCODE')\n",
    "sm_mod_cols+=['med_surv']\n",
    "print len(sm_mod_cols), len(modeling_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xp = emB[sm_mod_cols].as_matrix().astype(np.float)\n",
    "print np.shape(Xp)\n",
    "#y_tenure = emB.Tenure_years.as_matrix().astype(np.float)\n",
    "Xeval_p = emB_eval[sm_mod_cols].as_matrix().astype(np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "RFRforest2 = ensemble.RandomForestRegressor(n_jobs=50,n_estimators=500,max_features=None)\n",
    "RFRforest2.fit(Xp,y_tenure)\n",
    "#importances= forest.feature_importances_\n",
    "## apply to the eval subset from emB\n",
    "pred_tenure_eval_2 = RFRforest2.predict(Xeval_p)\n",
    "np.shape(pred_tenure_eval_2)#, np.shape(y_tenure_class.ix[eval_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_feature_importances(RFRforest2,sm_mod_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.scatter(y_tenure_class.ix[eval_index],pred_tenure_eval,color='chartreuse',alpha=0.3)\n",
    "sns.regplot(emB_eval.Tenure_years, pred_tenure_eval_2,color='darkorchid')\n",
    "#plt.scatter(emB_eval.Tenure_years,pred_tenure_eval,color='darkslategray',alpha=0.3)\n",
    "plt.xlabel('True Tenure Length')\n",
    "plt.ylabel('Predicted Tenure Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.scatter(y_tenure_class.ix[eval_index],pred_tenure_eval,color='chartreuse',alpha=0.3)\n",
    "plt.scatter(emB_eval.Tenure_years,pred_tenure_eval_2,color='darkorchid',alpha=0.3)\n",
    "plt.xlabel('True Tenure Length')\n",
    "plt.ylabel('Predicted Tenure Length')\n",
    "plt.xlim([0,10])\n",
    "plt.ylim([0,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## back to classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "forest2 = ensemble.RandomForestClassifier(n_jobs=50,n_estimators=500,max_features=None)\n",
    "forest2.fit(Xp,y_tenure_class.ix[train_index])\n",
    "y_pred_tenure_class_2 = forest2.predict(Xeval_p)\n",
    "rfc_tenureclass_conf_matrix2 = metrics.confusion_matrix(y_tenure_class.ix[eval_index],y_pred_tenure_class_2)\n",
    "sns.heatmap(rfc_tenureclass_conf_matrix2, annot=True,  fmt='',cmap='Greens')#\n",
    "plt.title('Random Forest Classifier Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rfc_tenureclass_conf_matrix = metrics.confusion_matrix(y_tenure_class.ix[eval_index],y_pred_tenure_class)\n",
    "sns.heatmap(rfc_tenureclass_conf_matrix, annot=True,  fmt='',cmap='Blues')#\n",
    "plt.title('Random Forest Classifier Confusion Matrix (before)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm_normalized = rfc_tenureclass_conf_matrix.astype('float') / rfc_tenureclass_conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "#print(cm_normalized)\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "sns.heatmap(cm_normalized)#, title='Normalized confusion matrix')\n",
    "plt.subplot(122)\n",
    "cm_normalized2 = rfc_tenureclass_conf_matrix2.astype('float') / rfc_tenureclass_conf_matrix2.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_normalized2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(cm_normalized2-cm_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside about JOBCODE, job_fcode (JOB_FAMILY), & grade_code (GRADE)\n",
    "* spoke with HR team on June 11, 2015 --> consider eliminating some subset of grades that are _never_ going to be requested for projections.\n",
    "* they will provide this information\n",
    "* Look into calculating median survival for all 3 classes --> they are slightly different from one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(empl.JOBCODE.unique()), len(empl.job_fcode.unique()), len(empl.grade_code.unique())\n",
    "print len(empl[empl.status==0].JOBCODE.unique()), len(empl[empl.status==0].job_fcode.unique()), len(empl[empl.status==0].grade_code.unique())\n",
    "\n",
    "np.log(empl[empl.status==0].grade_code.value_counts()).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sum(empl[empl.status==0].JOBCODE.value_counts() [empl[empl.status==0].JOBCODE.value_counts() == 1])\n",
    "np.log(empl[empl_dates.term_tstmp>=pd.to_datetime('2010-01-01')].grade_code.value_counts()).hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Calculate Age at hire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## now calculate age at hire\n",
    "hire_age_tdelta = empl_dates['hire_tstmp']-empl_dates['birth_tstmp']#)/np.timedelta64(1,'D')\n",
    "# convert to days, months or years\n",
    "empl_dates['hire_age'] = hire_age_tdelta/np.timedelta64(1,'Y')\n",
    "\n",
    "#empl_dates.drop('hire_age_tdelta',axis=1,inplace=True)\n",
    "empl_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### push to emSets[1]\n",
    "emSets[1]['hire_age']=empl_dates.ix[emSets[1].index]['hire_age']\n",
    "emSets[1][['Age_years','Tenure_years','hire_age']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the temporal kfold sets\n",
    "Begin with only subset of employees that retired/terminated after 2002-01-01\n",
    "## Pull out an evaluation set\n",
    "* use test_train_split\n",
    "### Requirements\n",
    "* initial date\n",
    "* final date\n",
    "* time_delta\n",
    "* employee DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Starting with subest of {0} employees.\".format(len(emSets[1]))\n",
    "eval_fraction = 0.15\n",
    "em2, em2_eval = cross_validation.train_test_split(emSets[1],test_size=eval_fraction)\n",
    "print \"Evaluation set has {0} employees; training set has {1} employees.\".format(len(em2_eval),len(em2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2.terminated.value_counts()/float(len(em2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2_eval.terminated.value_counts()/float(len(em2_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create k-folds based upon time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_date_range = [str(a)+'-01-01' for a in np.arange(2002,2016)]\n",
    "print len(full_date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_date = pd.to_datetime(full_date_range[0])\n",
    "max_date = pd.to_datetime(full_date_range[-1])\n",
    "print type(max_date - min_date),np.int(np.round((max_date-min_date).days/365.24,0))\n",
    "for a in xrange(0,3):\n",
    "    print a, full_date_range[a::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create procedure for time selections.\n",
    "def split_on_time(dates_df, split_tstmp):\n",
    "    #split_tstmp = pd.to_datetime(split_date_str)\n",
    "    #print split_tstmp\n",
    "    \n",
    "    before_idx = dates_df[(dates_df.hire_tstmp < split_tstmp)].index\n",
    "    after_idx = list(set(dates_df.index) -set(before_idx))\n",
    "    print len(after_idx), len(dates_df)\n",
    "    print \"Splitting on {0} amounts to a hold-out fraction of {1}\".format(split_tstmp,len(after_idx)/float(len(dates_df)))\n",
    "    return before_idx, after_idx\n",
    "\n",
    "def temporal_kfold(dates_df,t1,t2):\n",
    "    before_idx = dates_df[((dates_df.term_tstmp>=t1))].index\n",
    "    kfold_idx = dates_df[((dates_df.term_tstmp>=t1) & (dates_df.hire_tstmp<t2))].index\n",
    "    after_idx = list(set(dates_df.index)-set(before_idx)-set(kfold_idx))\n",
    "    print len(before_idx),len(kfold_idx),len(after_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_temporal_kfolds(dates_df,date_range,time_delta):\n",
    "    min_date = pd.to_datetime(date_range[0])\n",
    "    max_date = pd.to_datetime(date_range[-1])\n",
    "    my_index = dates_df[(dates_df.term_tstmp>=min_date)].index\n",
    "    # calculate number of kfolds\n",
    "    date_span_years = np.int(np.round((max_date-min_date).days/365.24,0))\n",
    "    nfolds = date_span_years - time_delta\n",
    "    print date_span_years, time_delta, nfolds, len(my_index)\n",
    "    all_pairs = list(itertools.combinations(date_range,2))\n",
    "    # now filter if difference in time  == time_delta\n",
    "    filtered_pairs = []\n",
    "    for i0,i1 in all_pairs:\n",
    "        if int(i1[:4])-int(i0[:4]) == time_delta:\n",
    "            filtered_pairs.append([i0,i1])\n",
    "            #print i0,i1\n",
    "    print len(filtered_pairs)\n",
    "    # now process each of these filtered pairs\n",
    "    kf = []\n",
    "    for j0,j1 in filtered_pairs: # omit the last one because it has no\n",
    "        start_date = pd.to_datetime(j0)\n",
    "        end_date = pd.to_datetime(j1)\n",
    "        #print j0,j1#,len(k)\n",
    "        \n",
    "        \n",
    "        kfold_idx = dates_df[(dates_df.term_tstmp >= start_date) & (dates_df.hire_tstmp<start_date)].index\n",
    "        after_idx = dates_df[(dates_df.hire_tstmp>=end_date)].index\n",
    "        before_idx = list(set(my_index)-set(kfold_idx)-set(after_idx))\n",
    "        #temporal_kfold(dates_df[dates_df.term_tstmp>=min_date],start_date,end_date)\n",
    "        #print \"\\t\",len(kfold_idx), len(after_idx),len(before_idx)\n",
    "        \n",
    "        # combined out of fold\n",
    "        not_kfold_idx = list(set(after_idx).union(set(before_idx)))\n",
    "        \n",
    "        print j0,j1,len(kfold_idx),len(not_kfold_idx)\n",
    "        kf.append([kfold_idx,not_kfold_idx])\n",
    "    \n",
    "    return kf,filtered_pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(em2),len(em2_eval),len(emSets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_folds,my_times = create_temporal_kfolds(empl_dates.ix[em2.index],full_date_range,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(my_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print my_times[0]\n",
    "[len(my_folds[0][i]) for i in xrange(0,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_years(paired_times,indices,dates_df,df,cols_to_alter = ['Age_years','Tenure_years']):\n",
    "    # calc the Age at beginnning of time period\n",
    "    ## now calculate age at hire\n",
    "    reset_age_tdelta = pd.to_datetime(paired_times[0])-dates_df['birth_tstmp']#)/np.timedelta64(1,'D')\n",
    "    reset_tenure_tdelta = pd.to_datetime(paired_times[0])-dates_df['hire_tstmp']#)/np.timedelta64(1,'D')\n",
    "    # convert to days, months or years\n",
    "    reset_age = reset_age_tdelta/np.timedelta64(1,'Y')\n",
    "    reset_tenure = reset_tenure_tdelta/np.timedelta64(1,'Y')\n",
    "    # look at terminated or not\n",
    "    #empl_df['terminated']= 0\n",
    "    \n",
    "    \n",
    "#my_rows = empl_df[(empl_df.status==1) & (empl_df.retired==0)].index\n",
    "#print \"Out of {0} rows, {1} are separated and not retired.\".format(len(empl_df),len(my_rows))\n",
    "##sum(empl_df['terminated']))#, len(my_rows)\n",
    "#empl_df.loc[my_rows,'terminated']=1\n",
    "#print sum(empl_df.terminated)\n",
    "#    if \n",
    "    return reset_age,reset_tenure\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2.ix[my_folds[0][0]].Age_years.hist(bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ra.ix[my_folds[0][0]].hist(bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ra,rt = reset_years(my_times[0],my_folds[0],empl_dates.ix[em2.index],em2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rt.ix[my_folds[0][0]].hist(bins=30)\n",
    "em2.ix[my_folds[0][0]].Tenure_years.hist(bins=30,alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## need to reset terminated based upon that time frame\n",
    "def check_status(t,ck_time):\n",
    "    print t, ck_time\n",
    "    x=0\n",
    "    if t <= pd.to_datetime(ck_time):\n",
    "        x=1\n",
    "    return x\n",
    "\n",
    "#empl_dates.ix[my_folds[0][0][:3]][['term_tstmp']].apply(lambda x: check_status(x,my_times[0[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_status(empl_dates.ix[my_folds[0][0][0]]['term_tstmp'],'2006-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print my_times[0]\n",
    "empl_dates.ix[my_folds[0][0][:5]]['term_tstmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2.ix[my_folds[0][0]].terminated.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if term_tstmp > end_tstmp then NOT terminated, otherwise terminated --. for those in kfold training set.\n",
    "new_term = (empl_dates.ix[my_folds[0][0]]['term_tstmp']-pd.to_datetime(my_times[0][1]))<0\n",
    "new_term.astype(np.int)\n",
    "new_term.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## work this into a classification problem\n",
    "* my y is the new_term\n",
    "* my X is [reset_Age,reset_tenure,SEX,surv_med, etc.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(new_term),len(my_folds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_list_cols = ['SEX','SAL1','MERIT1','PERF1','unempl_rate','HAVE_INS']\n",
    "fold_temp_df = em2.ix[my_folds[0][0]][min_list_cols].copy()\n",
    "fold_temp_df['age']=ra.ix[my_folds[0][0]]\n",
    "fold_temp_df['tenure']=rt.ix[my_folds[0][0]]\n",
    "X_set0 = fold_temp_df.as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_set0 = new_term.values.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest_0 = ensemble.RandomForestClassifier(n_estimators=500,max_features=None,n_jobs=50)\n",
    "forest_0.fit(X_set0,y_set0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perfect_collinearity_test(fold_temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotFI(forest_0,fold_temp_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## try applying this to the most recent data set? ir at least  my_times[5]\n",
    "ra5,rt5 = reset_years(my_times[5],my_folds[5],empl_dates.ix[em2.index],em2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_times[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_list_cols = ['SEX','SAL1','MERIT1','PERF1','unempl_rate','HAVE_INS']\n",
    "fold_test5_df = em2.ix[my_folds[5][0]][min_list_cols].copy()\n",
    "fold_test5_df['age']=ra5.ix[my_folds[5][0]]\n",
    "fold_test5_df['tenure']=rt5.ix[my_folds[5][0]]\n",
    "X_test5 = fold_test5_df.as_matrix().astype(np.float)\n",
    "y_test5 = ((empl_dates.ix[my_folds[5][0]]['term_tstmp']-pd.to_datetime(my_times[5][1]))<0).astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_5 = forest_0.predict(X_test5)\n",
    "sum(y_pred_5), sum(y_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(y_true,y_pred,normed=True,**kwargs):\n",
    "    my_c = metrics.confusion_matrix(y_true,y_pred)\n",
    "    \n",
    "    print metrics.matthews_corrcoef(y_true,y_pred)\n",
    "    if normed:\n",
    "        cm_normalized = my_c.astype('float') / my_c.sum(axis=1)[:, np.newaxis]\n",
    "        my_c = cm_normalized\n",
    "        plt.title('Normalized RF Classifier Confusion Matrix')\n",
    "    else:\n",
    "        plt.title('Random Forest Classifier Confusion Matrix')\n",
    "        \n",
    "    sns.heatmap(my_c, annot=True,  fmt='',cmap='Blues')\n",
    "    plt.ylabel('True')\n",
    "    #plt.yticks\n",
    "    plt.xlabel('Assigned')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em2.ix[my_folds[5][0]].terminated.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_times[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(y_test5,y_pred_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# repeat for 2nd fold\n",
    "ra1,rt1 = reset_years(my_times[1],my_folds[1],empl_dates.ix[em2.index],em2)\n",
    "fold_temp_df1 = em2.ix[my_folds[1][0]][min_list_cols].copy()\n",
    "fold_temp_df1['age']=ra1.ix[my_folds[1][0]]\n",
    "fold_temp_df1['tenure']=rt1.ix[my_folds[1][0]]\n",
    "X_set1 = fold_temp_df1.as_matrix().astype(np.float)\n",
    "y_set1 =((empl_dates.ix[my_folds[1][0]]['term_tstmp']-pd.to_datetime(my_times[1][1]))<0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest_1 = ensemble.RandomForestClassifier(n_estimators=500,max_features=None,n_jobs=50)\n",
    "forest_1.fit(X_set1,y_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotFI(forest_1,fold_temp_df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y1_pred_5 = forest_1.predict(X_test5)\n",
    "plot_conf_matrix(y_test5,y1_pred_5,normed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(forest_1.predict_proba(X_test5)[:,1],'*',alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which of the above terminate within 5 years of the starting date?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print my_times[5], sum(empl_dates.ix[my_folds[5][0]]['term_tstmp'] <= my_times[5][1])\n",
    "\n",
    "#em2.ix[my_folds[5][0]][min_list_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empl_dates.ix[my_folds[5][0]]['hire_tstmp'].max() # great required to have started prior to the date of this t_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fold_5_actual_term_idx = empl_dates.ix[my_folds[5][0]][empl_dates.ix[my_folds[5][0]]['term_tstmp'] <= my_times[5][1]].index\n",
    "print len(fold_5_actual_term_idx)\n",
    "em2.ix[fold_5_actual_term_idx].terminated.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the above is for 5-year projections. Can I do better on 2 year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "two_yr_folds,two_yr_times = create_temporal_kfolds(empl_dates.ix[em2.index],full_date_range,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed \"pipeline\"\n",
    "1. create the temporal kfolds\n",
    "2. for each t_kfold adjust the desired columns\n",
    "    a. this means defining Age & Tenure with respect to the start_date\n",
    "    b. if the person terminated after the end_date of that kfold, reset terminated as 0.\n",
    "    c. Other features to change?\n",
    "3. create a model for each t_kfold\n",
    "4. apply that model for each other t_kfold (Cross_validation)\n",
    "5. Apply each model/united model to the evaluation set\n",
    "    a. Figure out how to unite these models\n",
    "    b. adjust evaluation set ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
