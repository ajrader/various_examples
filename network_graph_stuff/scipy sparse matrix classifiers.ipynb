{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<H1> Classification of text documents using sparse features</h1>\n",
      "\n",
      "<p> This is an example showing how scikit-learn can be used to classify documents by topics using a bag-of-words approach. \n",
      "This example uses a scipy sparse matrix to store the features and demonstrates various classifiers that can effiently handle \n",
      "sparse matrices.</p>\n",
      "\n",
      "<p> The dataset used in this example is the 20 newsgroups dataset. it will be automatically downloaded, then cached.</p>\n",
      "<p> The bar plot indicates the accuracy, training time (normalized) and test time (normalized) for each classifier.</p>\n",
      "\n",
      "<p> Shamelessly copied from this URL: http://scikit-learn.org/dev/auto_examples/document_classification_20newsgroups.html</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile document_classification_20newsgroups.py\n",
      "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
      "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
      "#         Mathieu Blondel <mathieu@mblondel.org>\n",
      "#         Lars Buitinck <L.J.Buitinck@uva.nl>\n",
      "# License: BSD 3 clause\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "import logging\n",
      "import numpy as np\n",
      "from optparse import OptionParser\n",
      "import sys\n",
      "from time import time\n",
      "import pylab as pl\n",
      "\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.linear_model import Perceptron\n",
      "from sklearn.linear_model import PassiveAggressiveClassifier\n",
      "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.neighbors import NearestCentroid\n",
      "from sklearn.utils.extmath import density\n",
      "from sklearn import metrics\n",
      "\n",
      "\n",
      "# Display progress logs on stdout\n",
      "logging.basicConfig(level=logging.INFO,\n",
      "                    format='%(asctime)s %(levelname)s %(message)s')\n",
      "\n",
      "\n",
      "# parse commandline arguments\n",
      "op = OptionParser()\n",
      "op.add_option(\"--report\",\n",
      "              action=\"store_true\", dest=\"print_report\",\n",
      "              help=\"Print a detailed classification report.\")\n",
      "op.add_option(\"--chi2_select\",\n",
      "              action=\"store\", type=\"int\", dest=\"select_chi2\",\n",
      "              help=\"Select some number of features using a chi-squared test\")\n",
      "op.add_option(\"--confusion_matrix\",\n",
      "              action=\"store_true\", dest=\"print_cm\",\n",
      "              help=\"Print the confusion matrix.\")\n",
      "op.add_option(\"--top10\",\n",
      "              action=\"store_true\", dest=\"print_top10\",\n",
      "              help=\"Print ten most discriminative terms per class\"\n",
      "                   \" for every classifier.\")\n",
      "op.add_option(\"--all_categories\",\n",
      "              action=\"store_true\", dest=\"all_categories\",\n",
      "              help=\"Whether to use all categories or not.\")\n",
      "op.add_option(\"--use_hashing\",\n",
      "              action=\"store_true\",\n",
      "              help=\"Use a hashing vectorizer.\")\n",
      "op.add_option(\"--n_features\",\n",
      "              action=\"store\", type=int, default=2 ** 16,\n",
      "              help=\"n_features when using the hashing vectorizer.\")\n",
      "op.add_option(\"--filtered\",\n",
      "              action=\"store_true\",\n",
      "              help=\"Remove newsgroup information that is easily overfit: \"\n",
      "                   \"headers, signatures, and quoting.\")\n",
      "\n",
      "(opts, args) = op.parse_args()\n",
      "if len(args) > 0:\n",
      "    op.error(\"this script takes no arguments.\")\n",
      "    sys.exit(1)\n",
      "\n",
      "print(__doc__)\n",
      "op.print_help()\n",
      "print()\n",
      "\n",
      "###############################################################################\n",
      "# Load some categories from the training set\n",
      "if opts.all_categories:\n",
      "    categories = None\n",
      "else:\n",
      "    categories = [\n",
      "        'alt.atheism',\n",
      "        'talk.religion.misc',\n",
      "        'comp.graphics',\n",
      "        'sci.space',\n",
      "    ]\n",
      "\n",
      "if opts.filtered:\n",
      "    remove = ('headers', 'footers', 'quotes')\n",
      "else:\n",
      "    remove = ()\n",
      "\n",
      "print(\"Loading 20 newsgroups dataset for categories:\")\n",
      "print(categories if categories else \"all\")\n",
      "\n",
      "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
      "                                shuffle=True, random_state=42,\n",
      "                                remove=remove)\n",
      "\n",
      "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
      "                               shuffle=True, random_state=42,\n",
      "                               remove=remove)\n",
      "print('data loaded')\n",
      "\n",
      "categories = data_train.target_names    # for case categories == None\n",
      "\n",
      "\n",
      "def size_mb(docs):\n",
      "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
      "\n",
      "data_train_size_mb = size_mb(data_train.data)\n",
      "data_test_size_mb = size_mb(data_test.data)\n",
      "\n",
      "print(\"%d documents - %0.3fMB (training set)\" % (\n",
      "    len(data_train.data), data_train_size_mb))\n",
      "print(\"%d documents - %0.3fMB (test set)\" % (\n",
      "    len(data_test.data), data_test_size_mb))\n",
      "print(\"%d categories\" % len(categories))\n",
      "print()\n",
      "\n",
      "# split a training set and a test set\n",
      "y_train, y_test = data_train.target, data_test.target\n",
      "\n",
      "print(\"Extracting features from the training dataset using a sparse vectorizer\")\n",
      "t0 = time()\n",
      "if opts.use_hashing:\n",
      "    vectorizer = HashingVectorizer(stop_words='english', non_negative=True,\n",
      "                                   n_features=opts.n_features)\n",
      "    X_train = vectorizer.transform(data_train.data)\n",
      "else:\n",
      "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
      "                                 stop_words='english')\n",
      "    X_train = vectorizer.fit_transform(data_train.data)\n",
      "duration = time() - t0\n",
      "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
      "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
      "print()\n",
      "\n",
      "print(\"Extracting features from the test dataset using the same vectorizer\")\n",
      "t0 = time()\n",
      "X_test = vectorizer.transform(data_test.data)\n",
      "duration = time() - t0\n",
      "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
      "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
      "print()\n",
      "\n",
      "if opts.select_chi2:\n",
      "    print(\"Extracting %d best features by a chi-squared test\" %\n",
      "          opts.select_chi2)\n",
      "    t0 = time()\n",
      "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
      "    X_train = ch2.fit_transform(X_train, y_train)\n",
      "    X_test = ch2.transform(X_test)\n",
      "    print(\"done in %fs\" % (time() - t0))\n",
      "    print()\n",
      "\n",
      "\n",
      "def trim(s):\n",
      "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
      "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
      "\n",
      "\n",
      "# mapping from integer feature name to original token string\n",
      "if opts.use_hashing:\n",
      "    feature_names = None\n",
      "else:\n",
      "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
      "\n",
      "\n",
      "###############################################################################\n",
      "# Benchmark classifiers\n",
      "def benchmark(clf):\n",
      "    print('_' * 80)\n",
      "    print(\"Training: \")\n",
      "    print(clf)\n",
      "    t0 = time()\n",
      "    clf.fit(X_train, y_train)\n",
      "    train_time = time() - t0\n",
      "    print(\"train time: %0.3fs\" % train_time)\n",
      "\n",
      "    t0 = time()\n",
      "    pred = clf.predict(X_test)\n",
      "    test_time = time() - t0\n",
      "    print(\"test time:  %0.3fs\" % test_time)\n",
      "\n",
      "    score = metrics.f1_score(y_test, pred)\n",
      "    print(\"f1-score:   %0.3f\" % score)\n",
      "\n",
      "    if hasattr(clf, 'coef_'):\n",
      "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
      "        print(\"density: %f\" % density(clf.coef_))\n",
      "\n",
      "        if opts.print_top10 and feature_names is not None:\n",
      "            print(\"top 10 keywords per class:\")\n",
      "            for i, category in enumerate(categories):\n",
      "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
      "                print(trim(\"%s: %s\"\n",
      "                      % (category, \" \".join(feature_names[top10]))))\n",
      "        print()\n",
      "\n",
      "    if opts.print_report:\n",
      "        print(\"classification report:\")\n",
      "        print(metrics.classification_report(y_test, pred,\n",
      "                                            target_names=categories))\n",
      "\n",
      "    if opts.print_cm:\n",
      "        print(\"confusion matrix:\")\n",
      "        print(metrics.confusion_matrix(y_test, pred))\n",
      "\n",
      "    print()\n",
      "    clf_descr = str(clf).split('(')[0]\n",
      "    return clf_descr, score, train_time, test_time\n",
      "\n",
      "\n",
      "results = []\n",
      "for clf, name in (\n",
      "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
      "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
      "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
      "        (KNeighborsClassifier(n_neighbors=10), \"kNN\")):\n",
      "    print('=' * 80)\n",
      "    print(name)\n",
      "    results.append(benchmark(clf))\n",
      "\n",
      "for penalty in [\"l2\", \"l1\"]:\n",
      "    print('=' * 80)\n",
      "    print(\"%s penalty\" % penalty.upper())\n",
      "    # Train Liblinear model\n",
      "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
      "                                            dual=False, tol=1e-3)))\n",
      "\n",
      "    # Train SGD model\n",
      "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
      "                                           penalty=penalty)))\n",
      "\n",
      "# Train SGD with Elastic Net penalty\n",
      "print('=' * 80)\n",
      "print(\"Elastic-Net penalty\")\n",
      "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
      "                                       penalty=\"elasticnet\")))\n",
      "\n",
      "# Train NearestCentroid without threshold\n",
      "print('=' * 80)\n",
      "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
      "results.append(benchmark(NearestCentroid()))\n",
      "\n",
      "# Train sparse Naive Bayes classifiers\n",
      "print('=' * 80)\n",
      "print(\"Naive Bayes\")\n",
      "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
      "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
      "\n",
      "\n",
      "class L1LinearSVC(LinearSVC):\n",
      "\n",
      "    def fit(self, X, y):\n",
      "        # The smaller C, the stronger the regularization.\n",
      "        # The more regularization, the more sparsity.\n",
      "        self.transformer_ = LinearSVC(penalty=\"l1\",\n",
      "                                      dual=False, tol=1e-3)\n",
      "        X = self.transformer_.fit_transform(X, y)\n",
      "        return LinearSVC.fit(self, X, y)\n",
      "\n",
      "    def predict(self, X):\n",
      "        X = self.transformer_.transform(X)\n",
      "        return LinearSVC.predict(self, X)\n",
      "\n",
      "print('=' * 80)\n",
      "print(\"LinearSVC with L1-based feature selection\")\n",
      "results.append(benchmark(L1LinearSVC()))\n",
      "\n",
      "\n",
      "# make some plots\n",
      "\n",
      "indices = np.arange(len(results))\n",
      "\n",
      "results = [[x[i] for x in results] for i in range(4)]\n",
      "\n",
      "clf_names, score, training_time, test_time = results\n",
      "training_time = np.array(training_time) / np.max(training_time)\n",
      "test_time = np.array(test_time) / np.max(test_time)\n",
      "\n",
      "pl.figure(figsize=(12,8))\n",
      "pl.title(\"Score\")\n",
      "pl.barh(indices, score, .2, label=\"score\", color='r')\n",
      "pl.barh(indices + .3, training_time, .2, label=\"training time\", color='g')\n",
      "pl.barh(indices + .6, test_time, .2, label=\"test time\", color='b')\n",
      "pl.yticks(())\n",
      "pl.legend(loc='best')\n",
      "pl.subplots_adjust(left=.25)\n",
      "pl.subplots_adjust(top=.95)\n",
      "pl.subplots_adjust(bottom=.05)\n",
      "\n",
      "for i, c in zip(indices, clf_names):\n",
      "    pl.text(-.3, i, c)\n",
      "\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting document_classification_20newsgroups.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run document_classification_20newsgroups.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:sklearn.datasets.twenty_newsgroups:Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Built-in functions, exceptions, and other objects.\n",
        "\n",
        "Noteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\n",
        "Usage: document_classification_20newsgroups.py [options]\n",
        "\n",
        "Options:\n",
        "  -h, --help            show this help message and exit\n",
        "  --report              Print a detailed classification report.\n",
        "  --chi2_select=SELECT_CHI2\n",
        "                        Select some number of features using a chi-squared\n",
        "                        test\n",
        "  --confusion_matrix    Print the confusion matrix.\n",
        "  --top10               Print ten most discriminative terms per class for\n",
        "                        every classifier.\n",
        "  --all_categories      Whether to use all categories or not.\n",
        "  --use_hashing         Use a hashing vectorizer.\n",
        "  --n_features=N_FEATURES\n",
        "                        n_features when using the hashing vectorizer.\n",
        "  --filtered            Remove newsgroup information that is easily overfit:\n",
        "                        headers, signatures, and quoting.\n",
        "\n",
        "Loading 20 newsgroups dataset for categories:\n",
        "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "data loaded"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2034 documents - 3.980MB (training set)\n",
        "1353 documents - 2.867MB (test set)\n",
        "4 categories\n",
        "\n",
        "Extracting features from the training dataset using a sparse vectorizer\n",
        "done in 0.967000s at 4.115MB/s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "n_samples: 2034, n_features: 33810\n",
        "\n",
        "Extracting features from the test dataset using the same vectorizer\n",
        "done in 0.528000s at 5.431MB/s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "n_samples: 1353, n_features: 33810\n",
        "\n",
        "================================================================================"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Ridge Classifier\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
        "        max_iter=None, normalize=False, solver=lsqr, tol=0.01)\n",
        "train time: 0.076s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.006s\n",
        "f1-score:   0.903\n",
        "dimensionality: 33810\n",
        "density: 1.000000\n",
        "\n",
        "\n",
        "================================================================================\n",
        "Perceptron\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
        "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=False,\n",
        "      verbose=0, warm_start=False)\n",
        "train time: 0.236s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.004s\n",
        "f1-score:   0.879\n",
        "dimensionality: 33810\n",
        "density: 0.250325\n",
        "\n",
        "\n",
        "================================================================================\n",
        "Passive-Aggressive\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "PassiveAggressiveClassifier(C=1.0, fit_intercept=True, loss=hinge, n_iter=50,\n",
        "              n_jobs=1, random_state=None, shuffle=False, verbose=0,\n",
        "              warm_start=False)\n",
        "train time: 0.288s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.003s\n",
        "f1-score:   0.902\n",
        "dimensionality: 33810\n",
        "density: 0.697449\n",
        "\n",
        "\n",
        "================================================================================\n",
        "kNN\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "KNeighborsClassifier(algorithm=auto, leaf_size=30, metric=minkowski,\n",
        "           n_neighbors=10, p=2, weights=uniform)\n",
        "train time: 0.001s\n",
        "test time:  0.416s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.856\n",
        "\n",
        "================================================================================\n",
        "L2 penalty\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "     intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l2,\n",
        "     random_state=None, tol=0.001, verbose=0)\n",
        "train time: 0.245s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.003s\n",
        "f1-score:   0.899\n",
        "dimensionality: 33810\n",
        "density: 1.000000\n",
        "\n",
        "\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,\n",
        "       loss=hinge, n_iter=50, n_jobs=1, penalty=l2, power_t=0.5,\n",
        "       random_state=None, rho=None, shuffle=False, verbose=0,\n",
        "       warm_start=False)\n",
        "train time: 0.237s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.004s\n",
        "f1-score:   0.900\n",
        "dimensionality: 33810\n",
        "density: 0.666341\n",
        "\n",
        "\n",
        "================================================================================\n",
        "L1 penalty\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "     intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l1,\n",
        "     random_state=None, tol=0.001, verbose=0)\n",
        "train time: 0.360s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.003s\n",
        "f1-score:   0.872\n",
        "dimensionality: 33810\n",
        "density: 0.005568\n",
        "\n",
        "\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,\n",
        "       loss=hinge, n_iter=50, n_jobs=1, penalty=l1, power_t=0.5,\n",
        "       random_state=None, rho=None, shuffle=False, verbose=0,\n",
        "       warm_start=False)\n",
        "train time: 0.587s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.003s\n",
        "f1-score:   0.882\n",
        "dimensionality: 33810\n",
        "density: 0.020112\n",
        "\n",
        "\n",
        "================================================================================\n",
        "Elastic-Net penalty\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,\n",
        "       loss=hinge, n_iter=50, n_jobs=1, penalty=elasticnet, power_t=0.5,\n",
        "       random_state=None, rho=None, shuffle=False, verbose=0,\n",
        "       warm_start=False)\n",
        "train time: 0.657s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.003s\n",
        "f1-score:   0.883\n",
        "dimensionality: 33810\n",
        "density: 0.027669\n",
        "\n",
        "\n",
        "================================================================================\n",
        "NearestCentroid (aka Rocchio classifier)\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "NearestCentroid(metric=euclidean, shrink_threshold=None)\n",
        "train time: 0.013s\n",
        "test time:  0.011s\n",
        "f1-score:   0.853\n",
        "\n",
        "================================================================================\n",
        "Naive Bayes\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
        "train time: 0.017s\n",
        "test time:  0.004s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "f1-score:   0.899\n",
        "dimensionality: 33810\n",
        "density: 1.000000\n",
        "\n",
        "\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "train time: 0.021s\n",
        "test time:  0.014s\n",
        "f1-score:   0.883\n",
        "dimensionality: 33810\n",
        "density: 1.000000\n",
        "\n",
        "\n",
        "================================================================================\n",
        "LinearSVC with L1-based feature selection\n",
        "________________________________________________________________________________\n",
        "Training: \n",
        "L1LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "      intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l2,\n",
        "      random_state=None, tol=0.0001, verbose=0)\n",
        "train time: 0.388s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test time:  0.007s\n",
        "f1-score:   0.879\n",
        "dimensionality: 561\n",
        "density: 0.999554\n",
        "\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAIuCAYAAABJrYevAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIBEghMAQKL/B86M3xDMy8ipAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x5dc6c90>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "whos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variable                      Type                          Data/Info\n",
        "---------------------------------------------------------------------\n",
        "BernoulliNB                   ABCMeta                       <class 'sklearn.naive_bayes.BernoulliNB'>\n",
        "HashingVectorizer             type                          <class 'sklearn.feature_e<...>.text.HashingVectorizer'>\n",
        "KNeighborsClassifier          ABCMeta                       <class 'sklearn.neighbors<...>on.KNeighborsClassifier'>\n",
        "LinearSVC                     ABCMeta                       <class 'sklearn.svm.classes.LinearSVC'>\n",
        "MultinomialNB                 ABCMeta                       <class 'sklearn.naive_bayes.MultinomialNB'>\n",
        "NearestCentroid               type                          <class 'sklearn.neighbors<...>entroid.NearestCentroid'>\n",
        "OptionParser                  classobj                      optparse.OptionParser\n",
        "PassiveAggressiveClassifier   ABCMeta                       <class 'sklearn.linear_mo<...>iveAggressiveClassifier'>\n",
        "Perceptron                    ABCMeta                       <class 'sklearn.linear_mo<...>l.perceptron.Perceptron'>\n",
        "RidgeClassifier               ABCMeta                       <class 'sklearn.linear_mo<...>l.ridge.RidgeClassifier'>\n",
        "SGDClassifier                 ABCMeta                       <class 'sklearn.linear_mo<...>_gradient.SGDClassifier'>\n",
        "SelectKBest                   ABCMeta                       <class 'sklearn.feature_s<...>e_selection.SelectKBest'>\n",
        "TfidfVectorizer               type                          <class 'sklearn.feature_e<...>on.text.TfidfVectorizer'>\n",
        "args                          list                          n=0\n",
        "categories                    list                          n=4\n",
        "chi2                          function                      <function chi2 at 0x05B9E4F0>\n",
        "density                       function                      <function density at 0x05B94DB0>\n",
        "fetch_20newsgroups            function                      <function fetch_20newsgroups at 0x05B1E330>\n",
        "logging                       module                        <module 'logging' from 'C<...>ib\\logging\\__init__.pyc'>\n",
        "metrics                       module                        <module 'sklearn.metrics'<...>rn\\metrics\\__init__.pyc'>\n",
        "op                            optparse.OptionParser         <optparse.OptionParser instance at 0x05D06F58>\n",
        "opts                          optparse.Values               {'select_chi2': None, 'pr<...>536, 'print_top10': None}\n",
        "pl                            module                        <module 'pylab' from 'C:\\<...>site-packages\\pylab.pyc'>\n",
        "print_function                __future__._Feature           _Feature((2, 6, 0, 'alpha<...>0, 0, 'alpha', 0), 65536)\n",
        "remove                        tuple                         n=0\n",
        "time                          builtin_function_or_method    <built-in function time>\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import urllib2\n",
      "response = urllib2.urlopen('http://google.com')\n",
      "html = response.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "HTTPError",
       "evalue": "HTTP Error 407: Proxy Authentication Required",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-e15dba2ae7f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murllib2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://google.com'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_opener\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0m_opener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 523\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\urllib2.pyc\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_full_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 407: Proxy Authentication Required"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}